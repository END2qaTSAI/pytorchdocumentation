{
    "What values are specified to replaceNaN, positive infinity, and negative infinity values ininput?": {
        "answer": "bynan,posinf, andneginf",
        "question": "What values are specified to replaceNaN, positive infinity, and negative infinity values ininput?",
        "context": "ReplacesNaN, positive infinity, and negative infinity values ininputwith the values specified bynan,posinf, andneginf, respectively.\nBy default,NaN`sarereplacedwithzero,positiveinfinityisreplacedwiththegreatestfinitevaluerepresentableby:attr:`input\u2019s dtype, and negative infinity\nis replaced with the least finite value representable byinput\u2019s dtype. input(Tensor) \u2013 the input tensor. nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "By default,NaN is replaced with what value?": {
        "answer": "zero",
        "question": "By default,NaN is replaced with what value?",
        "context": "ReplacesNaN, positive infinity, and negative infinity values ininputwith the values specified bynan,posinf, andneginf, respectively.\nBy default,NaN`sarereplacedwithzero,positiveinfinityisreplacedwiththegreatestfinitevaluerepresentableby:attr:`input\u2019s dtype, and negative infinity\nis replaced with the least finite value representable byinput\u2019s dtype. input(Tensor) \u2013 the input tensor. nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is input(Tensor)?": {
        "answer": "input tensor",
        "question": "What is input(Tensor)?",
        "context": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\nRotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0. input(Tensor) \u2013 the input tensor. k(int) \u2013 number of times to rotate dims(a listortuple) \u2013 axis to rotate Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90"
    },
    "What is the value to replaceNaNs with?": {
        "answer": "nan",
        "question": "What is the value to replaceNaNs with?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the default value to replaceNaNs with?": {
        "answer": "zero",
        "question": "What is the default value to replaceNaNs with?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What values are used to replace negative infinity values in input?": {
        "answer": "bynan,posinf, andneginf",
        "question": "What values are used to replace negative infinity values in input?",
        "context": "ReplacesNaN, positive infinity, and negative infinity values ininputwith the values specified bynan,posinf, andneginf, respectively.\nBy default,NaN`sarereplacedwithzero,positiveinfinityisreplacedwiththegreatestfinitevaluerepresentableby:attr:`input\u2019s dtype, and negative infinity\nis replaced with the least finite value representable byinput\u2019s dtype. input(Tensor) \u2013 the input tensor. nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the default value for negative infinity?": {
        "answer": "the least finite value",
        "question": "What is the default value for negative infinity?",
        "context": "ReplacesNaN, positive infinity, and negative infinity values ininputwith the values specified bynan,posinf, andneginf, respectively.\nBy default,NaN`sarereplacedwithzero,positiveinfinityisreplacedwiththegreatestfinitevaluerepresentableby:attr:`input\u2019s dtype, and negative infinity\nis replaced with the least finite value representable byinput\u2019s dtype. input(Tensor) \u2013 the input tensor. nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the input tensor?": {
        "answer": "input(Tensor)",
        "question": "What is the input tensor?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "What is the value to replace positive infinity values with?": {
        "answer": "posinf",
        "question": "What is the value to replace positive infinity values with?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the greatest finite value represented by?": {
        "answer": "byinput\u2019s dtype",
        "question": "What is the greatest finite value represented by?",
        "context": "input(Tensor) \u2013 the input tensor. nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the default value to replace positive infinity values with?": {
        "answer": "None",
        "question": "What is the default value to replace positive infinity values with?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "When are positive infinity values replaced with the greatest finite value representable by input's dtype?": {
        "answer": "If None",
        "question": "When are positive infinity values replaced with the greatest finite value representable by input's dtype?",
        "context": "input(Tensor) \u2013 the input tensor. nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "When are positive infinity values replaced with the greatest finite value representable byinput's dtype?": {
        "answer": "If None",
        "question": "When are positive infinity values replaced with the greatest finite value representable byinput's dtype?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the value to replace negative infinity values with?": {
        "answer": "neginf",
        "question": "What is the value to replace negative infinity values with?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "Neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with?": {
        "answer": "None",
        "question": "Neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with?",
        "context": "nan(Number,optional) \u2013 the value to replaceNaNs with. Default is zero. posinf(Number,optional) \u2013 if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable byinput\u2019s dtype.\nDefault is None. neginf(Number,optional) \u2013 if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable byinput\u2019s dtype.\nDefault is None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num"
    },
    "What is the name of the plant?": {
        "answer": "Alias fortorch.le",
        "question": "What is the name of the plant?",
        "context": "Alias fortorch.le(). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.less_equal.html#torch.less_equal"
    },
    "What does Alias fortorch.linalg.slogdet() do?": {
        "answer": "Alias",
        "question": "What does Alias fortorch.linalg.slogdet() do?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does each element of the inputinput by the corresponding element ofother do?": {
        "answer": "Divides",
        "question": "What does each element of the inputinput by the corresponding element ofother do?",
        "context": "Divides each element of the inputinputby the corresponding element ofother. Note By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "By default, this performs a \u201cwhat\u201d division like Python 3?": {
        "answer": "true",
        "question": "By default, this performs a \u201cwhat\u201d division like Python 3?",
        "context": "By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is another name for floor division?": {
        "answer": "therounding_modeargument",
        "question": "What is another name for floor division?",
        "context": "By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "Supportsbroadcasting to what?": {
        "answer": "common shape,type promotion",
        "question": "Supportsbroadcasting to what?",
        "context": "Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "Always promotes integer types to the default what?": {
        "answer": "scalar type",
        "question": "Always promotes integer types to the default what?",
        "context": "By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the divisor of input(Tensor)?": {
        "answer": "rounding",
        "question": "What is the divisor of input(Tensor)?",
        "context": "Divides each element of the inputinputby the corresponding element ofother. Note By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the name of the floor division function?": {
        "answer": "therounding_modeargument",
        "question": "What is the name of the floor division function?",
        "context": "Note By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the divisor of the input(Tensor)?": {
        "answer": "rounding",
        "question": "What is the divisor of the input(Tensor)?",
        "context": "Note By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What does input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor?": {
        "answer": "rounding",
        "question": "What does input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor?",
        "context": "By default, this performs a \u201ctrue\u201d division like Python 3.\nSee therounding_modeargument for floor division. Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "Always promotes integer types to what type?": {
        "answer": "default scalar type",
        "question": "Always promotes integer types to what type?",
        "context": "Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the default behavior?": {
        "answer": "None",
        "question": "What is the default behavior?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "Performs what type of rounding if both input andotherare integer types?": {
        "answer": "no rounding",
        "question": "Performs what type of rounding if both input andotherare integer types?",
        "context": "Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is equivalent to NumPy'snp.true_divide?": {
        "answer": "true division",
        "question": "What is equivalent to NumPy'snp.true_divide?",
        "context": "Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type. input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What type of rounding is performed if both input and otherare integer types?": {
        "answer": "no",
        "question": "What type of rounding is performed if both input and otherare integer types?",
        "context": "input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the equivalent to in Python and NumPy'snp.true_divide?": {
        "answer": "true division",
        "question": "What is the equivalent to in Python and NumPy'snp.true_divide?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "\"trunc\" rounds the results of the division towards what?": {
        "answer": "zero",
        "question": "\"trunc\" rounds the results of the division towards what?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What type of integer division is trunc equivalent to?": {
        "answer": "C-style",
        "question": "What type of integer division is trunc equivalent to?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the case when the inputs are promoted to the default scalar type?": {
        "answer": "if bothinputandotherare integer types",
        "question": "What is the case when the inputs are promoted to the default scalar type?",
        "context": "input(Tensor) \u2013 the dividend other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is equivalent to the/operator in Python and NumPy'snp.true_divide?": {
        "answer": "true division",
        "question": "What is equivalent to the/operator in Python and NumPy'snp.true_divide?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What rounds the results of the division towards zero?": {
        "answer": "trunc",
        "question": "What rounds the results of the division towards zero?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is equivalent to true division in Python?": {
        "answer": "C-style integer division",
        "question": "What is equivalent to true division in Python?",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What happens if both input and otherare integer types?": {
        "answer": "Performs no rounding",
        "question": "What happens if both input and otherare integer types?",
        "context": "other(TensororNumber) \u2013 the divisor rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the equivalent to in Python?": {
        "answer": "true division",
        "question": "What is the equivalent to in Python?",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the default behavior of rounding?": {
        "answer": "None",
        "question": "What is the default behavior of rounding?",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "Does rounding_mode(str,optional) perform any rounding?": {
        "answer": "no",
        "question": "Does rounding_mode(str,optional) perform any rounding?",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "Rounding_mode(str,optional) - default behavior. Performs no rounding and, if bothinputandother": {
        "answer": "None",
        "question": "Rounding_mode(str,optional) - default behavior. Performs no rounding and, if bothinputandother",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "When does rounding_mode(str,optional) perform no rounding?": {
        "answer": "if bothinputandotherare integer types",
        "question": "When does rounding_mode(str,optional) perform no rounding?",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is equivalent to the/operator in Python?": {
        "answer": "true division",
        "question": "What is equivalent to the/operator in Python?",
        "context": "rounding_mode(str,optional) \u2013 Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What type of rounding rounds the results of the division down?": {
        "answer": "floor",
        "question": "What type of rounding rounds the results of the division down?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What does the//operator and NumPy'snp.floor_divide equivalent to?": {
        "answer": "floor division",
        "question": "What does the//operator and NumPy'snp.floor_divide equivalent to?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What type of rounding does None perform?": {
        "answer": "no rounding",
        "question": "What type of rounding does None perform?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What type of division is equivalent to trunc?": {
        "answer": "C-style integer division",
        "question": "What type of division is equivalent to trunc?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the name of the rounding that rounds the results of a division down?": {
        "answer": "floor",
        "question": "What is the name of the rounding that rounds the results of a division down?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is equivalent to floor division in Python?": {
        "answer": "NumPy\u2019snp.floor_divide",
        "question": "What is equivalent to floor division in Python?",
        "context": "Type of rounding applied to the result: None - default behavior. Performs no rounding and, if bothinputandotherare integer types, promotes the inputs to the default scalar type.\nEquivalent to true division in Python (the/operator) and NumPy\u2019snp.true_divide. \"trunc\"- rounds the results of the division towards zero.\nEquivalent to C-style integer division. \"floor\"- rounds the results of the division down.\nEquivalent to floor division in Python (the//operator) and NumPy\u2019snp.floor_divide. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div"
    },
    "What is the name of Alias fortorch.trunc?": {
        "answer": "Alias fortorch.trunc()",
        "question": "What is the name of Alias fortorch.trunc?",
        "context": "Alias fortorch.trunc() ",
        "source": "https://pytorch.org/docs/stable/generated/torch.fix.html#torch.fix"
    },
    "What is another name for fortorch.trunc()?": {
        "answer": "Alias fortorch.trunc()",
        "question": "What is another name for fortorch.trunc()?",
        "context": "Alias fortorch.trunc() ",
        "source": "https://pytorch.org/docs/stable/generated/torch.fix.html#torch.fix"
    },
    "What does the Appendix Migrate to?": {
        "answer": "PyTorch 1.2 Recursive Scripting API References",
        "question": "What does the Appendix Migrate to?",
        "context": "Creating TorchScript Code Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer?": {
        "answer": "Python Functions and Modules",
        "question": "What Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer?",
        "context": "TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the difference between Python and PyTorch?": {
        "answer": "Python Language Reference Comparison",
        "question": "What is the difference between Python and PyTorch?",
        "context": "Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Appendix Migrating to what?": {
        "answer": "PyTorch 1.2 Recursive Scripting API References",
        "question": "Appendix Migrating to what?",
        "context": "TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is Debugging Disable JIT for Debugging?": {
        "answer": "Python Language Reference Comparison",
        "question": "What is Debugging Disable JIT for Debugging?",
        "context": "Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What did Appendix Migrate to?": {
        "answer": "PyTorch 1.2 Recursive Scripting API References",
        "question": "What did Appendix Migrate to?",
        "context": "Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What language can a TorchScript program be saved from?": {
        "answer": "Python",
        "question": "What language can a TorchScript program be saved from?",
        "context": "Creating TorchScript Code Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What Python Language Reference Comparison Debugging Disable JIT for Debugging?": {
        "answer": "Python Functions and Modules",
        "question": "What Python Language Reference Comparison Debugging Disable JIT for Debugging?",
        "context": "Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript?": {
        "answer": "a way to create serializable and optimizable models from PyTorch code",
        "question": "What is TorchScript?",
        "context": "Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What program can a TorchScript program be saved from?": {
        "answer": "Python",
        "question": "What program can a TorchScript program be saved from?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript do for Debugging?": {
        "answer": "Disable JIT",
        "question": "What does TorchScript do for Debugging?",
        "context": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the Appendix Migrating to PyTorch 1.2 Recursive Scripting API References?": {
        "answer": "Frequently Asked Questions Known Issues",
        "question": "What is the Appendix Migrating to PyTorch 1.2 Recursive Scripting API References?",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of process can a TorchScript program be saved from?": {
        "answer": "Python",
        "question": "What type of process can a TorchScript program be saved from?",
        "context": "Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API Reference": {
        "answer": "Frequently Asked Questions",
        "question": "What is the name of the Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API Reference",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Any TorchScript program can be saved from what process?": {
        "answer": "Python",
        "question": "Any TorchScript program can be saved from what process?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the Appendix Migrating to PyTorch 1.2 Recursive Scripting API References?": {
        "answer": "Known Issues",
        "question": "What is the name of the Appendix Migrating to PyTorch 1.2 Recursive Scripting API References?",
        "context": "Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a way to create serializable and optimizable models from PyTorch code?": {
        "answer": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript",
        "question": "What is a way to create serializable and optimizable models from PyTorch code?",
        "context": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript a way to create serializable and optimizable models from?": {
        "answer": "PyTorch code",
        "question": "What is TorchScript a way to create serializable and optimizable models from?",
        "context": "Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is References TorchScript?": {
        "answer": "a way to create serializable and optimizable models",
        "question": "What is References TorchScript?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a standalone TorchScript program that can be run independently from Python?": {
        "answer": "C++ program",
        "question": "What is an example of a standalone TorchScript program that can be run independently from Python?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Why are Python programs disadvantageous?": {
        "answer": "performance and multi-threading reasons",
        "question": "Why are Python programs disadvantageous?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What program can be run independently from Python?": {
        "answer": "TorchScript",
        "question": "What program can be run independently from Python?",
        "context": "We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what language is it possible to train models in PyTorch?": {
        "answer": "Python",
        "question": "In what language is it possible to train models in PyTorch?",
        "context": "Creating TorchScript Code Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a gentle introduction to TorchScript?": {
        "answer": "theIntroduction to TorchScripttutorial",
        "question": "What is a gentle introduction to TorchScript?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What language is used to run a PyTorch model?": {
        "answer": "C++",
        "question": "What language is used to run a PyTorch model?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will inspect the source code, compile it as TorchScript code using the TorchScript compiler?": {
        "answer": "Scripting a function ornn.Module",
        "question": "What will inspect the source code, compile it as TorchScript code using the TorchScript compiler?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the introduction to TorchScript?": {
        "answer": "introduction to TorchScript",
        "question": "What is the introduction to TorchScript?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an end-to-end example of converting a PyTorch model to TorchScript and running it in C++?": {
        "answer": "Loading a PyTorch Model in C++tutorial",
        "question": "What is an end-to-end example of converting a PyTorch model to TorchScript and running it in C++?",
        "context": "For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleor": {
        "answer": "ornn.Module",
        "question": "What will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleor",
        "context": "Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How is a scriptFunction optimized?": {
        "answer": "just-in-time compilation",
        "question": "How is a scriptFunction optimized?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When does Compilesfn occur?": {
        "answer": "Compilesfnwhen it is first called during tracing",
        "question": "When does Compilesfn occur?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of converting a PyTorch model to TorchScript and running it in C++?": {
        "answer": "end-to-end example",
        "question": "What is an example of converting a PyTorch model to TorchScript and running it in C++?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of code does ornn.Module compile?": {
        "answer": "TorchScript",
        "question": "What type of code does ornn.Module compile?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to optimize a function?": {
        "answer": "just-in-time compilation",
        "question": "What is used to optimize a function?",
        "context": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is called when it is first called during tracing?": {
        "answer": "Compilesfn",
        "question": "What is called when it is first called during tracing?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a module that will inspect the source code and compile it as TorchScript code using the TorchScript compiler?": {
        "answer": "Scripting a function ornn",
        "question": "What is an example of a module that will inspect the source code and compile it as TorchScript code using the TorchScript compiler?",
        "context": "Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will be used to optimize a function?": {
        "answer": "just-in-time compilation",
        "question": "What will be used to optimize a function?",
        "context": "Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When is Compilesfn called?": {
        "answer": "Compilesfnwhen it is first called during tracing",
        "question": "When is Compilesfn called?",
        "context": "Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will be used to optimize a module?": {
        "answer": "just-in-time compilation",
        "question": "What will be used to optimize a module?",
        "context": "Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Scripting a function ornn.Module compile it as?": {
        "answer": "TorchScript code",
        "question": "What does Scripting a function ornn.Module compile it as?",
        "context": "Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will be used to optimize a script module?": {
        "answer": "just-in-time compilation",
        "question": "What will be used to optimize a script module?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does executingfuncand a reference to the value of the result of this execution do?": {
        "answer": "Creates an asynchronous task",
        "question": "What does executingfuncand a reference to the value of the result of this execution do?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this function do?": {
        "answer": "Draws binary random numbers (0 or 1) from a Bernoulli distribution",
        "question": "What does this function do?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is used to optimize a script module?": {
        "answer": "just-in-time compilation",
        "question": "What is used to optimize a script module?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of task is created?": {
        "answer": "asynchronous task executingfunc",
        "question": "What type of task is created?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this do?": {
        "answer": "Sets the seed for generating random numbers",
        "question": "What does this do?",
        "context": "Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a wrapper around?": {
        "answer": "C++torch::jit::Module",
        "question": "What is a wrapper around?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When is Compilesfn first called?": {
        "answer": "tracing",
        "question": "When is Compilesfn first called?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to optimize a scriptModule?": {
        "answer": "just-in-time compilation",
        "question": "What is used to optimize a scriptModule?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Compilesfn do?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What does Compilesfn do?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this create?": {
        "answer": "asynchronous task executingfunc",
        "question": "What does this create?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does it do to complete the atorch.jit.Future[T]asynchronous task?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What does it do to complete the atorch.jit.Future[T]asynchronous task?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a wrapper around C++torch functionally equivalent to?": {
        "answer": "aScriptModule",
        "question": "What is a wrapper around C++torch functionally equivalent to?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does atorch.jit.Future[T]asynchronous task do?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What does atorch.jit.Future[T]asynchronous task do?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is C++torch::jit::Module functionally equivalent to?": {
        "answer": "aScriptModule",
        "question": "What is C++torch::jit::Module functionally equivalent to?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of task does atorch.jit.Future[T]ask create?": {
        "answer": "asynchronous task",
        "question": "What type of task does atorch.jit.Future[T]ask create?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Forces completion of what?": {
        "answer": "atorch.jit.Future[T]asynchronous task",
        "question": "Forces completion of what?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is jit::Module functionally equivalent to?": {
        "answer": "aScriptModule",
        "question": "What is jit::Module functionally equivalent to?",
        "context": "Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the function that returns the result of atorch.jit.Future[T]asynchronous task?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What is the function that returns the result of atorch.jit.Future[T]asynchronous task?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is atorch.jit::Module functionally equivalent to?": {
        "answer": "aScriptModule",
        "question": "What is atorch.jit::Module functionally equivalent to?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Freezing aScriptModule do?": {
        "answer": "Save an offline version of this module for use in a separate process",
        "question": "What does Freezing aScriptModule do?",
        "context": "  Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScriptModule do?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What does TorchScriptModule do?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the Torch": {
        "answer": "Freezing aScriptModule",
        "question": "What will attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the Torch",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of version of atorch.jit.Future[T]asynchronous task can be saved for use in a separate process?": {
        "answer": "offline",
        "question": "What type of version of atorch.jit.Future[T]asynchronous task can be saved for use in a separate process?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will clone it and attempt to inline the cloned module's submodules, parameters, and attributes as": {
        "answer": "Freezing aScriptModule",
        "question": "What will clone it and attempt to inline the cloned module's submodules, parameters, and attributes as",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you do with the cloned module?": {
        "answer": "Save an offline version of this module for use in a separate process",
        "question": "What can you do with the cloned module?",
        "context": "A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What did aScriptModuleorScriptFunction previously save?": {
        "answer": "withtorch.jit.save",
        "question": "What did aScriptModuleorScriptFunction previously save?",
        "context": "Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "A wrapper around C++torch::jit::Module is functionally equivalent to what?": {
        "answer": "aScriptModule",
        "question": "A wrapper around C++torch::jit::Module is functionally equivalent to what?",
        "context": "A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is C++torch::jit::Module?": {
        "answer": "wrapper",
        "question": "What is C++torch::jit::Module?",
        "context": "For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of version of aScriptModule can you save for use in a separate process?": {
        "answer": "offline",
        "question": "What type of version of aScriptModule can you save for use in a separate process?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where was aScriptModuleorScriptFunction previously saved?": {
        "answer": "withtorch.jit.save",
        "question": "Where was aScriptModuleorScriptFunction previously saved?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is functionally equivalent to?": {
        "answer": "aScriptModule",
        "question": "What is functionally equivalent to?",
        "context": "Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as": {
        "answer": "Freezing aScriptModule",
        "question": "What will clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as",
        "context": "Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to save a cloned aScriptModule?": {
        "answer": "Save an offline version of this module for use in a separate process",
        "question": "What is one way to save a cloned aScriptModule?",
        "context": "Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the difference between aScriptModule and aScriptModule?": {
        "answer": "represents a single function and does not have any attributes or Parameters",
        "question": "What is the difference between aScriptModule and aScriptModule?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will clone aScriptModule and attempt to inline the cloned module\u2019s submodules,": {
        "answer": "Freezing",
        "question": "What will clone aScriptModule and attempt to inline the cloned module\u2019s submodules,",
        "context": "Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to save a cloned module?": {
        "answer": "Save an offline version of this module for use in a separate process",
        "question": "What is one way to save a cloned module?",
        "context": "A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will attempt to inline the cloned module's submodules, parameters, and attributes as constants in the Torch": {
        "answer": "Freezing aScriptModule",
        "question": "What will attempt to inline the cloned module's submodules, parameters, and attributes as constants in the Torch",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to save a module?": {
        "answer": "Save an offline version of this module for use in a separate process",
        "question": "What is one way to save a module?",
        "context": "Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this decorator indicate to the compiler that a function or method should be ignored and replaced with?": {
        "answer": "raising of an exception",
        "question": "What does this decorator indicate to the compiler that a function or method should be ignored and replaced with?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where does this function provide for conatiner type refinement?": {
        "answer": "TorchScript",
        "question": "Where does this function provide for conatiner type refinement?",
        "context": "This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where can you save a version of this module for use in a separate process?": {
        "answer": "offline",
        "question": "Where can you save a version of this module for use in a separate process?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this function provide in TorchScript?": {
        "answer": "conatiner type refinement",
        "question": "What does this function provide in TorchScript?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What was previously saved withtorch.jit.save?": {
        "answer": "Load aScriptModuleorScriptFunction",
        "question": "What was previously saved withtorch.jit.save?",
        "context": "Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What language should a function in TorchScript be left as?": {
        "answer": "Python",
        "question": "What language should a function in TorchScript be left as?",
        "context": "This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this decorator indicate to the compiler that a function or method should be ignored and left as?": {
        "answer": "Python function",
        "question": "What does this decorator indicate to the compiler that a function or method should be ignored and left as?",
        "context": "This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this function provide for in TorchScript?": {
        "answer": "conatiner type refinement",
        "question": "What does this function provide for in TorchScript?",
        "context": "  Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the left-hand side expression used to indicate to the TorchScript compiler?": {
        "answer": "a class instance attribute with type oftype",
        "question": "What is the left-hand side expression used to indicate to the TorchScript compiler?",
        "context": "Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the decorator indicate to the compiler that a function or method should be ignored and replaced with?": {
        "answer": "raising of an exception",
        "question": "What does the decorator indicate to the compiler that a function or method should be ignored and replaced with?",
        "context": "This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the TorchScript conatiner type refinement?": {
        "answer": "a pass-through function that returnsvalue",
        "question": "What is the TorchScript conatiner type refinement?",
        "context": "This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does returnthe_value hint TorchScript compiler about?": {
        "answer": "the type ofthe_value",
        "question": "What does returnthe_value hint TorchScript compiler about?",
        "context": "  This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the returnthe_value hint TorchScript compiler?": {
        "answer": "the type ofthe_value",
        "question": "What does the returnthe_value hint TorchScript compiler?",
        "context": "  This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing or scripting can be composed to suit the specific requirements of a part of a model?": {
        "answer": "TorchScript",
        "question": "Tracing or scripting can be composed to suit the specific requirements of a part of a model?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be composed to suit the particular requirements of a part of a model?": {
        "answer": "Tracing and scripting",
        "question": "What can be composed to suit the particular requirements of a part of a model?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can scripted functions call?": {
        "answer": "traced functions",
        "question": "What can scripted functions call?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a traced function particularly useful when you need to use around a simple feed-forward model?": {
        "answer": "control-flow",
        "question": "What is a traced function particularly useful when you need to use around a simple feed-forward model?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can a beam search of a sequence to sequence model call?": {
        "answer": "encoder module",
        "question": "What can a beam search of a sequence to sequence model call?",
        "context": "Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an easier approach for converting a model to TorchScript?": {
        "answer": "tracing or scripting",
        "question": "What is an easier approach for converting a model to TorchScript?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can tracing and scripting be composed to?": {
        "answer": "suit the particular requirements of a part of a model",
        "question": "What can tracing and scripting be composed to?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When are scripted functions useful?": {
        "answer": "when you need to use control-flow around a simple feed-forward model",
        "question": "When are scripted functions useful?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can the beam search of a sequence to sequence model call?": {
        "answer": "an encoder module generated using tracing",
        "question": "What can the beam search of a sequence to sequence model call?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a traced function useful when you need to use around a feed-forward model?": {
        "answer": "control-flow",
        "question": "What is a traced function useful when you need to use around a feed-forward model?",
        "context": "Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what language can a traced function be called?": {
        "answer": "script",
        "question": "In what language can a traced function be called?",
        "context": "Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can a scripted function call?": {
        "answer": "an encoder module generated using tracing",
        "question": "What can a scripted function call?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can traced functions call?": {
        "answer": "script functions",
        "question": "What can traced functions call?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of model is most of the model?": {
        "answer": "feed-forward network",
        "question": "What type of model is most of the model?",
        "context": "Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is preserved correctly inside of a script function called by a traced function?": {
        "answer": "Control-flow",
        "question": "What is preserved correctly inside of a script function called by a traced function?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a function that can call a traced function?": {
        "answer": "script function in a traced function",
        "question": "What is an example of a function that can call a traced function?",
        "context": "Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Traced functions can call what?": {
        "answer": "script functions",
        "question": "Traced functions can call what?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When is this useful?": {
        "answer": "when a small part of a model requires some control-flow",
        "question": "When is this useful?",
        "context": "Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a script function called in?": {
        "answer": "a traced function",
        "question": "What is a script function called in?",
        "context": "Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of network is most of the model?": {
        "answer": "feed-forward network",
        "question": "What type of network is most of the model?",
        "context": "Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing can be called from the methods of what?": {
        "answer": "script module",
        "question": "Tracing can be called from the methods of what?",
        "context": "Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When are script functions useful?": {
        "answer": "when a small part of a model requires some control-flow",
        "question": "When are script functions useful?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used to generate a submodule using fornn.Modules?": {
        "answer": "tracing",
        "question": "What can be used to generate a submodule using fornn.Modules?",
        "context": "Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be called in a traced function?": {
        "answer": "script function",
        "question": "What can be called in a traced function?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used to call a submodule using tracing?": {
        "answer": "script module",
        "question": "What can be used to call a submodule using tracing?",
        "context": "Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used to generate a submodule using tracing?": {
        "answer": "traced module",
        "question": "What can be used to generate a submodule using tracing?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can a submodule be generated using fornn.Modules?": {
        "answer": "using a traced module",
        "question": "How can a submodule be generated using fornn.Modules?",
        "context": "Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript is a statically typed subset of what programming language?": {
        "answer": "Python",
        "question": "TorchScript is a statically typed subset of what programming language?",
        "context": "TorchScript is a statically typed subset of Python, so many Python features apply\ndirectly to TorchScript. See the fullTorchScript Language Referencefor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the reference for TorchScript?": {
        "answer": "fullTorchScript Language Reference",
        "question": "What is the name of the reference for TorchScript?",
        "context": "TorchScript is a statically typed subset of Python, so many Python features apply\ndirectly to TorchScript. See the fullTorchScript Language Referencefor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What supports the use of most PyTorch functions and many Python built-ins?": {
        "answer": "TorchScript",
        "question": "What supports the use of most PyTorch functions and many Python built-ins?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript Builtins provide?": {
        "answer": "a full reference of supported functions",
        "question": "What does TorchScript Builtins provide?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript supports a subset of what PyTorch provides?": {
        "answer": "tensor and neural network functions",
        "question": "TorchScript supports a subset of what PyTorch provides?",
        "context": "TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where are most modules fromtorch.nn supported?": {
        "answer": "TorchScript",
        "question": "Where are most modules fromtorch.nn supported?",
        "context": "TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a list of unsupported PyTorch functions and modules?": {
        "answer": "SeeTorchScript Unsupported Pytorch Constructs",
        "question": "What is a list of unsupported PyTorch functions and modules?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript support?": {
        "answer": "PyTorch functions and many Python built-ins",
        "question": "What does TorchScript support?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where can you find a full reference of supported functions?": {
        "answer": "SeeTorchScript Builtins",
        "question": "Where can you find a full reference of supported functions?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript supports a subset of what PyTorch functions?": {
        "answer": "tensor and neural network functions",
        "question": "TorchScript supports a subset of what PyTorch functions?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is supported by TorchScript?": {
        "answer": "most modules",
        "question": "What is supported by TorchScript?",
        "context": "TorchScript supports the use of most PyTorch functions and many Python built-ins.\nSeeTorchScript Builtinsfor a full reference of supported functions. TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where can you find a list of unsupported PyTorch functions and modules?": {
        "answer": "SeeTorchScript",
        "question": "Where can you find a list of unsupported PyTorch functions and modules?",
        "context": "TorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthetorchnamespace, all functions intorch.nn.functionaland\nmost modules fromtorch.nnare supported in TorchScript. SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a list of unsupported PyTorch Constructs?": {
        "answer": "SeeTorchScript",
        "question": "What is a list of unsupported PyTorch Constructs?",
        "context": "SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. Many of Python\u2019sbuilt-in functionsare supported in TorchScript.\nThemathmodule is also supported (seemath Modulefor details), but no other Python modules\n(built-in or third party) are supported. For a full listing of supported Python features, seePython Language Reference Coverage. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where are many of Python's built-in functions supported?": {
        "answer": "TorchScript",
        "question": "Where are many of Python's built-in functions supported?",
        "context": "Many of Python\u2019sbuilt-in functionsare supported in TorchScript.\nThemathmodule is also supported (seemath Modulefor details), but no other Python modules\n(built-in or third party) are supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is also supported, but no other Python modules are supported?": {
        "answer": "Themathmodule",
        "question": "What is also supported, but no other Python modules are supported?",
        "context": "SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. Many of Python\u2019sbuilt-in functionsare supported in TorchScript.\nThemathmodule is also supported (seemath Modulefor details), but no other Python modules\n(built-in or third party) are supported. For a full listing of supported Python features, seePython Language Reference Coverage. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "For a full listing of supported features, seePython Language Reference Coverage.": {
        "answer": "Python",
        "question": "For a full listing of supported features, seePython Language Reference Coverage.",
        "context": "SeeTorchScript Unsupported Pytorch Constructsfor a list of unsupported PyTorch functions and modules. Many of Python\u2019sbuilt-in functionsare supported in TorchScript.\nThemathmodule is also supported (seemath Modulefor details), but no other Python modules\n(built-in or third party) are supported. For a full listing of supported Python features, seePython Language Reference Coverage. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is also supported in TorchScript?": {
        "answer": "Themathmodule",
        "question": "What is also supported in TorchScript?",
        "context": "Many of Python\u2019sbuilt-in functionsare supported in TorchScript.\nThemathmodule is also supported (seemath Modulefor details), but no other Python modules\n(built-in or third party) are supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Many of Python'sbuilt-in functions are supported in what?": {
        "answer": "TorchScript",
        "question": "Many of Python'sbuilt-in functions are supported in what?",
        "context": "Many of Python\u2019sbuilt-in functionsare supported in TorchScript.\nThemathmodule is also supported (seemath Modulefor details), but no other Python modules\n(built-in or third party) are supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What language is supported by the Python Language Reference Coverage?": {
        "answer": "Python",
        "question": "What language is supported by the Python Language Reference Coverage?",
        "context": "For a full listing of supported Python features, seePython Language Reference Coverage. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the full list of supported Python features?": {
        "answer": "Python Language Reference Coverage",
        "question": "What is the full list of supported Python features?",
        "context": "For a full listing of supported Python features, seePython Language Reference Coverage. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Debugging this script use?": {
        "answer": "withpdbworks",
        "question": "What does Debugging this script use?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can we disable TorchScript?": {
        "answer": "globally disable JIT",
        "question": "How can we disable TorchScript?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If the above script is calleddisable_what, we can invoke it like so?": {
        "answer": "jit_example.py",
        "question": "If the above script is calleddisable_what, we can invoke it like so?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To disable what for a specific function, see@torch.jit.ignore.": {
        "answer": "TorchScript compiler",
        "question": "To disable what for a specific function, see@torch.jit.ignore.",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will we be able to step into the@torch.jit.scriptfunction as?": {
        "answer": "normal Python function",
        "question": "What will we be able to step into the@torch.jit.scriptfunction as?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What compiler does TorchScript provide a code pretty-printer for allScriptModuleinstances?": {
        "answer": "TorchScript",
        "question": "What compiler does TorchScript provide a code pretty-printer for allScriptModuleinstances?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript provide a code pretty-printer for?": {
        "answer": "allScriptModuleinstances",
        "question": "What does TorchScript provide a code pretty-printer for?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the code pretty-printer do?": {
        "answer": "gives an interpretation of the script method\u2019s code as valid Python syntax",
        "question": "What does the code pretty-printer do?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a code pretty-printer for allScriptModuleinstances?": {
        "answer": "example",
        "question": "What is an example of a code pretty-printer for allScriptModuleinstances?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "AScriptModulewith a singleforwardmethod will have what?": {
        "answer": "attributecode",
        "question": "AScriptModulewith a singleforwardmethod will have what?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do you need to do if theScriptModulehas more than one method?": {
        "answer": "access.codeon the method itself and not the module",
        "question": "What do you need to do if theScriptModulehas more than one method?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can we inspect the code of a method namedfooon aScriptModule?": {
        "answer": "accessing.foo.code",
        "question": "How can we inspect the code of a method namedfooon aScriptModule?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the example above produce?": {
        "answer": "output",
        "question": "What does the example above produce?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If theScriptModulehas more than one method, you will need to do what?": {
        "answer": "access.codeon the method itself and not the module",
        "question": "If theScriptModulehas more than one method, you will need to do what?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the code for?": {
        "answer": "theforwardmethod",
        "question": "What is the code for?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is another way to verify that TorchScript has captured your model code correctly?": {
        "answer": "tracing or scripting",
        "question": "What is another way to verify that TorchScript has captured your model code correctly?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript's representation at a lower level than the code pretty- printer?": {
        "answer": "IR graphs",
        "question": "What is TorchScript's representation at a lower level than the code pretty- printer?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript's compilation of the code for?": {
        "answer": "theforwardmethod",
        "question": "What is TorchScript's compilation of the code for?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the purpose of theforwardmethod?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "What is the purpose of theforwardmethod?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is another name for static single assignment?": {
        "answer": "SSA",
        "question": "What is another name for static single assignment?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the C++ backend of PyTorch?": {
        "answer": "ATen",
        "question": "What is the C++ backend of PyTorch?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of TorchScript's SSA intermediate representation?": {
        "answer": "example",
        "question": "What is an example of TorchScript's SSA intermediate representation?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does SSA stand for?": {
        "answer": "static single assignment",
        "question": "What does SSA stand for?",
        "context": "TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The graph follows the same rules described in what section with regard toforwardmethod lookup?": {
        "answer": "theInspecting Codesection",
        "question": "The graph follows the same rules described in what section with regard toforwardmethod lookup?",
        "context": "TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the example script above produce?": {
        "answer": "the graph",
        "question": "What does the example script above produce?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What produces the graph?": {
        "answer": "The example script above",
        "question": "What produces the graph?",
        "context": "TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the example script that produces the graph?": {
        "answer": "instruction%rv.1:Tensor=aten::zeros",
        "question": "What is the example script that produces the graph?",
        "context": "graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do we assign the output to a (unique) value namedrv.1?": {
        "answer": "%rv.1:Tensormeans",
        "question": "What do we assign the output to a (unique) value namedrv.1?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The graph follows the same rules described in theInspecting Codesection with regard to what?": {
        "answer": "forwardmethod lookup",
        "question": "The graph follows the same rules described in theInspecting Codesection with regard to what?",
        "context": "graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the script that produces the graph?": {
        "answer": "test.py",
        "question": "What is the name of the script that produces the graph?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the value that we assign the output to?": {
        "answer": "ofTensortype",
        "question": "What is the value that we assign the output to?",
        "context": "graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the instruction that produces the graph?": {
        "answer": "%rv.1:Tensor",
        "question": "What is the name of the instruction that produces the graph?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of value is assigned to the output?": {
        "answer": "ofTensortype",
        "question": "What type of value is assigned to the output?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What specifies which values in scope should be passed as inputs?": {
        "answer": "aten::zerosis the operator (equivalent totorch.zeros) and the input list",
        "question": "What specifies which values in scope should be passed as inputs?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where can the schema for built-in functions likeaten::zeros be found?": {
        "answer": "atBuiltin Functions",
        "question": "Where can the schema for built-in functions likeaten::zeros be found?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does %rv.1:Tensormeans assign the output to?": {
        "answer": "a (unique) value namedrv.1",
        "question": "What does %rv.1:Tensormeans assign the output to?",
        "context": "The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the operator (equivalent totorch.zeros) that specifies which values in scope should be passed as inputs?": {
        "answer": "aten",
        "question": "What is the operator (equivalent totorch.zeros) that specifies which values in scope should be passed as inputs?",
        "context": "The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be found atBuiltin Functions?": {
        "answer": "built-in functions likeaten::zeros",
        "question": "What can be found atBuiltin Functions?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of an instruction that assigns the output to a (unique) value namedrv.1?": {
        "answer": "instruction%rv.1:Tensor=aten::zeros",
        "question": "What is an example of an instruction that assigns the output to a (unique) value namedrv.1?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the instruction%rv.1:Tensor=aten?": {
        "answer": "test.py",
        "question": "What is the name of the instruction%rv.1:Tensor=aten?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the unique value assigned to rv.1?": {
        "answer": "ofTensortype",
        "question": "What is the unique value assigned to rv.1?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Which operator specifies which values in scope should be passed as inputs?": {
        "answer": "aten",
        "question": "Which operator specifies which values in scope should be passed as inputs?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the unique value assigned to the output?": {
        "answer": "%rv.1",
        "question": "What is the name of the unique value assigned to the output?",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the equivalent totorch.zeros?": {
        "answer": "aten",
        "question": "What is the equivalent totorch.zeros?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of functions can be found atBuiltin Functions?": {
        "answer": "built-in functions",
        "question": "What type of functions can be found atBuiltin Functions?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the operator?": {
        "answer": "aten",
        "question": "What is the operator?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the location in the original source file that generated this instruction?": {
        "answer": "#test.py:9:10",
        "question": "What is the location in the original source file that generated this instruction?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where is the file named test.py located?": {
        "answer": "line 9",
        "question": "Where is the file named test.py located?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What operator specifies which values in scope should be passed as inputs?": {
        "answer": "aten",
        "question": "What operator specifies which values in scope should be passed as inputs?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the file that generated the instruction?": {
        "answer": "test.py",
        "question": "What is the name of the file that generated the instruction?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Operators can also have what?": {
        "answer": "associatedblocks",
        "question": "Operators can also have what?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Why are operators formatted to reflect their equivalent source code forms?": {
        "answer": "to facilitate easy debugging",
        "question": "Why are operators formatted to reflect their equivalent source code forms?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Graphs can be inspected as shown to confirm that the computation described by what is correct?": {
        "answer": "aScriptModuleis",
        "question": "Graphs can be inspected as shown to confirm that the computation described by what is correct?",
        "context": "#test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be inspected to confirm that the computation described by aScriptModule is correct?": {
        "answer": "Graphs",
        "question": "What can be inspected to confirm that the computation described by aScriptModule is correct?",
        "context": "Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be inspected to confirm that the computation described by aScriptModuleis correct?": {
        "answer": "Graphs",
        "question": "What can be inspected to confirm that the computation described by aScriptModuleis correct?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of cases exist where the trace of a given Python function/module will not be representative of the underlying code?": {
        "answer": "edge cases",
        "question": "What type of cases exist where the trace of a given Python function/module will not be representative of the underlying code?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is dependent on inputs?": {
        "answer": "control flow",
        "question": "What is dependent on inputs?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a control flow dependent on inputs?": {
        "answer": "tensor shapes",
        "question": "What is an example of a control flow dependent on inputs?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of in-place operations of tensor views?": {
        "answer": "indexing",
        "question": "What is an example of in-place operations of tensor views?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of control flow that is dependent on inputs (e.g. what?": {
        "answer": "tensor shapes",
        "question": "Tracing of control flow that is dependent on inputs (e.g. what?",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g. what on the left-hand side of an assignment) is": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g. what on the left-hand side of an assignment) is",
        "context": "Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a control flow that is dependent on inputs?": {
        "answer": "tensor shapes",
        "question": "What is an example of a control flow that is dependent on inputs?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a tensor view that may not be traceable in the future?": {
        "answer": "indexing",
        "question": "What is an example of a tensor view that may not be traceable in the future?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of control flow that is dependent on what?": {
        "answer": "inputs",
        "question": "Tracing of control flow that is dependent on what?",
        "context": "Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of control flow that is dependent on inputs (e.g. what) Tracing of in-place operations of tens": {
        "answer": "tensor shapes",
        "question": "Tracing of control flow that is dependent on inputs (e.g. what) Tracing of in-place operations of tens",
        "context": "Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g. what on the left-hand side of an assignment)": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g. what on the left-hand side of an assignment)",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to automatically catch many errors in traces?": {
        "answer": "check_inputson",
        "question": "What is one way to automatically catch many errors in traces?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a list of tuples of inputs that will be used to re-trace the computation and verify the": {
        "answer": "example",
        "question": "What is an example of a list of tuples of inputs that will be used to re-trace the computation and verify the",
        "context": "Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the term for in-place operations of tensor views?": {
        "answer": "Tracing",
        "question": "What is the term for in-place operations of tensor views?",
        "context": "Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In-place operations of tensor views (e.g. what on the left-hand side of an assignment) may be traceable in": {
        "answer": "indexing",
        "question": "In-place operations of tensor views (e.g. what on the left-hand side of an assignment) may be traceable in",
        "context": "Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a list of tuples of inputs that will be used to re-trace the computation and verify the results?": {
        "answer": "check_inputson",
        "question": "What is a list of tuples of inputs that will be used to re-trace the computation and verify the results?",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does check_inputson thetorch.jit.trace()API.check_inputstakes give us?": {
        "answer": "diagnostic information",
        "question": "What does check_inputson thetorch.jit.trace()API.check_inputstakes give us?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In the future, these cases may be what?": {
        "answer": "traceable",
        "question": "In the future, these cases may be what?",
        "context": "Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a check_inputson that will be used to re-trace the computation and verify the results?": {
        "answer": "Gives us the following diagnostic information",
        "question": "What is an example of a check_inputson that will be used to re-trace the computation and verify the results?",
        "context": "Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does check_inputson thetorch.jit.trace()API.check_inputstakes contain?": {
        "answer": "a list of tuples of inputs",
        "question": "What does check_inputson thetorch.jit.trace()API.check_inputstakes contain?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does check_inputson do?": {
        "answer": "a list of tuples of inputs that will be used to re-trace the computation and verify the results",
        "question": "What does check_inputson do?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does check_inputson give us?": {
        "answer": "diagnostic information",
        "question": "What does check_inputson give us?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this message indicate to us that the computation differed between when we first traced it and when we traced it?": {
        "answer": "thecheck_inputs",
        "question": "What does this message indicate to us that the computation differed between when we first traced it and when we traced it?",
        "context": "Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the loop within the body ofloop_in_traced_fn depend on?": {
        "answer": "the shape of the inputx",
        "question": "What does the loop within the body ofloop_in_traced_fn depend on?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can a data-dependent control flow be captured?": {
        "answer": "usingtorch.jit.script()",
        "question": "How can a data-dependent control flow be captured?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The loop within the body ofloop_in_traced_fndepends on what?": {
        "answer": "the shape of the inputx",
        "question": "The loop within the body ofloop_in_traced_fndepends on what?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can data-dependent control flow be captured?": {
        "answer": "usingtorch.jit.script()",
        "question": "How can data-dependent control flow be captured?",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "A trace of a function that contains an in-place assignment on a slice of a Tensor produces several warnings and what else?": {
        "answer": "a graph",
        "question": "A trace of a function that contains an in-place assignment on a slice of a Tensor produces several warnings and what else?",
        "context": "In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What produces warnings for several problematic patterns in traced computation?": {
        "answer": "tracer",
        "question": "What produces warnings for several problematic patterns in traced computation?",
        "context": "The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "A trace of a function that contains an in-place assignment on a slice (a view) of a Tensor produces several warnings": {
        "answer": "a graph",
        "question": "A trace of a function that contains an in-place assignment on a slice (a view) of a Tensor produces several warnings",
        "context": "In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an in-place assignment on a Tensor?": {
        "answer": "a slice",
        "question": "What is an in-place assignment on a Tensor?",
        "context": "The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the tracer produce for several problematic patterns in traced computation?": {
        "answer": "warnings",
        "question": "What does the tracer produce for several problematic patterns in traced computation?",
        "context": "The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be done to fix the warnings?": {
        "answer": "build up the result tensor out-of-place withtorch",
        "question": "What can be done to fix the warnings?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you use this to ensure TorchScript has captured correctly?": {
        "answer": "model code",
        "question": "What can you use this to ensure TorchScript has captured correctly?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can you use the forwardmethod?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "How can you use the forwardmethod?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can we fix this problem?": {
        "answer": "build up the result tensor out-of-place withtorch",
        "question": "How can we fix this problem?",
        "context": "The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the model train on GPU and do inference on?": {
        "answer": "CPU",
        "question": "What does the model train on GPU and do inference on?",
        "context": "Q: I would like to train a model on GPU and do inference on CPU. What are the\nbest practices? First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do I want to train a model on?": {
        "answer": "GPU",
        "question": "What do I want to train a model on?",
        "context": "Q: I would like to train a model on GPU and do inference on CPU. What are the\nbest practices? First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are the best practices for training a model on GPU and doing inference on CPU?": {
        "answer": "best practices",
        "question": "What are the best practices for training a model on GPU and doing inference on CPU?",
        "context": "Q: I would like to train a model on GPU and do inference on CPU. What are the\nbest practices? First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The tracer may witness what type of creation on a specific device?": {
        "answer": "tensor",
        "question": "The tracer may witness what type of creation on a specific device?",
        "context": "This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does casting the model before saving it do?": {
        "answer": "ensures that the tracer has the correct device information",
        "question": "What does casting the model before saving it do?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do I store attributes on?": {
        "answer": "aScriptModule",
        "question": "What do I store attributes on?",
        "context": "Q: I would like to train a model on GPU and do inference on CPU. What are the\nbest practices? First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of aScriptModule?": {
        "answer": "model like:",
        "question": "What is an example of aScriptModule?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What may the tracer witness on a specific device?": {
        "answer": "tensor creation",
        "question": "What may the tracer witness on a specific device?",
        "context": "This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does casting a model before saving ensure the tracer has?": {
        "answer": "the correct device information",
        "question": "What does casting a model before saving ensure the tracer has?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where do I store attributes?": {
        "answer": "aScriptModule",
        "question": "Where do I store attributes?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does aScriptModule store attributes on?": {
        "answer": "a model",
        "question": "What does aScriptModule store attributes on?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do I store on aScriptModule?": {
        "answer": "attributes",
        "question": "What do I store on aScriptModule?",
        "context": "Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Casting the model before saving ensures that the tracer has what?": {
        "answer": "the correct device information",
        "question": "Casting the model before saving ensures that the tracer has what?",
        "context": "This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to inform the compiler of attributes onScriptModule?": {
        "answer": "How do I store attributes on aScriptModule",
        "question": "What is one way to inform the compiler of attributes onScriptModule?",
        "context": "This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What model will result in a compilation error?": {
        "answer": "IfModelis instantiated",
        "question": "What model will result in a compilation error?",
        "context": "This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How many ways to inform the compiler of attributes onScriptModule?": {
        "answer": "4",
        "question": "How many ways to inform the compiler of attributes onScriptModule?",
        "context": "This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will happen if a model is instantiated?": {
        "answer": "a compilation error",
        "question": "What will happen if a model is instantiated?",
        "context": "Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to inform the compiler of attributes on aScriptModule?": {
        "answer": "How do I store attributes on aScriptModule",
        "question": "What is one way to inform the compiler of attributes on aScriptModule?",
        "context": "Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What model would result in a compilation error if the compiler didn't know aboutx?": {
        "answer": "IfModelis instantiated",
        "question": "What model would result in a compilation error if the compiler didn't know aboutx?",
        "context": "Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of attribute does register_buffer correspond to?": {
        "answer": "typeTensor",
        "question": "What type of attribute does register_buffer correspond to?",
        "context": "Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is equivalent to an attribute of typeTensor?": {
        "answer": "register_buffer",
        "question": "What is equivalent to an attribute of typeTensor?",
        "context": "IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What attribute is equivalent to register_buffer?": {
        "answer": "typeTensor",
        "question": "What attribute is equivalent to register_buffer?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "IfModelis instantiated, what will happen to a model?": {
        "answer": "a compilation error",
        "question": "IfModelis instantiated, what will happen to a model?",
        "context": "Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will result in a compilation error since the compiler doesn't know aboutx?": {
        "answer": "IfModelis instantiated",
        "question": "What will result in a compilation error since the compiler doesn't know aboutx?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How many ways are there to inform the compiler of attributes onScriptModule?": {
        "answer": "4",
        "question": "How many ways are there to inform the compiler of attributes onScriptModule?",
        "context": "IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is register_buffer equivalent to?": {
        "answer": "attribute",
        "question": "What is register_buffer equivalent to?",
        "context": "2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "IfModelis is instantiated, what will happen?": {
        "answer": "a compilation error",
        "question": "IfModelis is instantiated, what will happen?",
        "context": "IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Register_buffer is equivalent to what type of typeTensor?": {
        "answer": "attribute",
        "question": "Register_buffer is equivalent to what type of typeTensor?",
        "context": "1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How many Constants are saved directly in the code of the model?": {
        "answer": "3.",
        "question": "How many Constants are saved directly in the code of the model?",
        "context": "2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Annotating a class member asFinal or adding it to a list called what will mark the contained names as constants?": {
        "answer": "constants",
        "question": "Annotating a class member asFinal or adding it to a list called what will mark the contained names as constants?",
        "context": "2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where are constants saved?": {
        "answer": "the code of the model",
        "question": "Where are constants saved?",
        "context": "2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How are constants saved in the code of the model?": {
        "answer": "Seebuiltin-constantsfor details",
        "question": "How are constants saved in the code of the model?",
        "context": "2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Values wrapped inregister_buffer will work as they do what?": {
        "answer": "onnn.Modules",
        "question": "Values wrapped inregister_buffer will work as they do what?",
        "context": "2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. 3. Constants - Annotating a class member asFinal(or adding it to a list called__constants__at the class definition level) will mark the contained names\nas constants. Constants are saved directly in the code of the model. Seebuiltin-constantsfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do I want to trace?": {
        "answer": "module\u2019s method",
        "question": "What do I want to trace?",
        "context": "Q: I would like to trace module\u2019s method but I keep getting this error: RuntimeError:CannotinsertaTensorthatrequiresgradasaconstant.Considermakingitaparameterorinput,ordetachingthegradient This error usually means that the method you are tracing uses a module\u2019s parameters and\nyou are passing the module\u2019s method instead of the module instance (e.g.my_module_instance.forwardvsmy_module_instance). Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Invokingtracewith a module's method captures what asconstants?": {
        "answer": "module parameters",
        "question": "Invokingtracewith a module's method captures what asconstants?",
        "context": "RuntimeError:CannotinsertaTensorthatrequiresgradasaconstant.Considermakingitaparameterorinput,ordetachingthegradient This error usually means that the method you are tracing uses a module\u2019s parameters and\nyou are passing the module\u2019s method instead of the module instance (e.g.my_module_instance.forwardvsmy_module_instance). Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are you passing instead of the module instance?": {
        "answer": "module\u2019s method",
        "question": "What are you passing instead of the module instance?",
        "context": "RuntimeError:CannotinsertaTensorthatrequiresgradasaconstant.Considermakingitaparameterorinput,ordetachingthegradient This error usually means that the method you are tracing uses a module\u2019s parameters and\nyou are passing the module\u2019s method instead of the module instance (e.g.my_module_instance.forwardvsmy_module_instance). Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the method you are tracing use?": {
        "answer": "module\u2019s parameters",
        "question": "What does the method you are tracing use?",
        "context": "This error usually means that the method you are tracing uses a module\u2019s parameters and\nyou are passing the module\u2019s method instead of the module instance (e.g.my_module_instance.forwardvsmy_module_instance). Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Invokingtracewith a module's method captures what?": {
        "answer": "module parameters",
        "question": "Invokingtracewith a module's method captures what?",
        "context": "Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. To trace a specific method on a module, seetorch.jit.trace_module ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What creates a new module and copies parameters into the new module?": {
        "answer": "invokingtracewith module\u2019s instance",
        "question": "What creates a new module and copies parameters into the new module?",
        "context": "Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. To trace a specific method on a module, seetorch.jit.trace_module ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is passed instead of the module instance?": {
        "answer": "module\u2019s method",
        "question": "What is passed instead of the module instance?",
        "context": "This error usually means that the method you are tracing uses a module\u2019s parameters and\nyou are passing the module\u2019s method instead of the module instance (e.g.my_module_instance.forwardvsmy_module_instance). Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Invokingtracewith a module's method captures what as constants?": {
        "answer": "module parameters",
        "question": "Invokingtracewith a module's method captures what as constants?",
        "context": "Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. To trace a specific method on a module, seetorch.jit.trace_module ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does invokingtrace with a module's instance do?": {
        "answer": "creates a new module and correctly copies parameters into the new module",
        "question": "What does invokingtrace with a module's instance do?",
        "context": "Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. To trace a specific method on a module, seetorch.jit.trace_module ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does seetorch.jit.trace_module do?": {
        "answer": "trace a specific method on a module",
        "question": "What does seetorch.jit.trace_module do?",
        "context": "Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. To trace a specific method on a module, seetorch.jit.trace_module ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to trace a specific method on a module?": {
        "answer": "seetorch.jit.trace_module",
        "question": "What is used to trace a specific method on a module?",
        "context": "Invokingtracewith a module\u2019s method captures module parameters (which may require gradients) asconstants. On the other hand, invokingtracewith module\u2019s instance (e.g.my_module) creates a new module and correctly copies parameters into the new module, so they can accumulate gradients if required. To trace a specific method on a module, seetorch.jit.trace_module ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If you're usingSequentialwith TorchScript, the inputs of some of theSequentialsubmodules may be": {
        "answer": "falsely inferred to beTensor",
        "question": "If you're usingSequentialwith TorchScript, the inputs of some of theSequentialsubmodules may be",
        "context": "If you\u2019re usingSequentialwith TorchScript, the inputs of some\nof theSequentialsubmodules may be falsely inferred to beTensor, even if they\u2019re annotated otherwise. The canonical\nsolution is to subclassnn.Sequentialand redeclareforwardwith the input typed correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the canonical solution to this problem?": {
        "answer": "subclassnn",
        "question": "What is the canonical solution to this problem?",
        "context": "If you\u2019re usingSequentialwith TorchScript, the inputs of some\nof theSequentialsubmodules may be falsely inferred to beTensor, even if they\u2019re annotated otherwise. The canonical\nsolution is to subclassnn.Sequentialand redeclareforwardwith the input typed correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The inputs of some of theSequentialsubmodules may be falsely inferred to what?": {
        "answer": "beTensor",
        "question": "The inputs of some of theSequentialsubmodules may be falsely inferred to what?",
        "context": "If you\u2019re usingSequentialwith TorchScript, the inputs of some\nof theSequentialsubmodules may be falsely inferred to beTensor, even if they\u2019re annotated otherwise. The canonical\nsolution is to subclassnn.Sequentialand redeclareforwardwith the input typed correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the canonical solution?": {
        "answer": "redeclareforward",
        "question": "What is the canonical solution?",
        "context": "If you\u2019re usingSequentialwith TorchScript, the inputs of some\nof theSequentialsubmodules may be falsely inferred to beTensor, even if they\u2019re annotated otherwise. The canonical\nsolution is to subclassnn.Sequentialand redeclareforwardwith the input typed correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What version of TorchScript does this section detail?": {
        "answer": "PyTorch 1.2",
        "question": "What version of TorchScript does this section detail?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you do if you are new to TorchScript?": {
        "answer": "skip this section",
        "question": "What can you do if you are new to TorchScript?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How many main changes are there to the TorchScript API with PyTorch 1.2?": {
        "answer": "two",
        "question": "How many main changes are there to the TorchScript API with PyTorch 1.2?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will now attempt to recursively compile functions, methods, and classes that it encounters?": {
        "answer": "1.torch.jit.script",
        "question": "What will now attempt to recursively compile functions, methods, and classes that it encounters?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the command that makes compilation of TorchScript \"opt-out\" instead of \"opt-in\"?": {
        "answer": "calltorch.jit.script",
        "question": "What is the name of the command that makes compilation of TorchScript \"opt-out\" instead of \"opt-in\"?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How many main changes to the TorchScript API with PyTorch 1.2?": {
        "answer": "two",
        "question": "How many main changes to the TorchScript API with PyTorch 1.2?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When you calltorch.jit.script, compilation is what?": {
        "answer": "\u201copt-out\u201d, rather than \u201copt-in\u201d",
        "question": "When you calltorch.jit.script, compilation is what?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When you compile functions, methods, and classes, compilation is \"opt-out\", rather than \"opt-in\"?": {
        "answer": "calltorch.jit.script",
        "question": "When you compile functions, methods, and classes, compilation is \"opt-out\", rather than \"opt-in\"?",
        "context": "1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the preferred way to createScriptModules?": {
        "answer": "2.torch.jit.script(nn_module_instance)",
        "question": "What is the preferred way to createScriptModules?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a simpler, easier-to-use API for?": {
        "answer": "converting yournn.Modules intoScriptModules",
        "question": "What is a simpler, easier-to-use API for?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Torch.jit.script now try to do?": {
        "answer": "recursively compile functions, methods, and classes",
        "question": "What does Torch.jit.script now try to do?",
        "context": "1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what environment are yournn.Modules ready to be optimized and executed?": {
        "answer": "a non-Python environment",
        "question": "In what environment are yournn.Modules ready to be optimized and executed?",
        "context": "1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "ScriptModules are ready to be optimized and executed in a non-what environment?": {
        "answer": "Python",
        "question": "ScriptModules are ready to be optimized and executed in a non-what environment?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is compiled by default?": {
        "answer": "module\u2019sforward",
        "question": "What is compiled by default?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what order are methods called fromforward compiled?": {
        "answer": "inforward",
        "question": "In what order are methods called fromforward compiled?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the module'sforward compiled by?": {
        "answer": "default",
        "question": "What is the module'sforward compiled by?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What method is lazily compiled in the order they are used inforward?": {
        "answer": "fromforwardare",
        "question": "What method is lazily compiled in the order they are used inforward?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a way to compile a method that is not called fromforward?": {
        "answer": "add@torch.jit.export",
        "question": "What is a way to compile a method that is not called fromforward?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a way to stop the compiler from compiling a method?": {
        "answer": "add@torch.jit.ignoreor@torch.jit.unused",
        "question": "What is a way to stop the compiler from compiling a method?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To what does the method need to be called?": {
        "answer": "python",
        "question": "To what does the method need to be called?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the new usage look like?": {
        "answer": "@ignoredcannot be exported;@unusedcan",
        "question": "What does the new usage look like?",
        "context": "The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To compile a method that is not called fromforward that is not called fromforward, what is done?": {
        "answer": "add@torch.jit.export",
        "question": "To compile a method that is not called fromforward that is not called fromforward, what is done?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does add@torch.jit.export do to stop the compiler from compiling a method?": {
        "answer": "add@torch.jit.ignoreor",
        "question": "What does add@torch.jit.export do to stop the compiler from compiling a method?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoreor do to a call to python?": {
        "answer": "@ignoreleaves the method",
        "question": "What does @ignoreor do to a call to python?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoredcannot be exported?": {
        "answer": "@ignoredcannot be exported;@unusedcan",
        "question": "What does @ignoredcannot be exported?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are the two exceptions that prevent the compiler from compiling a method that is not called fromforward?": {
        "answer": "@ignoredcannot be exported;@unusedcan",
        "question": "What are the two exceptions that prevent the compiler from compiling a method that is not called fromforward?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does a compiler do to compile a method that is not called fromforward?": {
        "answer": "add@torch.jit.export",
        "question": "What does a compiler do to compile a method that is not called fromforward?",
        "context": "To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What cannot be exported?": {
        "answer": "@ignored",
        "question": "What cannot be exported?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To what does the method have to be called to stop the compiler from compiling it?": {
        "answer": "python",
        "question": "To what does the method have to be called to stop the compiler from compiling it?",
        "context": "To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the difference between an exported method and an unused one?": {
        "answer": "@ignoredcannot be exported;@unusedcan",
        "question": "What is the difference between an exported method and an unused one?",
        "context": "To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Most attribute types can be what?": {
        "answer": "inferred",
        "question": "Most attribute types can be what?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of type can be annotated using PEP 526-styleclass annotations?": {
        "answer": "empty container types",
        "question": "What type of type can be annotated using PEP 526-styleclass annotations?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does add@torch.jit.ignoreor do?": {
        "answer": "@ignoreleaves the method",
        "question": "What does add@torch.jit.ignoreor do?",
        "context": "To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be inferred?": {
        "answer": "attribute types",
        "question": "What can be inferred?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of container types can be annotated using PEP 526-styleclass annotations?": {
        "answer": "empty container types",
        "question": "What type of container types can be annotated using PEP 526-styleclass annotations?",
        "context": "To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoreleaves the method as a call to?": {
        "answer": "python",
        "question": "What does @ignoreleaves the method as a call to?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used to mark constants instead of adding the name of the member to__constants__?": {
        "answer": "aFinalclass annotation",
        "question": "What can be used to mark constants instead of adding the name of the member to__constants__?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does add@torch.jit.ignoreor@torch.jit.unused do?": {
        "answer": "stop the compiler from compiling a method",
        "question": "What does add@torch.jit.ignoreor@torch.jit.unused do?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoreor do to stop the compiler from compiling a method as a call to python?": {
        "answer": "@ignoreleaves",
        "question": "What does @ignoreor do to stop the compiler from compiling a method as a call to python?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoredcannot be exported do?": {
        "answer": "@ignoredcannot be exported",
        "question": "What does @ignoredcannot be exported do?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do empty container types do?": {
        "answer": "annotate their types usingPEP 526-styleclass annotations",
        "question": "What do empty container types do?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be marked with aFinalclass annotation instead of adding the name of the member to__constants__?": {
        "answer": "Constants",
        "question": "What can be marked with aFinalclass annotation instead of adding the name of the member to__constants__?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the method a call to?": {
        "answer": "python",
        "question": "What is the method a call to?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How many styleclass annotations are needed for empty container types?": {
        "answer": "526",
        "question": "How many styleclass annotations are needed for empty container types?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of hints can be used in place oftorch.jit.annotate?": {
        "answer": "Python 3",
        "question": "What type of hints can be used in place oftorch.jit.annotate?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What happens when a method is called to python?": {
        "answer": "and@unusedreplaces it with an exception",
        "question": "What happens when a method is called to python?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of containers can be annotated using PEP 526-styleclass annotations?": {
        "answer": "empty container types",
        "question": "What type of containers can be annotated using PEP 526-styleclass annotations?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used in place oftorch.jit.annotate?": {
        "answer": "Python 3 type hints",
        "question": "What can be used in place oftorch.jit.annotate?",
        "context": "The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of attributes can be annotated using PEP 526-styleclass annotations?": {
        "answer": "empty container types",
        "question": "What type of attributes can be annotated using PEP 526-styleclass annotations?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecor": {
        "answer": "Python 3",
        "question": "What type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecor",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of hints can be used in place oftorch.jit.annotate The@torch.jit.script_methodde": {
        "answer": "Python 3",
        "question": "What type of hints can be used in place oftorch.jit.annotate The@torch.jit.script_methodde",
        "context": "Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What classes inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class?": {
        "answer": "The@torch.jit.script_methoddecorator Classes",
        "question": "What classes inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class?",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What class inherits fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class": {
        "answer": "The__constants__array",
        "question": "What class inherits fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What class does The__constants__array inherit from?": {
        "answer": "Attributewrapper",
        "question": "What class does The__constants__array inherit from?",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the function that changes behavior in PyTorch 1.2?": {
        "answer": "Thetorch.jit.annotatefunction",
        "question": "What is the name of the function that changes behavior in PyTorch 1.2?",
        "context": "Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Before PyTorch 1.2, what decorator was used to make a function or method callable from code that is exported?": {
        "answer": "@ignore",
        "question": "Before PyTorch 1.2, what decorator was used to make a function or method callable from code that is exported?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to get the @ignore decorator back?": {
        "answer": "@torch.jit.unused()",
        "question": "What is used to get the @ignore decorator back?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is now equivalent to @torch.jit.ignore(drop=False)?": {
        "answer": "@torch.jit.ignoreis",
        "question": "What is now equivalent to @torch.jit.ignore(drop=False)?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the decorator used to make a function or method callable from code that was exported before PyTorch 1.2?": {
        "answer": "@torch.jit.ignore",
        "question": "What is the name of the decorator used to make a function or method callable from code that was exported before PyTorch 1.2?",
        "context": "Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When did The@torch.jit.ignoreannotation's behavior change?": {
        "answer": "PyTorch 1.2",
        "question": "When did The@torch.jit.ignoreannotation's behavior change?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the decorator used to make a function or method callable from code that is exported?": {
        "answer": "@torch.jit.ignore",
        "question": "What is the name of the decorator used to make a function or method callable from code that is exported?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what version of Python did the @torch.jit.ignoreannotation's behavior change?": {
        "answer": "PyTorch 1.2",
        "question": "In what version of Python did the @torch.jit.ignoreannotation's behavior change?",
        "context": "The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is now equivalent to @torch.jit.ignore?": {
        "answer": "@torch.jit.ignore",
        "question": "What is now equivalent to @torch.jit.ignore?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is another name for the @ignore decorator in PyTorch 1.2?": {
        "answer": "@torch.jit.ignore",
        "question": "What is another name for the @ignore decorator in PyTorch 1.2?",
        "context": "The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Which module's data is copied to aScriptModule when passed to thetorch.jit.scriptfunction?": {
        "answer": "atorch.nn.Module",
        "question": "Which module's data is copied to aScriptModule when passed to thetorch.jit.scriptfunction?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "By what method is the module'sforward compiled?": {
        "answer": "default",
        "question": "By what method is the module'sforward compiled?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a method on annn.Module used for?": {
        "answer": "an entry point into aScriptModuleand",
        "question": "What is a method on annn.Module used for?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Who compiles the module?": {
        "answer": "TorchScript compiler",
        "question": "Who compiles the module?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In addition to fromforward, what is compiled in the order they are used inforward?": {
        "answer": "any@torch.jit.exportmethods",
        "question": "In addition to fromforward, what is compiled in the order they are used inforward?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used as an entry point into aScriptModule?": {
        "answer": "annn.Module",
        "question": "What is used as an entry point into aScriptModule?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used as an entry point into aScriptModuleand?": {
        "answer": "annn.Moduleis",
        "question": "What is used as an entry point into aScriptModuleand?",
        "context": "This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is assumed to be an entry point?": {
        "answer": "forwardimplicitly",
        "question": "What is assumed to be an entry point?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Functions and methods called what are compiled as they are seen by the compiler?": {
        "answer": "fromforwardare",
        "question": "Functions and methods called what are compiled as they are seen by the compiler?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a method that does not need this decorator?": {
        "answer": "@torch.jit.exporton a method",
        "question": "What is an example of a method that does not need this decorator?",
        "context": "This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this decorator indicate about a method on annn.Module?": {
        "answer": "Warning",
        "question": "What does this decorator indicate about a method on annn.Module?",
        "context": "This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is assumed to be an entry point, so it does not need this decorator?": {
        "answer": "forwardimplicitly",
        "question": "What is assumed to be an entry point, so it does not need this decorator?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are compiled as they are seen by the compiler?": {
        "answer": "Functions and methods called fromforward",
        "question": "What are compiled as they are seen by the compiler?",
        "context": "forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Functions can be decorated with what if needed?": {
        "answer": "@torch.jit.ignoreortorch.jit",
        "question": "Functions can be decorated with what if needed?",
        "context": "Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this decorator indicate that a method on annn.Module should be compiled?": {
        "answer": "Warning",
        "question": "What does this decorator indicate that a method on annn.Module should be compiled?",
        "context": "This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Forwardimplicitly is assumed to be what?": {
        "answer": "entry point",
        "question": "Forwardimplicitly is assumed to be what?",
        "context": "forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a method that does not need a decorator?": {
        "answer": "@torch.jit.exporton a method",
        "question": "What is an example of a method that does not need a decorator?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does forwardimplicitly do?": {
        "answer": "Warning",
        "question": "What does forwardimplicitly do?",
        "context": "forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the warning that can be added to Functions and methods called fromforwardimplicitly?": {
        "answer": "Warning",
        "question": "What is the name of the warning that can be added to Functions and methods called fromforwardimplicitly?",
        "context": "forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the main benefit of using @torch.jit.exporton a method?": {
        "answer": "Functions don\u2019t change much",
        "question": "What is the main benefit of using @torch.jit.exporton a method?",
        "context": "forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript class support?": {
        "answer": "experimental",
        "question": "What is TorchScript class support?",
        "context": "Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of type is TorchScript best suited for?": {
        "answer": "aNamedTuple",
        "question": "What type of type is TorchScript best suited for?",
        "context": "This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is exported by default?": {
        "answer": "Everything in a user definedTorchScript Classis exported by default",
        "question": "What is exported by default?",
        "context": "Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Functions can be decorated with what?": {
        "answer": "@torch.jit.ignoreortorch.jit.unusedif needed",
        "question": "Functions can be decorated with what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How is everything in a user definedTorchScript Class exported?": {
        "answer": "by default",
        "question": "How is everything in a user definedTorchScript Class exported?",
        "context": "Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Why can functions be decorated with@torch.jit.ignoreortorch.jit.unusedif needed?": {
        "answer": "Functions don\u2019t change much",
        "question": "Why can functions be decorated with@torch.jit.ignoreortorch.jit.unusedif needed?",
        "context": "Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a simple record-like type?": {
        "answer": "aNamedTuple",
        "question": "What is an example of a simple record-like type?",
        "context": "Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What doesn't change much?": {
        "answer": "Functions",
        "question": "What doesn't change much?",
        "context": "Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can functions be decorated with if needed?": {
        "answer": "@torch.jit.ignore",
        "question": "What can functions be decorated with if needed?",
        "context": "Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript best suited for?": {
        "answer": "simple record-like types",
        "question": "What is TorchScript best suited for?",
        "context": "Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be decorated with@torch.jit.ignore if needed?": {
        "answer": "functions",
        "question": "What can be decorated with@torch.jit.ignore if needed?",
        "context": "Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Who needs to know the types ofmodule attributes?": {
        "answer": "The TorchScript compiler",
        "question": "Who needs to know the types ofmodule attributes?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can most types be inferred from?": {
        "answer": "the value of the member",
        "question": "What can most types be inferred from?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What cannot have their types inferred and must have their types annotated withPEP 526-styleclass annotations?": {
        "answer": "Empty lists and dicts",
        "question": "What cannot have their types inferred and must have their types annotated withPEP 526-styleclass annotations?",
        "context": "Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If a type cannot be inferred and is not explicitly annotated, it will not be added as what to the resultingScriptModul": {
        "answer": "an attribute",
        "question": "If a type cannot be inferred and is not explicitly annotated, it will not be added as what to the resultingScriptModul",
        "context": "forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How is everything exported in a TorchScript Class?": {
        "answer": "by default",
        "question": "How is everything exported in a TorchScript Class?",
        "context": "Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the TorchScript compiler need to know?": {
        "answer": "types ofmodule attributes",
        "question": "What does the TorchScript compiler need to know?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Most types can be inferred from what?": {
        "answer": "value of the member",
        "question": "Most types can be inferred from what?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What cannot have their types inferred and must have their types annotated with PEP 526-styleclass annotations?": {
        "answer": "Empty lists and dicts",
        "question": "What cannot have their types inferred and must have their types annotated with PEP 526-styleclass annotations?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What happens if a type is not explicitly annotated?": {
        "answer": "it will not be added as an attribute",
        "question": "What happens if a type is not explicitly annotated?",
        "context": "Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What happens if a type cannot be inferred and is not explicitly annotated?": {
        "answer": "it will not be added as an attribute",
        "question": "What happens if a type cannot be inferred and is not explicitly annotated?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used to mark members as constant?": {
        "answer": "TheFinaltype constructor",
        "question": "What can be used to mark members as constant?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What happens if members are not marked constant?": {
        "answer": "If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute",
        "question": "What happens if members are not marked constant?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What opens opportunities for optimization if the value is known to be fixed?": {
        "answer": "UsingFinal",
        "question": "What opens opportunities for optimization if the value is known to be fixed?",
        "context": "TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the new API?": {
        "answer": "New API",
        "question": "What is the name of the new API?",
        "context": "TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is assumed to have typeTensor?": {
        "answer": "Containers",
        "question": "What is assumed to have typeTensor?",
        "context": "Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What was Torch.jit.annotate used to tell?": {
        "answer": "TorchScript compiler",
        "question": "What was Torch.jit.annotate used to tell?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are now supported?": {
        "answer": "Python 3 style type hints",
        "question": "What are now supported?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Containers are assumed to have what?": {
        "answer": "typeTensor",
        "question": "Containers are assumed to have what?",
        "context": "Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What compiler used Torch.jit.annotate?": {
        "answer": "TorchScript",
        "question": "What compiler used Torch.jit.annotate?",
        "context": "Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is now supported by TorchScript?": {
        "answer": "Python 3 style type hints",
        "question": "What is now supported by TorchScript?",
        "context": "Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What doesn't change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif": {
        "answer": "Functions",
        "question": "What doesn't change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif",
        "context": "Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What compiler was Torch.jit.annotate used to tell?": {
        "answer": "TorchScript",
        "question": "What compiler was Torch.jit.annotate used to tell?",
        "context": "Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is now supported?": {
        "answer": "Python 3 style type hints",
        "question": "What is now supported?",
        "context": "Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What compiler used Torch.jit.annotate to tell what type should be?": {
        "answer": "TorchScript",
        "question": "What compiler used Torch.jit.annotate to tell what type should be?",
        "context": "Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Alias fortorch.le stand for?": {
        "answer": "Alias fortorch.le",
        "question": "What does Alias fortorch.le stand for?",
        "context": "Alias fortorch.le(). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.less_equal.html#torch.less_equal"
    },
    "What creates a new tensor?": {
        "answer": "horizontally stacking the tensors intensors",
        "question": "What creates a new tensor?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors. Equivalent totorch.hstack(tensors), except each zero or one dimensional tensortintensorsis first reshaped into a(t.numel(),1)column before being stacked horizontally. tensors(sequence of Tensors) \u2013 sequence of tensors to concatenate out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.column_stack.html#torch.column_stack"
    },
    "What is each zero or one dimensional tensortintensors first reshaped into?": {
        "answer": "a(t.numel(),1)column",
        "question": "What is each zero or one dimensional tensortintensors first reshaped into?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors. Equivalent totorch.hstack(tensors), except each zero or one dimensional tensortintensorsis first reshaped into a(t.numel(),1)column before being stacked horizontally. tensors(sequence of Tensors) \u2013 sequence of tensors to concatenate out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.column_stack.html#torch.column_stack"
    },
    "What does tensors(sequence of Tensors) concatenate out(Tensor,optional": {
        "answer": "output tensor",
        "question": "What does tensors(sequence of Tensors) concatenate out(Tensor,optional",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors. Equivalent totorch.hstack(tensors), except each zero or one dimensional tensortintensorsis first reshaped into a(t.numel(),1)column before being stacked horizontally. tensors(sequence of Tensors) \u2013 sequence of tensors to concatenate out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.column_stack.html#torch.column_stack"
    },
    "What is the output tensor?": {
        "answer": "out(Tensor,optional) \u2013 the output tensor",
        "question": "What is the output tensor?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What type of tensor does ifobj return True?": {
        "answer": "PyTorch tensor",
        "question": "What type of tensor does ifobj return True?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What does ifobjis a PyTorch tensor return?": {
        "answer": "True",
        "question": "What does ifobjis a PyTorch tensor return?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What is the function that returns true ifobjis a PyTorch tensor?": {
        "answer": "doingisinstance",
        "question": "What is the function that returns true ifobjis a PyTorch tensor?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What is better for typechecking with mypy?": {
        "answer": "thatisinstancecheck",
        "question": "What is better for typechecking with mypy?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What is obj?": {
        "answer": "Object",
        "question": "What is obj?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What is the return value for ifobjis a PyTorch tensor?": {
        "answer": "True",
        "question": "What is the return value for ifobjis a PyTorch tensor?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What is the function that returns True ifobjis a PyTorch tensor?": {
        "answer": "doingisinstance(obj,Tensor)",
        "question": "What is the function that returns True ifobjis a PyTorch tensor?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What is thatisinstancecheck better for?": {
        "answer": "typechecking with mypy",
        "question": "What is thatisinstancecheck better for?",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "obj(obj,Tensor) \u2013 Object to test Example:": {
        "answer": "Object",
        "question": "obj(obj,Tensor) \u2013 Object to test Example:",
        "context": "Returns True ifobjis a PyTorch tensor. Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor. obj(Object) \u2013 Object to test Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor"
    },
    "What does set_flush_denormal() do?": {
        "answer": "Disables denormal floating numbers on CPU",
        "question": "What does set_flush_denormal() do?",
        "context": "Disables denormal floating numbers on CPU. ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3. mode(bool) \u2013 Controls whether to enable flush denormal mode or not Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal"
    },
    "If your system supports flushing denormal numbers and it successfully configures what?": {
        "answer": "flush denormal mode",
        "question": "If your system supports flushing denormal numbers and it successfully configures what?",
        "context": "Disables denormal floating numbers on CPU. ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3. mode(bool) \u2013 Controls whether to enable flush denormal mode or not Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal"
    },
    "On what architectures is set_flush_denormal() only supported?": {
        "answer": "x86 architectures",
        "question": "On what architectures is set_flush_denormal() only supported?",
        "context": "Disables denormal floating numbers on CPU. ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3. mode(bool) \u2013 Controls whether to enable flush denormal mode or not Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal"
    },
    "What controls whether to enable flush denormal mode or not?": {
        "answer": "mode(bool)",
        "question": "What controls whether to enable flush denormal mode or not?",
        "context": "Disables denormal floating numbers on CPU. ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3. mode(bool) \u2013 Controls whether to enable flush denormal mode or not Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal"
    },
    "What does set_flush_denormal() do on CPU?": {
        "answer": "Disables denormal floating numbers",
        "question": "What does set_flush_denormal() do on CPU?",
        "context": "Disables denormal floating numbers on CPU. ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3. mode(bool) \u2013 Controls whether to enable flush denormal mode or not Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal"
    },
    "ReturnsTrueif your system supports what?": {
        "answer": "flushing denormal numbers",
        "question": "ReturnsTrueif your system supports what?",
        "context": "Disables denormal floating numbers on CPU. ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3. mode(bool) \u2013 Controls whether to enable flush denormal mode or not Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal"
    },
    "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on what convention?": {
        "answer": "Einstein summation convention",
        "question": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on what convention?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "Sums the product of the elements of what dimension specified using a notation based on the Einstein summation convention?": {
        "answer": "inputoperandsalong",
        "question": "Sums the product of the elements of what dimension specified using a notation based on the Einstein summation convention?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What summation convention is used to sum the product of the elements of inputoperandsalong dimensions specified?": {
        "answer": "Einstein",
        "question": "What summation convention is used to sum the product of the elements of inputoperandsalong dimensions specified?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the name of the equation that is used to describe it?": {
        "answer": "Equation",
        "question": "What is the name of the equation that is used to describe it?",
        "context": "Equation: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the name of the Equation?": {
        "answer": "Equation",
        "question": "What is the name of the Equation?",
        "context": "Equation: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What can be added at the end of the equation to define the output subscripts?": {
        "answer": "an arrow",
        "question": "What can be added at the end of the equation to define the output subscripts?",
        "context": "Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is an example of an equation that can be explicitly defined by adding an arrow at the end of the equation followed by the subscripts for the": {
        "answer": "the following equation computes the transpose of a matrix multiplication",
        "question": "What is an example of an equation that can be explicitly defined by adding an arrow at the end of the equation followed by the subscripts for the",
        "context": "Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "How often must the output subscripts appear for some input operand?": {
        "answer": "at least once",
        "question": "How often must the output subscripts appear for some input operand?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "How can the output subscripts be explicitly defined?": {
        "answer": "by adding an arrow (\u2018->\u2019) at the end of the equation",
        "question": "How can the output subscripts be explicitly defined?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "The following equation computes the transpose of what?": {
        "answer": "matrix multiplication",
        "question": "The following equation computes the transpose of what?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What does torch.einsumhandle ellipsis differ from?": {
        "answer": "NumPy",
        "question": "What does torch.einsumhandle ellipsis differ from?",
        "context": "Note torch.einsumhandles ellipsis (\u2018\u2026\u2019) differently from NumPy in that it allows dimensions\ncovered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output. Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "Why does torch.einsum not optimize the given expression?": {
        "answer": "a different formula for the same computation may run faster or consume less memory",
        "question": "Why does torch.einsum not optimize the given expression?",
        "context": "torch.einsumhandles ellipsis (\u2018\u2026\u2019) differently from NumPy in that it allows dimensions\ncovered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output. Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What project can optimize the formula for you?": {
        "answer": "opt_einsum",
        "question": "What project can optimize the formula for you?",
        "context": "Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. operands(Tensor) \u2013 The operands to compute the Einstein sum of. Examples: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What does torch.einsum handle differently from NumPy?": {
        "answer": "ellipsis",
        "question": "What does torch.einsum handle differently from NumPy?",
        "context": "Note torch.einsumhandles ellipsis (\u2018\u2026\u2019) differently from NumPy in that it allows dimensions\ncovered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output. Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What does torch.einsum handle differently from NumPy in that it allows dimensions covered by the ellipsis to be summed": {
        "answer": "ellipsis",
        "question": "What does torch.einsum handle differently from NumPy in that it allows dimensions covered by the ellipsis to be summed",
        "context": "torch.einsumhandles ellipsis (\u2018\u2026\u2019) differently from NumPy in that it allows dimensions\ncovered by the ellipsis to be summed over, that is, ellipsis are not required to be part of the output. Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What are the subscripts for the Einstein summation?": {
        "answer": "equation(string)",
        "question": "What are the subscripts for the Einstein summation?",
        "context": "Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. operands(Tensor) \u2013 The operands to compute the Einstein sum of. Examples: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "Why does this function not optimize the given expression?": {
        "answer": "a different formula for the same computation may run faster or consume less memory",
        "question": "Why does this function not optimize the given expression?",
        "context": "Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. operands(Tensor) \u2013 The operands to compute the Einstein sum of. Examples: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What are the operands to compute the Einstein sum of?": {
        "answer": "operands",
        "question": "What are the operands to compute the Einstein sum of?",
        "context": "Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. operands(Tensor) \u2013 The operands to compute the Einstein sum of. Examples: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What are operands(Tensor) \u2013 The operands to compute the Einstein sum of?": {
        "answer": "Examples",
        "question": "What are operands(Tensor) \u2013 The operands to compute the Einstein sum of?",
        "context": "Note This function does not optimize the given expression, so a different formula for the same computation may\nrun faster or consume less memory. Projects like opt_einsum (https://optimized-einsum.readthedocs.io/en/stable/)\ncan optimize the formula for you. equation(string) \u2013 The subscripts for the Einstein summation. operands(Tensor) \u2013 The operands to compute the Einstein sum of. Examples: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "Computes what?": {
        "answer": "error function ofinput",
        "question": "Computes what?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "If one of the elements being compared is what, then that element is returned.maximum()is not supported for tensors with": {
        "answer": "a NaN",
        "question": "If one of the elements being compared is what, then that element is returned.maximum()is not supported for tensors with",
        "context": "Computes the element-wise maximum ofinputandother. Note If one of the elements being compared is a NaN, then that element is returned.maximum()is not supported for tensors with complex dtypes. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum"
    },
    "What is the second input tensor out(Tensor,optional) \u2013 the output tensor?": {
        "answer": "other(Tensor)",
        "question": "What is the second input tensor out(Tensor,optional) \u2013 the output tensor?",
        "context": "Computes the element-wise maximum ofinputandother. Note If one of the elements being compared is a NaN, then that element is returned.maximum()is not supported for tensors with complex dtypes. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum"
    },
    "What is an example of an output tensor?": {
        "answer": "Example",
        "question": "What is an example of an output tensor?",
        "context": "Computes the element-wise maximum ofinputandother. Note If one of the elements being compared is a NaN, then that element is returned.maximum()is not supported for tensors with complex dtypes. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum"
    },
    "What is the name of the window function?": {
        "answer": "Hamming",
        "question": "What is the name of the window function?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is NNN?": {
        "answer": "full window size",
        "question": "What is NNN?",
        "context": "whereNNNis the full window size. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the Bartlett window function?": {
        "answer": "full window size",
        "question": "What is the Bartlett window function?",
        "context": "Bartlett window function. whereNNNis the full window size. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "Where is the full window size?": {
        "answer": "whereNNNis the full window size",
        "question": "Where is the full window size?",
        "context": "whereNNNis the full window size. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is a positive integer controlling the returned window size?": {
        "answer": "inputwindow_lengthis",
        "question": "What is a positive integer controlling the returned window size?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is theNNNin above formula in factwindow_length+1textwindow_length + 1window_length+1": {
        "answer": "ifperiodicis true",
        "question": "What is theNNNin above formula in factwindow_length+1textwindow_length + 1window_length+1",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the same as totorch.bartlett_window(L+1,periodic=False)?": {
        "answer": "havetorch.bartlett_window",
        "question": "What is the same as totorch.bartlett_window(L+1,periodic=False)?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the size of the returned window periodic?": {
        "answer": "window_length(int)",
        "question": "What is the size of the returned window periodic?",
        "context": "Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "If True, return a symmetric window.": {
        "answer": "If False",
        "question": "If True, return a symmetric window.",
        "context": "Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the desired data type of returned tensor?": {
        "answer": "dtype",
        "question": "What is the desired data type of returned tensor?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What uses a global default?": {
        "answer": "ifNone",
        "question": "What uses a global default?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What type of windows are supported?": {
        "answer": "floating point types",
        "question": "What type of windows are supported?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the name of the window that contains a single value?": {
        "answer": "window_length",
        "question": "What is the name of the window that contains a single value?",
        "context": "Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "If False, return a window to be used as periodic function.": {
        "answer": "symmetric window",
        "question": "If False, return a window to be used as periodic function.",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What type of tensor type does ifNone use?": {
        "answer": "Default",
        "question": "What type of tensor type does ifNone use?",
        "context": "Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What type of tensors are supported?": {
        "answer": "floating point types",
        "question": "What type of tensors are supported?",
        "context": "Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What returns a symmetric window?": {
        "answer": "If False",
        "question": "What returns a symmetric window?",
        "context": "periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the size of returned window periodic?": {
        "answer": "window_length",
        "question": "What is the size of returned window periodic?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "If True, return a symmetric window?": {
        "answer": "If False",
        "question": "If True, return a symmetric window?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What type of window types are supported?": {
        "answer": "floating point types",
        "question": "What type of window types are supported?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the desired layout of returned window tensor?": {
        "answer": "layout",
        "question": "What is the desired layout of returned window tensor?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What type of layout is supported?": {
        "answer": "Onlytorch.strided",
        "question": "What type of layout is supported?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What returns a window to be used as periodic function?": {
        "answer": "If True",
        "question": "What returns a window to be used as periodic function?",
        "context": "periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What types are supported only?": {
        "answer": "floating point types",
        "question": "What types are supported only?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is supported for dense layout?": {
        "answer": "Onlytorch.strided",
        "question": "What is supported for dense layout?",
        "context": "layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the desired device of returned tensor?": {
        "answer": "device(torch.device, optional)",
        "question": "What is the desired device of returned tensor?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What default uses the current device for the default tensor type?": {
        "answer": "ifNone",
        "question": "What default uses the current device for the default tensor type?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What should record operations on the returned tensor?": {
        "answer": "autograd",
        "question": "What should record operations on the returned tensor?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the default value for autograd to record operations on the returned tensor?": {
        "answer": "Default:False",
        "question": "What is the default value for autograd to record operations on the returned tensor?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "A 1-D tensor of size(window_length,)(textwindow_length,)(window_": {
        "answer": "window Tensor",
        "question": "A 1-D tensor of size(window_length,)(textwindow_length,)(window_",
        "context": "device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What does ifNone use for the default tensor type?": {
        "answer": "current device",
        "question": "What does ifNone use for the default tensor type?",
        "context": "end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default setting for autograd to record operations on the returned tensor?": {
        "answer": "False",
        "question": "What is the default setting for autograd to record operations on the returned tensor?",
        "context": "device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is a window Tensor of size(window_length,)(textwindow_length,)(wind": {
        "answer": "1-D tensor",
        "question": "What is a window Tensor of size(window_length,)(textwindow_length,)(wind",
        "context": "device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "Returns what of a given tensor?": {
        "answer": "matrix norm or vector norm",
        "question": "Returns what of a given tensor?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is deprecated and may be removed in a future PyTorch release?": {
        "answer": "torch.norm",
        "question": "What is deprecated and may be removed in a future PyTorch release?",
        "context": "torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is used when computing vector norms?": {
        "answer": "ortorch.linalg.vector_norm()",
        "question": "What is used when computing vector norms?",
        "context": "Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the signature for these functions?": {
        "answer": "slightly different",
        "question": "What is the signature for these functions?",
        "context": "Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What function is used when computing vector norms?": {
        "answer": "ortorch.linalg.vector_norm()",
        "question": "What function is used when computing vector norms?",
        "context": "Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What does ortorch.linalg.matrix_norm() do?": {
        "answer": "matrix norms",
        "question": "What does ortorch.linalg.matrix_norm() do?",
        "context": "torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "How different is the signature for these functions from the signature for torch.norm?": {
        "answer": "slightly different",
        "question": "How different is the signature for these functions from the signature for torch.norm?",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. keepdim(bool,optional) \u2013 whether the output tensors havedimretained or not. Ignored ifdim=Noneandout=None. Default:False out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What function does usetorch.linalg.norm() instead of torch.norm?": {
        "answer": "ortorch.linalg.vector_norm()",
        "question": "What function does usetorch.linalg.norm() instead of torch.norm?",
        "context": "torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the name of the input tensor?": {
        "answer": "input(Tensor)",
        "question": "What is the name of the input tensor?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What type of data type must the input tensor have?": {
        "answer": "floating point or complex type",
        "question": "What type of data type must the input tensor have?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "How is the norm calculated for complex inputs?": {
        "answer": "the absolute value of each element",
        "question": "How is the norm calculated for complex inputs?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will be the corresponding what?": {
        "answer": "floating point type",
        "question": "If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will be the corresponding what?",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. keepdim(bool,optional) \u2013 whether the output tensors havedimretained or not. Ignored ifdim=Noneandout=None. Default:False out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "If input is complex and neitherdtypenoroutis specified, the result's data type will be the corresponding floating point type (e.": {
        "answer": "ifinputis complexfloat",
        "question": "If input is complex and neitherdtypenoroutis specified, the result's data type will be the corresponding floating point type (e.",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is p(int,float,inf,-inf,'fro','nuc',optional)?": {
        "answer": "the order of norm",
        "question": "What is p(int,float,inf,-inf,'fro','nuc',optional)?",
        "context": "p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What are the following norms that can be calculated?": {
        "answer": "ord matrix norm vector norm \u2019fro\u2019",
        "question": "What are the following norms that can be calculated?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What does p(int,float,inf,-inf,'fro','nuc',optional',": {
        "answer": "the order of norm",
        "question": "What does p(int,float,inf,-inf,'fro','nuc',optional',",
        "context": "p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the default order of norms?": {
        "answer": "Default:'fro'",
        "question": "What is the default order of norms?",
        "context": "the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "The corresponding dimensions of input are what?": {
        "answer": "flattened",
        "question": "The corresponding dimensions of input are what?",
        "context": "matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the name of the norm that can be calculated?": {
        "answer": "Frobenius norm",
        "question": "What is the name of the norm that can be calculated?",
        "context": "p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "The corresponding dimensions of inputare what?": {
        "answer": "flattened",
        "question": "The corresponding dimensions of inputare what?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the name of the order in which a norm can be calculated?": {
        "answer": "order of norm",
        "question": "What is the name of the order in which a norm can be calculated?",
        "context": "the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the vector norm 'fro'?": {
        "answer": "matrix norm",
        "question": "What is the vector norm 'fro'?",
        "context": "matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the order of norms?": {
        "answer": "order of norm",
        "question": "What is the order of norms?",
        "context": "the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the ord matrix norm vector norm?": {
        "answer": "fro",
        "question": "What is the ord matrix norm vector norm?",
        "context": "ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "When does Frobenius norm throw an error?": {
        "answer": "whendimis a list of three or more dims",
        "question": "When does Frobenius norm throw an error?",
        "context": "Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the vector norm fro?": {
        "answer": "ord matrix norm",
        "question": "What is the vector norm fro?",
        "context": "ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What produces the same result asp=2 in all cases except whendimis a list of three or more dims?": {
        "answer": "Frobenius norm",
        "question": "What produces the same result asp=2 in all cases except whendimis a list of three or more dims?",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. keepdim(bool,optional) \u2013 whether the output tensors havedimretained or not. Ignored ifdim=Noneandout=None. Default:False out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What can be calculated across any number of dimensions?": {
        "answer": "vector norm",
        "question": "What can be calculated across any number of dimensions?",
        "context": "The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What happens to the corresponding dimensions of input?": {
        "answer": "flattened",
        "question": "What happens to the corresponding dimensions of input?",
        "context": "the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "Nuclear norm can only be calculated across exactly how many dimensions?": {
        "answer": "two",
        "question": "Nuclear norm can only be calculated across exactly how many dimensions?",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. keepdim(bool,optional) \u2013 whether the output tensors havedimretained or not. Ignored ifdim=Noneandout=None. Default:False out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "The vector norm can be calculated across what?": {
        "answer": "any number of dimensions",
        "question": "The vector norm can be calculated across what?",
        "context": "sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "Nuclear norm can only be calculated across what?": {
        "answer": "exactly two dimensions",
        "question": "Nuclear norm can only be calculated across what?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the Frobenius norm?": {
        "answer": "fro",
        "question": "What is the Frobenius norm?",
        "context": "\u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What does nuclear norm stand for?": {
        "answer": "Number",
        "question": "What does nuclear norm stand for?",
        "context": "\u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What case does Frobenius norm throw an error?": {
        "answer": "whendimis a list of three or more dims",
        "question": "What case does Frobenius norm throw an error?",
        "context": "\u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is nuclear norm?": {
        "answer": "Number",
        "question": "What is nuclear norm?",
        "context": "nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is Number \u2013 sum(abs(x)**ord)**(1./ord))?": {
        "answer": "nuclear norm",
        "question": "What is Number \u2013 sum(abs(x)**ord)**(1./ord))?",
        "context": "nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the value of the vector norm?": {
        "answer": "Number",
        "question": "What is the value of the vector norm?",
        "context": "\u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What can only be calculated across exactly two dimensions?": {
        "answer": "Nuclear norm",
        "question": "What can only be calculated across exactly two dimensions?",
        "context": "Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the vector norm calculated across any number of dimensions?": {
        "answer": "sum(abs(x)**ord)**(1./ord)",
        "question": "What is the vector norm calculated across any number of dimensions?",
        "context": "sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the sum of the vector norm?": {
        "answer": "sum(abs(x)**ord)**(1./ord)",
        "question": "What is the sum of the vector norm?",
        "context": "\u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is out(Tensor,optional)?": {
        "answer": "output tensor",
        "question": "What is out(Tensor,optional)?",
        "context": "Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the output tensor ignored?": {
        "answer": "ifdim=None",
        "question": "What is the output tensor ignored?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. dtype(torch.dtype, optional) \u2013 the desired data type of\nreturned tensor. If specified, the input tensor is casted to\n:attr:\u2019dtype\u2019 while performing the operation. Default: None. Note ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the input tensor casted to when performing the operation?": {
        "answer": ":attr:\u2019dtype\u2019",
        "question": "What is the input tensor casted to when performing the operation?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. dtype(torch.dtype, optional) \u2013 the desired data type of\nreturned tensor. If specified, the input tensor is casted to\n:attr:\u2019dtype\u2019 while performing the operation. Default: None. Note ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the default value of the input tensor?": {
        "answer": "Default:None",
        "question": "What is the default value of the input tensor?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "dtype(torch.dtype, optional) \u2013 what?": {
        "answer": "desired data type of returned tensor",
        "question": "dtype(torch.dtype, optional) \u2013 what?",
        "context": "out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "If specified, the input tensor is casted to what?": {
        "answer": ":attr:\u2019dtype\u2019",
        "question": "If specified, the input tensor is casted to what?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of\nreturned tensor. If specified, the input tensor is casted to\n:attr:\u2019dtype\u2019 while performing the operation. Default: None. Note Even thoughp='fro'supports any number of dimensions, the true\nmathematical definition of Frobenius norm only applies to tensors with\nexactly two dimensions.torch.linalg.norm()withord='fro'aligns\nwith the mathematical definition, since it can only be applied across\nexactly two dimensions. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What applies only to tensors with exactly two dimensions?": {
        "answer": "Frobenius norm",
        "question": "What applies only to tensors with exactly two dimensions?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of\nreturned tensor. If specified, the input tensor is casted to\n:attr:\u2019dtype\u2019 while performing the operation. Default: None. Note Even thoughp='fro'supports any number of dimensions, the true\nmathematical definition of Frobenius norm only applies to tensors with\nexactly two dimensions.torch.linalg.norm()withord='fro'aligns\nwith the mathematical definition, since it can only be applied across\nexactly two dimensions. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is an example of a tensor that can only be applied across exactly two dimensions?": {
        "answer": "Example",
        "question": "What is an example of a tensor that can only be applied across exactly two dimensions?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of\nreturned tensor. If specified, the input tensor is casted to\n:attr:\u2019dtype\u2019 while performing the operation. Default: None. Note Even thoughp='fro'supports any number of dimensions, the true\nmathematical definition of Frobenius norm only applies to tensors with\nexactly two dimensions.torch.linalg.norm()withord='fro'aligns\nwith the mathematical definition, since it can only be applied across\nexactly two dimensions. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the tensor filled with?": {
        "answer": "random integers",
        "question": "What is the tensor filled with?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a sequence of integers defining the shape of the output tensor?": {
        "answer": "size",
        "question": "What is a sequence of integers defining the shape of the output tensor?",
        "context": "size(int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "Can be a variable number of arguments or what?": {
        "answer": "a collection like a list or tuple",
        "question": "Can be a variable number of arguments or what?",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined\nby the variable argumentsize. size(int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "Out(Tensor,optional) - what does out(Tensor,optional) return?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) - what does out(Tensor,optional) return?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "Returns a tensor filled with what value?": {
        "answer": "scalar value1",
        "question": "Returns a tensor filled with what value?",
        "context": "Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What defines the shape of the output tensor?": {
        "answer": "size",
        "question": "What defines the shape of the output tensor?",
        "context": "size(int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "What can size(int...) be?": {
        "answer": "a variable number of arguments or a collection like a list or tuple",
        "question": "What can size(int...) be?",
        "context": "size(int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "What can size(int) be?": {
        "answer": "a variable number of arguments",
        "question": "What can size(int) be?",
        "context": "size(int...) \u2013 a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "Out(Tensor,optional) - what does out(Tensor,optional) refer to?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) - what does out(Tensor,optional) refer to?",
        "context": "out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the desired layout of returned Tensor?": {
        "answer": "layout",
        "question": "What is the desired layout of returned Tensor?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default for the layout of the returned Tensor?": {
        "answer": "Default:torch.strided",
        "question": "What is the default for the layout of the returned Tensor?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default layout of returned tensor?": {
        "answer": "Default:torch.strided",
        "question": "What is the default layout of returned tensor?",
        "context": "end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "Out(Tensor,optional) - what does out(Tensor,optional) contain?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) - what does out(Tensor,optional) contain?",
        "context": "out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "What is the default layout of the returned Tensor?": {
        "answer": "Default:torch.strided",
        "question": "What is the default layout of the returned Tensor?",
        "context": "out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "What is the default layout of returned Tensor?": {
        "answer": "Default:torch.strided",
        "question": "What is the default layout of returned Tensor?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default type of returned tensor?": {
        "answer": "Default",
        "question": "What is the default type of returned tensor?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros"
    },
    "What does Alias fortorch.atanh do?": {
        "answer": "Alias fortorch.atanh()",
        "question": "What does Alias fortorch.atanh do?",
        "context": "Alias fortorch.atanh(). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arctanh.html#torch.arctanh"
    },
    "What is the name of the website that provides information about Alias fortorch.atanh?": {
        "answer": "Alias fortorch.atanh",
        "question": "What is the name of the website that provides information about Alias fortorch.atanh?",
        "context": "Alias fortorch.atanh(). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arctanh.html#torch.arctanh"
    },
    "What happens if an element ininputevaluates toTrue?": {
        "answer": "Tests",
        "question": "What happens if an element ininputevaluates toTrue?",
        "context": "Tests if any element ininputevaluates toTrue. Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "This function matches the behavior of what function?": {
        "answer": "NumPy",
        "question": "This function matches the behavior of what function?",
        "context": "Tests if any element ininputevaluates toTrue. Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What is the dtype of output foruint8?": {
        "answer": "Foruint8the dtype of output isuint8itself",
        "question": "What is the dtype of output foruint8?",
        "context": "input(Tensor) \u2013 the input tensor. Tests if any element ininputevaluates toTrue. Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What is returned for each row of inputin the given dimensiondim?": {
        "answer": "returnsTrueif any element in the row evaluate toTrueandFalseotherwise",
        "question": "What is returned for each row of inputin the given dimensiondim?",
        "context": "input(Tensor) \u2013 the input tensor. Tests if any element ininputevaluates toTrue. Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What does input(Tensor) do?": {
        "answer": "Tests if any element ininputevaluates toTrue",
        "question": "What does input(Tensor) do?",
        "context": "input(Tensor) \u2013 the input tensor. Tests if any element ininputevaluates toTrue. Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "This function matches the behaviour of what function in returning output of dtypebool for all supported dtypes exceptuint8?": {
        "answer": "NumPy",
        "question": "This function matches the behaviour of what function in returning output of dtypebool for all supported dtypes exceptuint8?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What is the dtype of output?": {
        "answer": "isuint8itself",
        "question": "What is the dtype of output?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What does the function return if any element in the row evaluate toTrueandFalseotherwise?": {
        "answer": "returnsTrue",
        "question": "What does the function return if any element in the row evaluate toTrueandFalseotherwise?",
        "context": "input(Tensor) \u2013 the input tensor. Tests if any element ininputevaluates toTrue. Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What is the dtype of foruint8?": {
        "answer": "output isuint8itself",
        "question": "What is the dtype of foruint8?",
        "context": "Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What does the function return for each row ofinputin the given dimensiondim?": {
        "answer": "Trueif any element in the row evaluate toTrueandFalseotherwise",
        "question": "What does the function return for each row ofinputin the given dimensiondim?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What function returns output of dtypebool for all supported dtypes exceptuint8?": {
        "answer": "NumPy",
        "question": "What function returns output of dtypebool for all supported dtypes exceptuint8?",
        "context": "Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What does the function return for each row of inputin the given dimensiondim?": {
        "answer": "Trueif any element in the row evaluate toTrueandFalseotherwise",
        "question": "What does the function return for each row of inputin the given dimensiondim?",
        "context": "Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "For each row of inputin the given dimensiondim, returns what?": {
        "answer": "Trueif any element in the row evaluate toTrueandFalseotherwise",
        "question": "For each row of inputin the given dimensiondim, returns what?",
        "context": "Note This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "Which function returns output of dtypebool for all supported dtypes exceptuint8?": {
        "answer": "NumPy",
        "question": "Which function returns output of dtypebool for all supported dtypes exceptuint8?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What does this function match the behaviour of NumPy in returning output of dtypeboolfor all supported dtypes exceptuin": {
        "answer": "Foruint8the dtype of output isuint8itself",
        "question": "What does this function match the behaviour of NumPy in returning output of dtypeboolfor all supported dtypes exceptuin",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What function returns the output tensor of the same size asinput?": {
        "answer": "IfkeepdimisTrue",
        "question": "What function returns the output tensor of the same size asinput?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "If keepdimisTrue, the output tensor has what?": {
        "answer": "1 fewer dimension thaninput",
        "question": "If keepdimisTrue, the output tensor has what?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "For each row ofinputin the given dimensiondim, returns what?": {
        "answer": "Trueif any element in the row evaluate toTrueandFalseotherwise",
        "question": "For each row ofinputin the given dimensiondim, returns what?",
        "context": "For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What function ensures that the output tensor is of the same size as input except in the dimensiondim where it is of size 1?": {
        "answer": "IfkeepdimisTrue",
        "question": "What function ensures that the output tensor is of the same size as input except in the dimensiondim where it is of size 1?",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "If keepdimisTrue, the output tensor is of the same size asinput except in the dimensiondimwhere it is": {
        "answer": "1 fewer dimension",
        "question": "If keepdimisTrue, the output tensor is of the same size asinput except in the dimensiondimwhere it is",
        "context": "This function matches the behaviour of NumPy in returning\noutput of dtypeboolfor all supported dtypes exceptuint8.\nForuint8the dtype of output isuint8itself. Example: For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "Where is the output tensor of the same size asinput except in the dimensiondim?": {
        "answer": "size 1",
        "question": "Where is the output tensor of the same size asinput except in the dimensiondim?",
        "context": "For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What happens if the output tensor is squeezed?": {
        "answer": "1 fewer dimension thaninput",
        "question": "What happens if the output tensor is squeezed?",
        "context": "For each row ofinputin the given dimensiondim,\nreturnsTrueif any element in the row evaluate toTrueandFalseotherwise. IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any"
    },
    "What is the dimension to reduce?": {
        "answer": "dim(int)",
        "question": "What is the dimension to reduce?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What determines whether the output tensor hasdimretained or not?": {
        "answer": "keepdim(bool)",
        "question": "What determines whether the output tensor hasdimretained or not?",
        "context": "By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is the library part of?": {
        "answer": "thePyTorchproject",
        "question": "What is the library part of?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What is PyTorch?": {
        "answer": "open source machine learning framework",
        "question": "What is PyTorch?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What is the release status of PyTorch?": {
        "answer": "Stable",
        "question": "What is the release status of PyTorch?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What does PyTorch expect to maintain?": {
        "answer": "backwards compatibility",
        "question": "What does PyTorch expect to maintain?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What project is this library part of?": {
        "answer": "thePyTorchproject",
        "question": "What project is this library part of?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What type of machine learning framework is PyTorch?": {
        "answer": "open source",
        "question": "What type of machine learning framework is PyTorch?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What is the release status of the features described in this documentation?": {
        "answer": "Stable",
        "question": "What is the release status of the features described in this documentation?",
        "context": "Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What do we expect to maintain?": {
        "answer": "backwards compatibility",
        "question": "What do we expect to maintain?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What is the release status of features described in this documentation?": {
        "answer": "Stable",
        "question": "What is the release status of features described in this documentation?",
        "context": "Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What type of features will be maintained long-term?": {
        "answer": "Stable",
        "question": "What type of features will be maintained long-term?",
        "context": "Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "How long will these features be maintained?": {
        "answer": "long-term",
        "question": "How long will these features be maintained?",
        "context": "Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "Why are features tagged as Beta?": {
        "answer": "the performance needs to improve",
        "question": "Why are features tagged as Beta?",
        "context": "Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What classification do we commit to seeing a feature through to?": {
        "answer": "Stable",
        "question": "What classification do we commit to seeing a feature through to?",
        "context": "Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What are we not committing to?": {
        "answer": "backwards compatibility",
        "question": "What are we not committing to?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What may the API change based on?": {
        "answer": "user feedback",
        "question": "What may the API change based on?",
        "context": "Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What classification are Beta features committed to seeing through?": {
        "answer": "Stable",
        "question": "What classification are Beta features committed to seeing through?",
        "context": "Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "We are not committing to what?": {
        "answer": "backwards compatibility",
        "question": "We are not committing to what?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What are features sometimes hidden behind?": {
        "answer": "run-time flags",
        "question": "What are features sometimes hidden behind?",
        "context": "Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What are features at an early stage for?": {
        "answer": "feedback and testing",
        "question": "What are features at an early stage for?",
        "context": "Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "Thetorchaudiopackage consists of I/O, common audio transformations, and what?": {
        "answer": "popular datasets",
        "question": "Thetorchaudiopackage consists of I/O, common audio transformations, and what?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What does Thetorchaudiopackage consist of?": {
        "answer": "Package Reference PyTorch Libraries",
        "question": "What does Thetorchaudiopackage consist of?",
        "context": "Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What are PyPI and Conda features sometimes hidden behind?": {
        "answer": "run-time flags",
        "question": "What are PyPI and Conda features sometimes hidden behind?",
        "context": "Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What consists of I/O, popular datasets and common audio transformations?": {
        "answer": "Thetorchaudiopackage",
        "question": "What consists of I/O, popular datasets and common audio transformations?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What libraries are included in Thetorchaudiopackage?": {
        "answer": "Package Reference PyTorch Libraries",
        "question": "What libraries are included in Thetorchaudiopackage?",
        "context": "Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What is the LU solve of the linear systemAx=bAx = bAx=busing?": {
        "answer": "LU factorization of A fromtorch.lu()",
        "question": "What is the LU solve of the linear systemAx=bAx = bAx=busing?",
        "context": "Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted\nLU factorization of A fromtorch.lu(). This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What types of types does this function support?": {
        "answer": "float,double,cfloatandcdoubledtypes forinput",
        "question": "What types of types does this function support?",
        "context": "Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted\nLU factorization of A fromtorch.lu(). This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What is the RHS tensor of size(,m,k)(*, m, k)(,m": {
        "answer": "b(Tensor)",
        "question": "What is the RHS tensor of size(,m,k)(*, m, k)(,m",
        "context": "b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. LU_pivots(IntTensor) \u2013 the pivots of the LU factorization fromtorch.lu()of size(\u2217,m)(*, m)(\u2217,m),\nwhere\u2217*\u2217is zero or more batch dimensions.\nThe batch dimensions ofLU_pivotsmust be equal to the batch dimensions ofLU_data. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What is the pivoted LU factorization of A fromtorch.lu()?": {
        "answer": "LU_data(Tensor)",
        "question": "What is the pivoted LU factorization of A fromtorch.lu()?",
        "context": "Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted\nLU factorization of A fromtorch.lu(). This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "Returns what of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A": {
        "answer": "LU solve",
        "question": "Returns what of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "This function supports float,double, and what other type of input?": {
        "answer": "cfloat",
        "question": "This function supports float,double, and what other type of input?",
        "context": "Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted\nLU factorization of A fromtorch.lu(). This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What types of input does this function support?": {
        "answer": "float,double,cfloatandcdoubledtypes",
        "question": "What types of input does this function support?",
        "context": "This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What does LU_data(Tensor) do?": {
        "answer": "LU factorization",
        "question": "What does LU_data(Tensor) do?",
        "context": "This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What type of input does this function support?": {
        "answer": "forinput",
        "question": "What type of input does this function support?",
        "context": "This function supportsfloat,double,cfloatandcdoubledtypes forinput. b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What is the pivoted LU factorization of A fromtorch.lu()of size(,m,m)(*,": {
        "answer": "LU_data",
        "question": "What is the pivoted LU factorization of A fromtorch.lu()of size(,m,m)(*,",
        "context": "b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. LU_pivots(IntTensor) \u2013 the pivots of the LU factorization fromtorch.lu()of size(\u2217,m)(*, m)(\u2217,m),\nwhere\u2217*\u2217is zero or more batch dimensions.\nThe batch dimensions ofLU_pivotsmust be equal to the batch dimensions ofLU_data. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What are the pivots of the LU factorization fromtorch.lu()of size(,m)(*, m": {
        "answer": "LU_pivots",
        "question": "What are the pivots of the LU factorization fromtorch.lu()of size(,m)(*, m",
        "context": "b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. LU_pivots(IntTensor) \u2013 the pivots of the LU factorization fromtorch.lu()of size(\u2217,m)(*, m)(\u2217,m),\nwhere\u2217*\u2217is zero or more batch dimensions.\nThe batch dimensions ofLU_pivotsmust be equal to the batch dimensions ofLU_data. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What must the batch dimensions ofLU_pivots be equal to?": {
        "answer": "the batch dimensions ofLU_data",
        "question": "What must the batch dimensions ofLU_pivots be equal to?",
        "context": "b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. LU_pivots(IntTensor) \u2013 the pivots of the LU factorization fromtorch.lu()of size(\u2217,m)(*, m)(\u2217,m),\nwhere\u2217*\u2217is zero or more batch dimensions.\nThe batch dimensions ofLU_pivotsmust be equal to the batch dimensions ofLU_data. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "What must be the batch dimensions of LU_pivots be to the batch dimensions of LU_data?": {
        "answer": "equal",
        "question": "What must be the batch dimensions of LU_pivots be to the batch dimensions of LU_data?",
        "context": "b(Tensor) \u2013 the RHS tensor of size(\u2217,m,k)(*, m, k)(\u2217,m,k), where\u2217*\u2217is zero or more batch dimensions. LU_data(Tensor) \u2013 the pivoted LU factorization of A fromtorch.lu()of size(\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere\u2217*\u2217is zero or more batch dimensions. LU_pivots(IntTensor) \u2013 the pivots of the LU factorization fromtorch.lu()of size(\u2217,m)(*, m)(\u2217,m),\nwhere\u2217*\u2217is zero or more batch dimensions.\nThe batch dimensions ofLU_pivotsmust be equal to the batch dimensions ofLU_data. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve"
    },
    "Out(Tensor,optional) \u2013 what?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) \u2013 what?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Returns the indices that sort a tensor along a given dimension in what order?": {
        "answer": "ascending order by value",
        "question": "Returns the indices that sort a tensor along a given dimension in what order?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What is the second value returned?": {
        "answer": "bytorch.sort()",
        "question": "What is the second value returned?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What does the documentation of bytorch.sort() provide?": {
        "answer": "exact semantics",
        "question": "What does the documentation of bytorch.sort() provide?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What is the dimension to sort along descending?": {
        "answer": "dim(int,optional)",
        "question": "What is the dimension to sort along descending?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What is returned bytorch.sort()?": {
        "answer": "second value",
        "question": "What is returned bytorch.sort()?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What do you need to know about the second value returned bytorch.sort()?": {
        "answer": "semantics",
        "question": "What do you need to know about the second value returned bytorch.sort()?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What is the dimension to sort along descending(bool,optional)?": {
        "answer": "dim(int,optional)",
        "question": "What is the dimension to sort along descending(bool,optional)?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending\norder by value. This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method. input(Tensor) \u2013 the input tensor. dim(int,optional) \u2013 the dimension to sort along descending(bool,optional) \u2013 controls the sorting order (ascending or descending) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort"
    },
    "What returns the cumulative maximum of elements of input in the dimensiondim?": {
        "answer": "a namedtuple",
        "question": "What returns the cumulative maximum of elements of input in the dimensiondim?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of\nelements ofinputin the dimensiondim. Andindicesis the index\nlocation of each maximum value found in the dimensiondim. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to do the operation over out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cummax.html#torch.cummax"
    },
    "What is the index location of each maximum value found in the dimensiondim?": {
        "answer": "Andindices",
        "question": "What is the index location of each maximum value found in the dimensiondim?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of\nelements ofinputin the dimensiondim. Andindicesis the index\nlocation of each maximum value found in the dimensiondim. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to do the operation over out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cummin.html#torch.cummin"
    },
    "What is the dimension to do the operation over out(tuple,optional)?": {
        "answer": "dim(int)",
        "question": "What is the dimension to do the operation over out(tuple,optional)?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of\nelements ofinputin the dimensiondim. Andindicesis the index\nlocation of each maximum value found in the dimensiondim. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to do the operation over out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cummin.html#torch.cummin"
    },
    "What is the output specified by for a 3-D tensor?": {
        "answer": "inputandindexmust have the same number of dimensions",
        "question": "What is the output specified by for a 3-D tensor?",
        "context": "Gathers values along an axis specified bydim. For a 3-D tensor the output is specified by: inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other. input(Tensor) \u2013 the source tensor dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to gather sparse_grad(bool,optional) \u2013 IfTrue, gradient w.r.t.inputwill be a sparse tensor. out(Tensor,optional) \u2013 the destination tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather"
    },
    "Do inputandindexdo broadcast against each other?": {
        "answer": "not broadcast against each other",
        "question": "Do inputandindexdo broadcast against each other?",
        "context": "Gathers values along an axis specified bydim. For a 3-D tensor the output is specified by: inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other. input(Tensor) \u2013 the source tensor dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to gather sparse_grad(bool,optional) \u2013 IfTrue, gradient w.r.t.inputwill be a sparse tensor. out(Tensor,optional) \u2013 the destination tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather"
    },
    "What does index(LongTensor) contain?": {
        "answer": "indices of elements to gather sparse_grad(bool,optional)",
        "question": "What does index(LongTensor) contain?",
        "context": "Gathers values along an axis specified bydim. For a 3-D tensor the output is specified by: inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other. input(Tensor) \u2013 the source tensor dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to gather sparse_grad(bool,optional) \u2013 IfTrue, gradient w.r.t.inputwill be a sparse tensor. out(Tensor,optional) \u2013 the destination tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather"
    },
    "What must have the same number of dimensions?": {
        "answer": "inputandindex",
        "question": "What must have the same number of dimensions?",
        "context": "inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other. input(Tensor) \u2013 the source tensor dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to gather sparse_grad(bool,optional) \u2013 IfTrue, gradient w.r.t.inputwill be a sparse tensor. out(Tensor,optional) \u2013 the destination tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather"
    },
    "What is the destination tensor?": {
        "answer": "out",
        "question": "What is the destination tensor?",
        "context": "Gathers values along an axis specified bydim. For a 3-D tensor the output is specified by: inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other. input(Tensor) \u2013 the source tensor dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to gather sparse_grad(bool,optional) \u2013 IfTrue, gradient w.r.t.inputwill be a sparse tensor. out(Tensor,optional) \u2013 the destination tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather"
    },
    "What type of elements represent if each element of input is real-valued or not?": {
        "answer": "boolean elements",
        "question": "What type of elements represent if each element of input is real-valued or not?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "What is a boolean tensor?": {
        "answer": "All real-valued types are considered real",
        "question": "What is a boolean tensor?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "What is the default value of a boolean tensor?": {
        "answer": "True",
        "question": "What is the default value of a boolean tensor?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "Returns a new tensor with boolean elements representing what?": {
        "answer": "if each element ofinputis real-valued or not",
        "question": "Returns a new tensor with boolean elements representing what?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "What type of values are considered real?": {
        "answer": "real",
        "question": "What type of values are considered real?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "When are complex values considered real?": {
        "answer": "when their imaginary part is 0. input(Tensor) \u2013 the input tensor",
        "question": "When are complex values considered real?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "What is a boolean tensor that is whereinputis real and False elsewhere?": {
        "answer": "True",
        "question": "What is a boolean tensor that is whereinputis real and False elsewhere?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.\nAll real-valued types are considered real. Complex values are considered real when their imaginary part is 0. input(Tensor) \u2013 the input tensor. A boolean tensor that is True whereinputis real and False elsewhere Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal"
    },
    "What is nonlinearity gain?": {
        "answer": "nonlinearity gain Linear / Identity",
        "question": "What is nonlinearity gain?",
        "context": "nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What gain Linear / Identity 111 Conv1,2,3D 111 Tanh 53frac5335 Re": {
        "answer": "nonlinearity",
        "question": "What gain Linear / Identity 111 Conv1,2,3D 111 Tanh 53frac5335 Re",
        "context": "nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the 111 Sigmoid?": {
        "answer": "111 Tanh",
        "question": "What is the name of the 111 Sigmoid?",
        "context": "gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the definition of Identity 111 Conv1,2,3D 111 Tanh 53frac5335 ReLU": {
        "answer": "Linear",
        "question": "What is the definition of Identity 111 Conv1,2,3D 111 Tanh 53frac5335 ReLU",
        "context": "Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the 111 Tanh?": {
        "answer": "111 Sigmoid",
        "question": "What is the name of the 111 Tanh?",
        "context": "111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is 111 Tanh?": {
        "answer": "111 Tanh",
        "question": "What is 111 Tanh?",
        "context": "111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the number of the Leaky Relu 2sqrt22 Leaky Relu?": {
        "answer": "111 Tanh",
        "question": "What is the number of the Leaky Relu 2sqrt22 Leaky Relu?",
        "context": "111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "How many Tanhs are there?": {
        "answer": "111",
        "question": "How many Tanhs are there?",
        "context": "111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What should you use in order to implementSelf-Normalizing Neural Networks?": {
        "answer": "'linear'",
        "question": "What should you use in order to implementSelf-Normalizing Neural Networks?",
        "context": "34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does this give the initial weights?": {
        "answer": "variance of1/N",
        "question": "What does this give the initial weights?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does the default gain forSELUsacrifice?": {
        "answer": "normalisation effect",
        "question": "What does the default gain forSELUsacrifice?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the 2sqrt22?": {
        "answer": "Leaky Relu",
        "question": "What is the name of the 2sqrt22?",
        "context": "2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does the default gain forSELU sacrifice for more stable gradient flow in rectangular layers?": {
        "answer": "normalisation effect",
        "question": "What does the default gain forSELU sacrifice for more stable gradient flow in rectangular layers?",
        "context": "21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does the default gain forSELUsacrifice for more stable gradient flow in rectangular layers?": {
        "answer": "the default gain forSELUsacrifices the normalisation effect",
        "question": "What does the default gain forSELUsacrifice for more stable gradient flow in rectangular layers?",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is 21+negative_slope2sqrtfrac21 + textnegative_slope": {
        "answer": "Leaky Relu",
        "question": "What is 21+negative_slope2sqrtfrac21 + textnegative_slope",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the relu that is 21+negative_slope2sqrtfrac21 +": {
        "answer": "Leaky Relu",
        "question": "What is the name of the relu that is 21+negative_slope2sqrtfrac21 +",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the default gain forSELUsacrifices the normalisation effect for more stable gradient flow in rectangular layers?": {
        "answer": "linear",
        "question": "What is the default gain forSELUsacrifices the normalisation effect for more stable gradient flow in rectangular layers?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the initial weights' variance?": {
        "answer": "variance of1/N",
        "question": "What is the initial weights' variance?",
        "context": "In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the optional parameter for the non-linear function?": {
        "answer": "param",
        "question": "What is the optional parameter for the non-linear function?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the optional parameter for the non-linear function Examples?": {
        "answer": "nonlinearity",
        "question": "What is the optional parameter for the non-linear function Examples?",
        "context": "In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the default gain for forSELUsacrifices the normalisation effect for more stable gradient flow in rectangular layers?": {
        "answer": "selu",
        "question": "What is the default gain for forSELUsacrifices the normalisation effect for more stable gradient flow in rectangular layers?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the variance of the initial weights?": {
        "answer": "variance of1/N",
        "question": "What is the variance of the initial weights?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the non-linear function param?": {
        "answer": "optional parameter",
        "question": "What is the non-linear function param?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "In order to implementSelf-Normalizing Neural Networks, you should use what?": {
        "answer": "linear",
        "question": "In order to implementSelf-Normalizing Neural Networks, you should use what?",
        "context": "In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the non-linear function?": {
        "answer": "nonlinearity",
        "question": "What is the non-linear function?",
        "context": "nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is an n-dimensionaltorch?": {
        "answer": "tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor",
        "question": "What is an n-dimensionaltorch?",
        "context": "val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is a tensor?": {
        "answer": "an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor",
        "question": "What is a tensor?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is param for the non-linear function?": {
        "answer": "optional parameter",
        "question": "What is param for the non-linear function?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Param is what type of parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform distribution?": {
        "answer": "optional",
        "question": "Param is what type of parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform distribution?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What type of torch is a tensor?": {
        "answer": "2-dimensional",
        "question": "What type of torch is a tensor?",
        "context": "Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the input Tensor filled with values drawn from?": {
        "answer": "the uniform distribution",
        "question": "What is the input Tensor filled with values drawn from?",
        "context": "Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the uniform distributionU?": {
        "answer": "a,b",
        "question": "What is the uniform distributionU?",
        "context": "Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the mean of the normal distribution std?": {
        "answer": "standard deviation of the normal distribution",
        "question": "What is the mean of the normal distribution std?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the input Tensor with values drawn from what?": {
        "answer": "the uniform distribution",
        "question": "Fills the input Tensor with values drawn from what?",
        "context": "Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does a tensor represent?": {
        "answer": "a\u2013 the lower bound of the uniform distribution",
        "question": "What does a tensor represent?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does std stand for?": {
        "answer": "the standard deviation of the normal distribution",
        "question": "What does std stand for?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the upper bound of the uniform distribution?": {
        "answer": "b",
        "question": "What is the upper bound of the uniform distribution?",
        "context": "b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the value to fill the tensor with?": {
        "answer": "val",
        "question": "What is the value to fill the tensor with?",
        "context": "val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the value to fill the tensor with Examples?": {
        "answer": "an n-dimensionaltorch.Tensor val",
        "question": "What is the value to fill the tensor with Examples?",
        "context": "b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "b\u2013 what is the upper bound of the uniform distribution?": {
        "answer": "the upper bound",
        "question": "b\u2013 what is the upper bound of the uniform distribution?",
        "context": "b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What do examples fill the input Tensor with values drawn from?": {
        "answer": "the normal distribution",
        "question": "What do examples fill the input Tensor with values drawn from?",
        "context": "Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the standard deviation of the normal distribution?": {
        "answer": "std",
        "question": "What is the standard deviation of the normal distribution?",
        "context": "std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the input Tensor with values drawn from what distribution?": {
        "answer": "normal distribution",
        "question": "Fills the input Tensor with values drawn from what distribution?",
        "context": "Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the input Tensor with what value1?": {
        "answer": "scalar",
        "question": "Fills the input Tensor with what value1?",
        "context": "Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does a tensor fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What value does a tensor fill the input Tensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the mean of the normal distribution?": {
        "answer": "mean",
        "question": "What is the mean of the normal distribution?",
        "context": "mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does the input Tensor fill with?": {
        "answer": "scalar",
        "question": "What value does the input Tensor fill with?",
        "context": "std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does a tensor do when as many inputs are preserved as possible?": {
        "answer": "Preserves the identity of the inputs inLinearlayers",
        "question": "What does a tensor do when as many inputs are preserved as possible?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does Tensor val fill the input Tensor with?": {
        "answer": "scalar value",
        "question": "What value does Tensor val fill the input Tensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the 2-dimensional inputTensorwith what?": {
        "answer": "identity matrix",
        "question": "Fills the 2-dimensional inputTensorwith what?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does a tensor do inLinearlayers?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does a tensor do inLinearlayers?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the function that preserves the identity of the inputs inLinearlayers?": {
        "answer": "Preserves the identity of the inputs inLinearlayers",
        "question": "What is the function that preserves the identity of the inputs inLinearlayers?",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Linearlayers do?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does Linearlayers do?",
        "context": "val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the input Tensor filled with?": {
        "answer": "scalar value0",
        "question": "What is the input Tensor filled with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does a tensor do that allows as many inputs to be preserved as possible?": {
        "answer": "Preserves the identity of the inputs inLinearlayers",
        "question": "What does a tensor do that allows as many inputs to be preserved as possible?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Examples Fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What does Examples Fill the input Tensor with?",
        "context": "Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does filling the 2-dimensional inputTensor do?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does filling the 2-dimensional inputTensor do?",
        "context": "Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the input Tensor with what value?": {
        "answer": "scalar value1",
        "question": "Fills the input Tensor with what value?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does filling the 2-dimensional inputTensor with the identity matrix do?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does filling the 2-dimensional inputTensor with the identity matrix do?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does tensor fill the 2-dimensional inputTensor with?": {
        "answer": "the identity matrix",
        "question": "What does tensor fill the 2-dimensional inputTensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does tensor do?": {
        "answer": "Fills the input Tensor with the scalar value0",
        "question": "What does tensor do?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does tensor do inLinearlayers?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does tensor do inLinearlayers?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Examples fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What does Examples fill the input Tensor with?",
        "context": "Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Filling the 2-dimensional inputTensor with the identity matrix do?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does Filling the 2-dimensional inputTensor with the identity matrix do?",
        "context": "Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What dimension is a tensor?": {
        "answer": "n-dimensional",
        "question": "What dimension is a tensor?",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is tensor?": {
        "answer": "an n-dimensionaltorch.Tensor Examples",
        "question": "What is tensor?",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "InLinearlayers, where as many inputs are preserved, what does Fills the 2-dimensional inputTensorwith the identity matrix?": {
        "answer": "Preserves the identity of the inputs",
        "question": "InLinearlayers, where as many inputs are preserved, what does Fills the 2-dimensional inputTensorwith the identity matrix?",
        "context": "Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What reduces the amount of matrix multiplications in a batch matrix-matrix product?": {
        "answer": "add step",
        "question": "What reduces the amount of matrix multiplications in a batch matrix-matrix product?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What must batch1andbatch2 be?": {
        "answer": "3-D tensors",
        "question": "What must batch1andbatch2 be?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What happens in a reduced add step?": {
        "answer": "all matrix multiplications get accumulated along the first dimension",
        "question": "What happens in a reduced add step?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "Batch1andbatch2must be what?": {
        "answer": "3-D tensors",
        "question": "Batch1andbatch2must be what?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What must batch1 and batch2 be?": {
        "answer": "3-D tensors",
        "question": "What must batch1 and batch2 be?",
        "context": "batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What is a(bnm)(b times n times m)(bn": {
        "answer": "Ifbatch1",
        "question": "What is a(bnm)(b times n times m)(bn",
        "context": "Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "If input is ignored, andnanandinfin it will not be propagated, what is it?": {
        "answer": "Ifbetais 0,",
        "question": "If input is ignored, andnanandinfin it will not be propagated, what is it?",
        "context": "batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "Argumentsbetaandalphamust be real numbers, otherwise they should be what?": {
        "answer": "integers",
        "question": "Argumentsbetaandalphamust be real numbers, otherwise they should be what?",
        "context": "batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "Which inputs will not be propagated ifbetais 0?": {
        "answer": "andnanandinfin",
        "question": "Which inputs will not be propagated ifbetais 0?",
        "context": "Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "For inputs of typeFloatTensororDoubleTensor, what must be?": {
        "answer": "argumentsbetaandalphamust be real numbers",
        "question": "For inputs of typeFloatTensororDoubleTensor, what must be?",
        "context": "Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What does this operator support?": {
        "answer": "This operator supportsTensorFloat32",
        "question": "What does this operator support?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "If input is ignored, andnanandinfin it will not be propagated?": {
        "answer": "Ifbetais 0,",
        "question": "If input is ignored, andnanandinfin it will not be propagated?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be what": {
        "answer": "real numbers",
        "question": "For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be what",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "If input is ignored, what is it?": {
        "answer": "Ifbetais 0,",
        "question": "If input is ignored, what is it?",
        "context": "Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What must argumentsbeta andalpha be for inputs of typeFloatTensororDoubleTensor?": {
        "answer": "argumentsbetaandalphamust be real numbers",
        "question": "What must argumentsbeta andalpha be for inputs of typeFloatTensororDoubleTensor?",
        "context": "Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What is the first batch of matrices to be multiplied?": {
        "answer": "batch1",
        "question": "What is the first batch of matrices to be multiplied?",
        "context": "For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "If input is ignored, andnanandinfin it will not be propagated.": {
        "answer": "Ifbetais 0,",
        "question": "If input is ignored, andnanandinfin it will not be propagated.",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What is the name of the Moore-Penrose inverse?": {
        "answer": "pseudoinverse",
        "question": "What is the name of the Moore-Penrose inverse?",
        "context": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the most computationally convenient way to understand the pseudoinverse?": {
        "answer": "SVD",
        "question": "What is the most computationally convenient way to understand the pseudoinverse?",
        "context": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does the SVD support?": {
        "answer": "batches of matrices",
        "question": "What does the SVD support?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does the Moon-Penrose inverse stand for?": {
        "answer": "the pseudoinverse",
        "question": "What does the Moon-Penrose inverse stand for?",
        "context": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "The pseudoinverse is more computationally convenient to understand through what?": {
        "answer": "SVD",
        "question": "The pseudoinverse is more computationally convenient to understand through what?",
        "context": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What supports input of float, double, cfloat, and cdouble dtypes?": {
        "answer": "SVD",
        "question": "What supports input of float, double, cfloat, and cdouble dtypes?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Ifhermitian= what is assumed to be Hermitian if complex or symmetric if real?": {
        "answer": "True",
        "question": "Ifhermitian= what is assumed to be Hermitian if complex or symmetric if real?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What part of the matrix is used in computations?": {
        "answer": "lower triangular part of the matrix",
        "question": "What part of the matrix is used in computations?",
        "context": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is assumed to be Hermitian if complex or symmetric if real?": {
        "answer": "Ifhermitian= True",
        "question": "What is assumed to be Hermitian if complex or symmetric if real?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Supports input of what types of input?": {
        "answer": "float, double, cfloat and cdouble dtypes",
        "question": "Supports input of what types of input?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What type of matrices does Ais support?": {
        "answer": "batches of matrices",
        "question": "What type of matrices does Ais support?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Ifhermitian= what, is Ais assumed to be Hermitian if complex or symmetric if real?": {
        "answer": "True",
        "question": "Ifhermitian= what, is Ais assumed to be Hermitian if complex or symmetric if real?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What part of the matrix is used instead of Hermitian?": {
        "answer": "lower triangular part of the matrix",
        "question": "What part of the matrix is used instead of Hermitian?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Supports input of float, double, cfloat and what other dtype?": {
        "answer": "cdouble",
        "question": "Supports input of float, double, cfloat and what other dtype?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Supports input of float, double, cfloat and cdouble dtypes. Also supports what?": {
        "answer": "batches of matrices",
        "question": "Supports input of float, double, cfloat and cdouble dtypes. Also supports what?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "The singular values below the specifiedrcondthreshold are treated as what?": {
        "answer": "zero",
        "question": "The singular values below the specifiedrcondthreshold are treated as what?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What should be done to the singular values that are below the specifiedrcondthreshold?": {
        "answer": "Note",
        "question": "What should be done to the singular values that are below the specifiedrcondthreshold?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is assumed to be if complex or symmetric if real?": {
        "answer": "Hermitian",
        "question": "What is assumed to be if complex or symmetric if real?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What values that are below the specifiedrcondthreshold are treated as zero and discarded in the computation?": {
        "answer": "The singular values",
        "question": "What values that are below the specifiedrcondthreshold are treated as zero and discarded in the computation?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the difference between the singular values and the norm of the eigenvalues whenhermitian= True?": {
        "answer": "Note",
        "question": "What is the difference between the singular values and the norm of the eigenvalues whenhermitian= True?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What are the singular values that are below the specifiedrcondthreshold treated as?": {
        "answer": "zero",
        "question": "What are the singular values that are below the specifiedrcondthreshold treated as?",
        "context": "The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does the function usestorch.linalg.svd() if?": {
        "answer": "True",
        "question": "What does the function usestorch.linalg.svd() if?",
        "context": "The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does this function synchronize with the CPU for?": {
        "answer": "CUDA inputs",
        "question": "What does this function synchronize with the CPU for?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is a matrix on the left multiplied by?": {
        "answer": "the pseudoinverse",
        "question": "What is a matrix on the left multiplied by?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What function synchronizes a CUDA input with the CPU?": {
        "answer": "usestorch.linalg.svd()ifhermitian= False",
        "question": "What function synchronizes a CUDA input with the CPU?",
        "context": "The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does this function synchronize with the CPU?": {
        "answer": "CUDA inputs",
        "question": "What does this function synchronize with the CPU?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What function is used for multiplying a matrix on the left by the pseudoinverse?": {
        "answer": "usingtorch.linalg.lstsq()if possible",
        "question": "What function is used for multiplying a matrix on the left by the pseudoinverse?",
        "context": "The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does the function usestorch.linalg.svd() ifhermitian= False?": {
        "answer": "True",
        "question": "What does the function usestorch.linalg.svd() ifhermitian= False?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Why is it always preferable to uselstsq()?": {
        "answer": "faster and more numerically stable",
        "question": "Why is it always preferable to uselstsq()?",
        "context": "This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is a warning about usinglstsq()?": {
        "answer": "Warning",
        "question": "What is a warning about usinglstsq()?",
        "context": "Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the name of the function used to synchronize a CUDA input with the CPU?": {
        "answer": "Warning",
        "question": "What is the name of the function used to synchronize a CUDA input with the CPU?",
        "context": "This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does torch.linalg.inv() compute?": {
        "answer": "the inverse of a square matrix",
        "question": "What does torch.linalg.inv() compute?",
        "context": "torch.linalg.inv()computes the inverse of a square matrix. torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does torch.linalg.lstsq()computesA.pinv() @Bwith?": {
        "answer": "numerically stable algorithm",
        "question": "What does torch.linalg.lstsq()computesA.pinv() @Bwith?",
        "context": "torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. hermitian(bool,optional) \u2013 indicates whetherAis Hermitian if complex\nor symmetric if real. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the tensor of shape where*is zero or more batch dimensions?": {
        "answer": "A(Tensor)",
        "question": "What is the tensor of shape where*is zero or more batch dimensions?",
        "context": "torch.linalg.inv()computes the inverse of a square matrix. torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the tolerance value to determine when is a singular value zero?": {
        "answer": "rcond",
        "question": "What is the tolerance value to determine when is a singular value zero?",
        "context": "torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. hermitian(bool,optional) \u2013 indicates whetherAis Hermitian if complex\nor symmetric if real. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the default value of atorch.Tensor?": {
        "answer": "1e-15",
        "question": "What is the default value of atorch.Tensor?",
        "context": "See also torch.linalg.inv()computes the inverse of a square matrix. torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What computes the inverse of a square matrix?": {
        "answer": "torch.linalg.inv()",
        "question": "What computes the inverse of a square matrix?",
        "context": "See also torch.linalg.inv()computes the inverse of a square matrix. torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the tensor of shape(*, m, n)where*is zero or more batch dimensions?": {
        "answer": "A(Tensor)",
        "question": "What is the tensor of shape(*, m, n)where*is zero or more batch dimensions?",
        "context": "torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. hermitian(bool,optional) \u2013 indicates whetherAis Hermitian if complex\nor symmetric if real. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the default value for atorch.Tensor?": {
        "answer": "Default:1e-15",
        "question": "What is the default value for atorch.Tensor?",
        "context": "torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. hermitian(bool,optional) \u2013 indicates whetherAis Hermitian if complex\nor symmetric if real. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does torch.linalg.inv() compute of a square matrix?": {
        "answer": "inverse",
        "question": "What does torch.linalg.inv() compute of a square matrix?",
        "context": "torch.linalg.inv()computes the inverse of a square matrix. torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the default value of the atorch.Tensor?": {
        "answer": "1e-15",
        "question": "What is the default value of the atorch.Tensor?",
        "context": "torch.linalg.inv()computes the inverse of a square matrix. torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does hermitian indicate if complex or symmetric if real?": {
        "answer": "Hermitian",
        "question": "What does hermitian indicate if complex or symmetric if real?",
        "context": "torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. hermitian(bool,optional) \u2013 indicates whetherAis Hermitian if complex\nor symmetric if real. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the default value of Hermitian?": {
        "answer": "False",
        "question": "What is the default value of Hermitian?",
        "context": "torch.linalg.lstsq()computesA.pinv() @Bwith a\nnumerically stable algorithm. A(Tensor) \u2013 tensor of shape(*, m, n)where*is zero or more batch dimensions. rcond(floatorTensor,optional) \u2013 the tolerance value to determine when is a singular value zero\nIf it is atorch.Tensor, its shape must be\nbroadcastable to that of the singular values ofAas returned bytorch.svd().\nDefault:1e-15. hermitian(bool,optional) \u2013 indicates whetherAis Hermitian if complex\nor symmetric if real. Default:False. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What returns the cumulative minimum of elements of input in the dimensiondim?": {
        "answer": "a namedtuple",
        "question": "What returns the cumulative minimum of elements of input in the dimensiondim?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of\nelements ofinputin the dimensiondim. Andindicesis the index\nlocation of each maximum value found in the dimensiondim. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to do the operation over out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cummin.html#torch.cummin"
    },
    "What returns the mode value of each row of theinputtensor in the given dimensiondim?": {
        "answer": "a namedtuple(values,indices)",
        "question": "What returns the mode value of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Indicesis what of each mode value found?": {
        "answer": "index location",
        "question": "Indicesis what of each mode value found?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "By default,dimis is what?": {
        "answer": "the last dimension of theinputtensor",
        "question": "By default,dimis is what?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What returns the mode value of each row of the inputtensor in the given dimensiondim?": {
        "answer": "a namedtuple",
        "question": "What returns the mode value of each row of the inputtensor in the given dimensiondim?",
        "context": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How often does a value appear in a given row of theinputtensor?": {
        "answer": "most often",
        "question": "How often does a value appear in a given row of theinputtensor?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "By default,dimis the what dimension of theinputtensor?": {
        "answer": "last dimension",
        "question": "By default,dimis the what dimension of theinputtensor?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "By default,dimis the last dimension of what?": {
        "answer": "theinputtensor",
        "question": "By default,dimis the last dimension of what?",
        "context": "By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "When are the output tensors of the same size asinput except in the dimensiondimwhere they are of size 1?": {
        "answer": "IfkeepdimisTrue",
        "question": "When are the output tensors of the same size asinput except in the dimensiondimwhere they are of size 1?",
        "context": "By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is the result of the output tensors being squeezed?": {
        "answer": "1 fewer dimension thaninput",
        "question": "What is the result of the output tensors being squeezed?",
        "context": "IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "Where is this function not defined?": {
        "answer": "fortorch.cuda.Tensoryet",
        "question": "Where is this function not defined?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "By default,dimis what dimension of the inputtensor?": {
        "answer": "last dimension",
        "question": "By default,dimis what dimension of the inputtensor?",
        "context": "By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "In what case are output tensors of the same size as input except in the dimensiondimwhere they are of size 1?": {
        "answer": "IfkeepdimisTrue",
        "question": "In what case are output tensors of the same size as input except in the dimensiondimwhere they are of size 1?",
        "context": "By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is another name for squeezed output tensors?": {
        "answer": "seetorch.squeeze()",
        "question": "What is another name for squeezed output tensors?",
        "context": "By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "Note This function is not defined what?": {
        "answer": "fortorch.cuda.Tensoryet",
        "question": "Note This function is not defined what?",
        "context": "IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is the name of the function that determines whether the output tensor hasdimretained or not?": {
        "answer": "keepdim",
        "question": "What is the name of the function that determines whether the output tensor hasdimretained or not?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "When are output tensors of the same size as input?": {
        "answer": "IfkeepdimisTrue",
        "question": "When are output tensors of the same size as input?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is the result tuple of two output tensors?": {
        "answer": "out(tuple,optional)",
        "question": "What is the result tuple of two output tensors?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What makes the output tensors of the same size as input except in the dimensiondimwhere they are of size 1?": {
        "answer": "IfkeepdimisTrue",
        "question": "What makes the output tensors of the same size as input except in the dimensiondimwhere they are of size 1?",
        "context": "IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is the name of the function that results in the output tensors having 1 fewer dimension than input?": {
        "answer": "seetorch.squeeze()",
        "question": "What is the name of the function that results in the output tensors having 1 fewer dimension than input?",
        "context": "IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "This function is not defined what?": {
        "answer": "fortorch.cuda.Tensoryet",
        "question": "This function is not defined what?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is this function not defined?": {
        "answer": "fortorch.cuda.Tensoryet",
        "question": "What is this function not defined?",
        "context": "Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "Out(tuple,optional) is the result tuple of two what?": {
        "answer": "output tensors",
        "question": "Out(tuple,optional) is the result tuple of two what?",
        "context": "Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What website does Alias fortorch.ne belong to?": {
        "answer": "Alias fortorch.ne",
        "question": "What website does Alias fortorch.ne belong to?",
        "context": "Alias fortorch.ne(). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.not_equal.html#torch.not_equal"
    },
    "What is the name of the website?": {
        "answer": "Alias fortorch.ne",
        "question": "What is the name of the website?",
        "context": "Alias fortorch.ne(). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.not_equal.html#torch.not_equal"
    },
    "What does optimizer_class(torch.nn.Optimizer) contain?": {
        "answer": "the class of the local optimizer",
        "question": "What does optimizer_class(torch.nn.Optimizer) contain?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the local optimizer?": {
        "answer": "group",
        "question": "What is the name of the local optimizer?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a bool for when parameters are packed into larger buckets?": {
        "answer": "parameters_as_bucket_views",
        "question": "What is a bool for when parameters are packed into larger buckets?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What will remain intact when disabled?": {
        "answer": "butparams.data",
        "question": "What will remain intact when disabled?",
        "context": "parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Param.datafields will point to what at different offsets?": {
        "answer": "bucket views",
        "question": "Param.datafields will point to what at different offsets?",
        "context": "parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What will be forwarded to the given optimizer?": {
        "answer": "all trailing arguments",
        "question": "What will be forwarded to the given optimizer?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is an example of how to add a param group to theOptimizersparam_groups?": {
        "answer": "Add a param group to theOptimizersparam_groups",
        "question": "What is an example of how to add a param group to theOptimizersparam_groups?",
        "context": "parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What can be useful when fine tuning a pre-trained network?": {
        "answer": "Add a param group to theOptimizersparam_groups",
        "question": "What can be useful when fine tuning a pre-trained network?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What can be made trainable and added to theOptimizeras training progresses?": {
        "answer": "frozen layers",
        "question": "What can be made trainable and added to theOptimizeras training progresses?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does param_group(dict) specify?": {
        "answer": "Tensors",
        "question": "What does param_group(dict) specify?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many consolidated state_dicts are there per rank?": {
        "answer": "one",
        "question": "How many consolidated state_dicts are there per rank?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is to(int)?": {
        "answer": "the rank that receives the global states",
        "question": "What is to(int)?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the default value for the rank that receives the global states?": {
        "answer": "0",
        "question": "What is the default value for the rank that receives the global states?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What can be made trainable by adding a param group to theOptimizersparam_groups?": {
        "answer": "frozen layers",
        "question": "What can be made trainable by adding a param group to theOptimizersparam_groups?",
        "context": "**default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What Specifies what Tensors should be optimized along with group specific optimization options?": {
        "answer": "param_group(dict)",
        "question": "What Specifies what Tensors should be optimized along with group specific optimization options?",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many consolidated state_dicts are updated per rank?": {
        "answer": "one per rank",
        "question": "How many consolidated state_dicts are updated per rank?",
        "context": "This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the rank that receives the global states?": {
        "answer": "to(int)",
        "question": "What is the rank that receives the global states?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many states does the consolidated state_dict list update?": {
        "answer": "one per rank",
        "question": "How many states does the consolidated state_dict list update?",
        "context": "Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "To(int) \u2013 the rank that receives the global states. (default: what) Restore the global parameter groups as well as the": {
        "answer": "0",
        "question": "To(int) \u2013 the rank that receives the global states. (default: what) Restore the global parameter groups as well as the",
        "context": "to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many consolidated state_dicts does theOptimizersparam_groups update?": {
        "answer": "one per rank",
        "question": "How many consolidated state_dicts does theOptimizersparam_groups update?",
        "context": "Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does param_group(dict) do?": {
        "answer": "Specifies what Tensors should be optimized along with group specific optimization options",
        "question": "What does param_group(dict) do?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the default value for global parameter groups?": {
        "answer": "0",
        "question": "What is the default value for global parameter groups?",
        "context": "This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the default value for the rank that receives global states?": {
        "answer": "0",
        "question": "What is the default value for the rank that receives global states?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does state_dict(dict) contain?": {
        "answer": "optimizer state",
        "question": "What does state_dict(dict) contain?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the call that returns the state of the optimizer?": {
        "answer": "tostate_dict()",
        "question": "What is the name of the call that returns the state of the optimizer?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the state of the optimizer?": {
        "answer": "state of the optimizer as adict",
        "question": "What is the state of the optimizer?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many entries does the state of the optimizer as adict contain?": {
        "answer": "two",
        "question": "How many entries does the state of the optimizer as adict contain?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a dict containing all parameter groups?": {
        "answer": "param_groups",
        "question": "What is a dict containing all parameter groups?",
        "context": "Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a dict containing all parameter groups Partitions parameters across distributed data parallel ranks?": {
        "answer": "param_groups",
        "question": "What is a dict containing all parameter groups Partitions parameters across distributed data parallel ranks?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is state_dict(dict)?": {
        "answer": "optimizer state",
        "question": "What is state_dict(dict)?",
        "context": "to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Should be an object returned from a call from what?": {
        "answer": "tostate_dict()",
        "question": "Should be an object returned from a call from what?",
        "context": "to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many entries does the state of the optimizer contain?": {
        "answer": "two",
        "question": "How many entries does the state of the optimizer contain?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Restore the global parameter groups as well as what else?": {
        "answer": "shard",
        "question": "Restore the global parameter groups as well as what else?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What dict contains all parameter groups Partitions parameters across distributed data parallel ranks?": {
        "answer": "param_groups",
        "question": "What dict contains all parameter groups Partitions parameters across distributed data parallel ranks?",
        "context": "Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Restore what as well as the shard?": {
        "answer": "global parameter groups",
        "question": "Restore what as well as the shard?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the optimizer state?": {
        "answer": "state_dict(dict)",
        "question": "What is the name of the optimizer state?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does state_dict(dict) represent?": {
        "answer": "optimizer state",
        "question": "What does state_dict(dict) represent?",
        "context": "parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Should be an object returned from a call to what?": {
        "answer": "state_dict()",
        "question": "Should be an object returned from a call to what?",
        "context": "state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the state of the optimizer as adict?": {
        "answer": "Gets this rank\u2019sstate_dict",
        "question": "What is the state of the optimizer as adict?",
        "context": "Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a list of dict?": {
        "answer": "a list ofparam_groups",
        "question": "What is a list of dict?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Which element corresponds to rank 0, etc.?": {
        "answer": "Element 0",
        "question": "Which element corresponds to rank 0, etc.?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "We need all the ranks for the broadcast what?": {
        "answer": "insidestep()",
        "question": "We need all the ranks for the broadcast what?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does insidestep return for a given rank?": {
        "answer": "local_state_dict",
        "question": "What does insidestep return for a given rank?",
        "context": "Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a list of dicts?": {
        "answer": "a list ofparam_groups",
        "question": "What is a list of dicts?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Element 0 corresponds to what rank?": {
        "answer": "rank 0,",
        "question": "Element 0 corresponds to what rank?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the broadcast we need all the ranks for?": {
        "answer": "insidestep()",
        "question": "What is the name of the broadcast we need all the ranks for?",
        "context": "param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does insidestep() return for a given rank?": {
        "answer": "local_state_dict",
        "question": "What does insidestep() return for a given rank?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "We need all the ranks for the broadcast for what?": {
        "answer": "insidestep()",
        "question": "We need all the ranks for the broadcast for what?",
        "context": " The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does param_groups contain across distributed data parallel ranks?": {
        "answer": "Partitions parameters",
        "question": "What does param_groups contain across distributed data parallel ranks?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does rank(int) return?": {
        "answer": "getlocal_state_dictfor",
        "question": "What does rank(int) return?",
        "context": "The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the function that returns the local_state_dict for a given rank?": {
        "answer": "insidestep()",
        "question": "What is the name of the function that returns the local_state_dict for a given rank?",
        "context": "param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the rank to getlocal_state_dictfor?": {
        "answer": "rank",
        "question": "What is the name of the rank to getlocal_state_dictfor?",
        "context": "The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What differs between?": {
        "answer": "optimizer classes",
        "question": "What differs between?",
        "context": "differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "A list ofparam_groups is a list of what?": {
        "answer": "dict",
        "question": "A list ofparam_groups is a list of what?",
        "context": "Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What corresponds to rank 0, etc.?": {
        "answer": "Element 0",
        "question": "What corresponds to rank 0, etc.?",
        "context": "This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does state_dict(dict) return?": {
        "answer": "globalstate_dict",
        "question": "What does state_dict(dict) return?",
        "context": "param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What class differs between param_groups and param_groups?": {
        "answer": "optimizer classes",
        "question": "What class differs between param_groups and param_groups?",
        "context": "differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does getlocal_state_dict for state_dict(dict) return?": {
        "answer": "globalstate_dict",
        "question": "What does getlocal_state_dict for state_dict(dict) return?",
        "context": "param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Param_groups contains all parameter groups across distributed data parallel ranks.": {
        "answer": "Partitions parameters",
        "question": "Param_groups contains all parameter groups across distributed data parallel ranks.",
        "context": "param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Which element of the list corresponds to rank 0, etc.?": {
        "answer": "Element 0",
        "question": "Which element of the list corresponds to rank 0, etc.?",
        "context": "param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does getlocal_state_dictfor state_dict(dict) return?": {
        "answer": "globalstate_dict",
        "question": "What does getlocal_state_dictfor state_dict(dict) return?",
        "context": "param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a part of distributed data parallel ranks?": {
        "answer": "Partitions parameters",
        "question": "What is a part of distributed data parallel ranks?",
        "context": "Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Globalstate_dict consist of a list of what?": {
        "answer": "shards",
        "question": "Globalstate_dict consist of a list of what?",
        "context": "Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Partitions parameters across distributed data what?": {
        "answer": "parallel ranks",
        "question": "Partitions parameters across distributed data what?",
        "context": "Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What function returns the local_state_dict for a given rank?": {
        "answer": "insidestep()",
        "question": "What function returns the local_state_dict for a given rank?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the globalstate_dict?": {
        "answer": "last known global optimizer state",
        "question": "What is the globalstate_dict?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a single optimization step called?": {
        "answer": "parameter update",
        "question": "What is a single optimization step called?",
        "context": "Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is returned for a given rank?": {
        "answer": "local_state_dict",
        "question": "What is returned for a given rank?",
        "context": "Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the name of the rank to getlocal_state_dict for state_dict(dict)?": {
        "answer": "rank",
        "question": "What is the name of the rank to getlocal_state_dict for state_dict(dict)?",
        "context": "Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the last known global optimizer state?": {
        "answer": "globalstate_dict",
        "question": "What is the last known global optimizer state?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a closure that reevaluates the model and returns the loss?": {
        "answer": "closure",
        "question": "What is a closure that reevaluates the model and returns the loss?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What type of loss depends on the underlying optimizer?": {
        "answer": "Optional",
        "question": "What type of loss depends on the underlying optimizer?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does optional loss depend on?": {
        "answer": "underlying optimizer",
        "question": "What does optional loss depend on?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is expected to be the inverse ofstft()?": {
        "answer": "Inverse short time Fourier Transform",
        "question": "What is expected to be the inverse ofstft()?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Inverse short time Fourier Transform is expected to be the inverse of what?": {
        "answer": "ofstft()",
        "question": "Inverse short time Fourier Transform is expected to be the inverse of what?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What should the Inverse short time Fourier Transform return?": {
        "answer": "least squares estimation",
        "question": "What should the Inverse short time Fourier Transform return?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What condition will the algorithm check using?": {
        "answer": "NOLA condition",
        "question": "What condition will the algorithm check using?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the envelop created by?": {
        "answer": "the summation of all the windows",
        "question": "What is the envelop created by?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the envelop created by the summation of all the windows at a certain point in time?": {
        "answer": "0",
        "question": "What is the envelop created by the summation of all the windows at a certain point in time?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Why does stft return a shorter signal than the original signal?": {
        "answer": "Sincestft()discards elements at the end of the signal if they do not fit in a frame",
        "question": "Why does stft return a shorter signal than the original signal?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the envelop created by the summation of all windows at certain point in time?": {
        "answer": "never zero",
        "question": "What is the envelop created by the summation of all windows at certain point in time?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the envelop created by the summation of all windows never zero at certain point in time?": {
        "answer": "0",
        "question": "What is the envelop created by the summation of all windows never zero at certain point in time?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "If the signal isn\u2019t padded, what can result in a shorter signal than the original signal?": {
        "answer": "ifcenteris False",
        "question": "If the signal isn\u2019t padded, what can result in a shorter signal than the original signal?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What discards elements at the end of the signal if they do not fit in a frame?": {
        "answer": "Sincestft()",
        "question": "What discards elements at the end of the signal if they do not fit in a frame?",
        "context": "Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "If the signal isn't padded, what happens?": {
        "answer": "IfcenterisTrue",
        "question": "If the signal isn't padded, what happens?",
        "context": "Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "IfcenterisTrue, there will be padding e.g. what?": {
        "answer": "constant",
        "question": "IfcenterisTrue, there will be padding e.g. what?",
        "context": "Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What can be trimmed off exactly because they can be calculated?": {
        "answer": "Left padding",
        "question": "What can be trimmed off exactly because they can be calculated?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "If the signal isn't padded, what can result in a shorter signal than the original signal?": {
        "answer": "ifcenteris False",
        "question": "If the signal isn't padded, what can result in a shorter signal than the original signal?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "If centeris False, then there will be padding e.g. 'constant','reflect', etc.": {
        "answer": "IfcenterisTrue",
        "question": "If centeris False, then there will be padding e.g. 'constant','reflect', etc.",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "IfcenterisTrue, then there will be padding e.g.'reflect','reflect', etc.": {
        "answer": "constant",
        "question": "IfcenterisTrue, then there will be padding e.g.'reflect','reflect', etc.",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Why can left padding be trimmed off exactly?": {
        "answer": "because they can be calculated",
        "question": "Why can left padding be trimmed off exactly?",
        "context": "IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the last window of a signal?": {
        "answer": "last window",
        "question": "What is the last window of a signal?",
        "context": "Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "If there is padding, what is it called?": {
        "answer": "IfcenterisTrue",
        "question": "If there is padding, what is it called?",
        "context": "IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "If centerisTrue, then there will be padding e.g.'reflect','reflect', etc.": {
        "answer": "constant",
        "question": "If centerisTrue, then there will be padding e.g.'reflect','reflect', etc.",
        "context": "IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default setting for padding?": {
        "answer": "IfcenterisTrue",
        "question": "What is the default setting for padding?",
        "context": "IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the last window in a window?": {
        "answer": "last",
        "question": "What is the last window in a window?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Who wrote \"Signal estimation from modified short-time Fourier transform\"?": {
        "answer": "D. W. Griffin and J. S. Lim",
        "question": "Who wrote \"Signal estimation from modified short-time Fourier transform\"?",
        "context": "[1] D. W. Griffin and J. S. Lim, \u201cSignal estimation from modified short-time Fourier transform,\u201d\nIEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984. input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What was the title of the IEEE Trans. ASSP?": {
        "answer": "vol.32, no.2, pp.236-243",
        "question": "What was the title of the IEEE Trans. ASSP?",
        "context": "[1] D. W. Griffin and J. S. Lim, \u201cSignal estimation from modified short-time Fourier transform,\u201d\nIEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984. input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the input tensor expected to be?": {
        "answer": "output ofstft()",
        "question": "What is the input tensor expected to be?",
        "context": "[1] D. W. Griffin and J. S. Lim, \u201cSignal estimation from modified short-time Fourier transform,\u201d\nIEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984. input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "When was real input deprecated?": {
        "answer": "1.8.0",
        "question": "When was real input deprecated?",
        "context": "[1] D. W. Griffin and J. S. Lim, \u201cSignal estimation from modified short-time Fourier transform,\u201d\nIEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984. input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the channeldimension?": {
        "answer": "optional",
        "question": "What is the channeldimension?",
        "context": "The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Since what version is real input deprecated?": {
        "answer": "1.8.0",
        "question": "Since what version is real input deprecated?",
        "context": "Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the size of Fourier transform hop_length?": {
        "answer": "n_fft",
        "question": "What is the size of Fourier transform hop_length?",
        "context": "n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default value of hop_length(Optional[int])?": {
        "answer": "Default:n_fft//4)",
        "question": "What is the default value of hop_length(Optional[int])?",
        "context": "input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is expected to be output ofstft()?": {
        "answer": "input tensor",
        "question": "What is expected to be output ofstft()?",
        "context": "The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Since what version is the input tensor deprecated?": {
        "answer": "1.8.0",
        "question": "Since what version is the input tensor deprecated?",
        "context": "The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is hop_length?": {
        "answer": "The distance between neighboring sliding window frames",
        "question": "What is hop_length?",
        "context": "Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the size of window frame and STFT filter?": {
        "answer": "win_length",
        "question": "What is the size of window frame and STFT filter?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is window(Optional[torch.Tensor])?": {
        "answer": "optional window function",
        "question": "What is window(Optional[torch.Tensor])?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is Torch.ones(Optional[torch.Tensor]) called?": {
        "answer": "win_length",
        "question": "What is Torch.ones(Optional[torch.Tensor]) called?",
        "context": "Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is center(bool)?": {
        "answer": "Whetherinputwas padded on both sides",
        "question": "What is center(bool)?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default value for center(bool)?": {
        "answer": "True",
        "question": "What is the default value for center(bool)?",
        "context": "hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the distance between neighboring window frames?": {
        "answer": "hop_length",
        "question": "What is the distance between neighboring window frames?",
        "context": "hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is win_length?": {
        "answer": "The size of window frame and STFT filter",
        "question": "What is win_length?",
        "context": "hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default value of center(bool)?": {
        "answer": "True",
        "question": "What is the default value of center(bool)?",
        "context": "hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the distance between neighboring sliding window frames?": {
        "answer": "hop_length",
        "question": "What is the distance between neighboring sliding window frames?",
        "context": "hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the optional window function?": {
        "answer": "window",
        "question": "What is the optional window function?",
        "context": "window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is normalized(bool)?": {
        "answer": "Whether the STFT was normalized",
        "question": "What is normalized(bool)?",
        "context": "window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Whether the STFT was onesided or onesided?": {
        "answer": "onesided",
        "question": "Whether the STFT was onesided or onesided?",
        "context": "Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What does trueifn_fft! mean in the input size?": {
        "answer": "fft_size",
        "question": "What does trueifn_fft! mean in the input size?",
        "context": "input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Whether the STFT was normalized. (Default:False) onesided(Optional) \u2013 Whether the STFT was one": {
        "answer": "normalized",
        "question": "Whether the STFT was normalized. (Default:False) onesided(Optional) \u2013 Whether the STFT was one",
        "context": "center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the amount to trim the signal by (i.e. the original signal length)?": {
        "answer": "length",
        "question": "What is the amount to trim the signal by (i.e. the original signal length)?",
        "context": "center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the amount to trim the signal by?": {
        "answer": "the original signal length",
        "question": "What is the amount to trim the signal by?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default signal length?": {
        "answer": "whole signal",
        "question": "What is the default signal length?",
        "context": "center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is onesided(Optional[bool])?": {
        "answer": "Whether the STFT was onesided",
        "question": "What is onesided(Optional[bool])?",
        "context": "onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default value for the output of a STFT?": {
        "answer": "return_complex",
        "question": "What is the default value for the output of a STFT?",
        "context": "onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Is return_complex compatible or incompatible with onesided=True?": {
        "answer": "incompatible",
        "question": "Is return_complex compatible or incompatible with onesided=True?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the value of size (..., signal_length)?": {
        "answer": "Least squares estimation of the original signal",
        "question": "What is the value of size (..., signal_length)?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the value to trim the signal by?": {
        "answer": "length",
        "question": "What is the value to trim the signal by?",
        "context": "length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is incompatible withonesided=True?": {
        "answer": "return_complex",
        "question": "What is incompatible withonesided=True?",
        "context": "length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the Least squares estimation of the original signal of size?": {
        "answer": "Tensor",
        "question": "What is the Least squares estimation of the original signal of size?",
        "context": "length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is Optional[bool]) \u2013 Whether the output should be complex or if the input should be assumed to derive from ": {
        "answer": "return_complex",
        "question": "What is Optional[bool]) \u2013 Whether the output should be complex or if the input should be assumed to derive from ",
        "context": "length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is incompatible with return_complex?": {
        "answer": "withonesided=True",
        "question": "What is incompatible with return_complex?",
        "context": "length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the tensor of size?": {
        "answer": "1-D",
        "question": "What is the tensor of size?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is non-integerstep subject to when comparing againstend?": {
        "answer": "floating point rounding errors",
        "question": "What is non-integerstep subject to when comparing againstend?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the starting value for the set of points?": {
        "answer": "start(Number)",
        "question": "What is the starting value for the set of points?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default value for the starting value for the set of points?": {
        "answer": "Default:0",
        "question": "What is the default value for the starting value for the set of points?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is returned by sizeendstartstepleftlceil fractextend?": {
        "answer": "1-D tensor",
        "question": "What is returned by sizeendstartstepleftlceil fractextend?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "Non-integerstepis subject to what when comparing againstend?": {
        "answer": "floating point rounding errors",
        "question": "Non-integerstepis subject to what when comparing againstend?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is step(Number)?": {
        "answer": "the gap between each pair of adjacent points",
        "question": "What is step(Number)?",
        "context": "end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "Out(Tensor,optional) \u2013 what is the output tensor?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) \u2013 what is the output tensor?",
        "context": "start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the ending value for the set of points?": {
        "answer": "end(Number)",
        "question": "What is the ending value for the set of points?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default value for the ending value for the set of points step(Number)?": {
        "answer": "Default:1",
        "question": "What is the default value for the ending value for the set of points step(Number)?",
        "context": "end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the gap between each pair of adjacent points?": {
        "answer": "step(Number)",
        "question": "What is the gap between each pair of adjacent points?",
        "context": "step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "Out(Tensor,optional) - what?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) - what?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What happens if the data type is inferred from the other input arguments?": {
        "answer": "Ifdtypeis not given",
        "question": "What happens if the data type is inferred from the other input arguments?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is inferred to be the default dtype if any ofstart,end, orstopare floating-point?": {
        "answer": "thedtypeis",
        "question": "What is inferred to be the default dtype if any ofstart,end, orstopare floating-point?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default dtype inferred to if any ofstart,end, orstopare floating-point?": {
        "answer": "betorch.int64",
        "question": "What is the default dtype inferred to if any ofstart,end, orstopare floating-point?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What happens when a data type is inferred from the other input arguments?": {
        "answer": "Ifdtypeis not given",
        "question": "What happens when a data type is inferred from the other input arguments?",
        "context": "end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What happens when the data type is inferred from the other input arguments?": {
        "answer": "Ifdtypeis not given",
        "question": "What happens when the data type is inferred from the other input arguments?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default tensor type used by ifNone?": {
        "answer": "Default",
        "question": "What is the default tensor type used by ifNone?",
        "context": "out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What will infer the data type from the other input arguments?": {
        "answer": "Ifdtypeis not given",
        "question": "What will infer the data type from the other input arguments?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "If any ofstart,end, orstopare what, thedtypeis inferred to be the default dtype?": {
        "answer": "floating-point",
        "question": "If any ofstart,end, orstopare what, thedtypeis inferred to be the default dtype?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default dtype inferred to?": {
        "answer": "betorch.int64",
        "question": "What is the default dtype inferred to?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "If any ofstart,end, orstopare floating-point, what is inferred to be the default dtype?": {
        "answer": "thedtypeis",
        "question": "If any ofstart,end, orstopare floating-point, what is inferred to be the default dtype?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "If any ofstart,end, orstopare floating-point, thedtypeis inferred to what?": {
        "answer": "betorch.int64",
        "question": "If any ofstart,end, orstopare floating-point, thedtypeis inferred to what?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What uses a global default (seetorch.set_default_tensor_type())?": {
        "answer": "Default: ifNone",
        "question": "What uses a global default (seetorch.set_default_tensor_type())?",
        "context": "dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors?": {
        "answer": "The torch package",
        "question": "What contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch package provide?": {
        "answer": "it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities",
        "question": "What does the torch package provide?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does torch have that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0?": {
        "answer": "CUDA counterpart",
        "question": "What does torch have that enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the CUDA counterpart return?": {
        "answer": "True ifobjis a PyTorch storage object",
        "question": "What does the CUDA counterpart return?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What package contains data structures for multi-dimensional tensors?": {
        "answer": "torch",
        "question": "What package contains data structures for multi-dimensional tensors?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What utility does the torch package provide for Tensors and arbitrary types?": {
        "answer": "efficient serializing",
        "question": "What utility does the torch package provide for Tensors and arbitrary types?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the counterpart of the torch package?": {
        "answer": "CUDA",
        "question": "What is the counterpart of the torch package?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does True ifobjis return?": {
        "answer": "PyTorch storage object",
        "question": "What does True ifobjis return?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0?": {
        "answer": "CUDA counterpart",
        "question": "What enables you to run your tensor computations on an NVIDIA GPU with compute capability >= 3.0?",
        "context": "It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does True return ifobjis a PyTorch tensor?": {
        "answer": "PyTorch storage object",
        "question": "What does True return ifobjis a PyTorch tensor?",
        "context": "It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are two examples of a complex data type?": {
        "answer": "one oftorch.complex64, andtorch.complex128",
        "question": "What are two examples of a complex data type?",
        "context": "It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of data type is the data type ofinput?": {
        "answer": "floating point data type",
        "question": "What type of data type is the data type ofinput?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the GPU that allows you to run tensor computations on an NVIDIA GPU with compute capability >= 3.0": {
        "answer": "CUDA",
        "question": "What is the name of the GPU that allows you to run tensor computations on an NVIDIA GPU with compute capability >= 3.0",
        "context": "It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns True if the data type ofinput is a what?": {
        "answer": "complex data type",
        "question": "Returns True if the data type ofinput is a what?",
        "context": "It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns True if the data type ofinputis a what type of data type?": {
        "answer": "complex data type",
        "question": "Returns True if the data type ofinputis a what type of data type?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns True ifobjis a what?": {
        "answer": "PyTorch storage object",
        "question": "Returns True ifobjis a what?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns True if the data type ofinputis a what?": {
        "answer": "floating point data type",
        "question": "Returns True if the data type ofinputis a what?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is not equal to zero after type conversions?": {
        "answer": "a single element tensor",
        "question": "What is not equal to zero after type conversions?",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns True if the data type ofinputis a single element tensor which is not equal to zero after type conversion": {
        "answer": "Sets the default floating point dtype tod",
        "question": "What does Returns True if the data type ofinputis a single element tensor which is not equal to zero after type conversion",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned ifobjis a PyTorch storage object?": {
        "answer": "PyTorch storage object",
        "question": "What is returned ifobjis a PyTorch storage object?",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns True what if theinputis a single element tensor?": {
        "answer": "if theinputis a single element tensor",
        "question": "Returns True what if theinputis a single element tensor?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do if the input is a single element tensor which is not equal to zero after type conversions?": {
        "answer": "Sets the default floating point dtype tod",
        "question": "What does it do if the input is a single element tensor which is not equal to zero after type conversions?",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Sets the default floating point dtype tod return?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What does Sets the default floating point dtype tod return?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do if the data type ofinputis a single element tensor which is not equal to zero after type conversions": {
        "answer": "Sets the default floating point dtype tod",
        "question": "What does it do if the data type ofinputis a single element tensor which is not equal to zero after type conversions",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what if the data type ofinputis a floating point data type?": {
        "answer": "True",
        "question": "Returns what if the data type ofinputis a floating point data type?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do if the input is a single element tensor?": {
        "answer": "Sets the default floating point dtype tod",
        "question": "What does it do if the input is a single element tensor?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sets what to floating point tensor typet?": {
        "answer": "defaulttorch.Tensortype",
        "question": "Sets what to floating point tensor typet?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when the defaulttorch.Tensortype is set to floating point tensor typet?": {
        "answer": "the total number of elements in theinputtensor",
        "question": "What is returned when the defaulttorch.Tensortype is set to floating point tensor typet?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Set options for what?": {
        "answer": "printing",
        "question": "Set options for what?",
        "context": "Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what if theinputis a single element tensor which is not equal to zero after type conversions?": {
        "answer": "True",
        "question": "Returns what if theinputis a single element tensor which is not equal to zero after type conversions?",
        "context": "Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sets what?": {
        "answer": "random number generator state",
        "question": "Sets what?",
        "context": "Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the default floating pointtorch.dtype?": {
        "answer": "current",
        "question": "What is the default floating pointtorch.dtype?",
        "context": "Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned by the defaulttorch.Tensortype?": {
        "answer": "the total number of elements in theinputtensor",
        "question": "What is returned by the defaulttorch.Tensortype?",
        "context": "Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Disables what on CPU?": {
        "answer": "denormal floating numbers",
        "question": "Disables what on CPU?",
        "context": "Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Disables denormal floating numbers on CPU?": {
        "answer": "Note",
        "question": "Disables denormal floating numbers on CPU?",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the default floating point dtype tod?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What is the default floating point dtype tod?",
        "context": "Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned by setting the defaulttorch.Tensortype to floating point tensor typet?": {
        "answer": "the total number of elements in theinputtensor",
        "question": "What is returned by setting the defaulttorch.Tensortype to floating point tensor typet?",
        "context": "Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What do you get?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What do you get?",
        "context": "Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the defaulttorch.Tensortype set to?": {
        "answer": "floating point tensor typet",
        "question": "What is the defaulttorch.Tensortype set to?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the total number of elements in what?": {
        "answer": "theinputtensor",
        "question": "Returns the total number of elements in what?",
        "context": "Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to denormal floating numbers on CPU?": {
        "answer": "Disables",
        "question": "What does it do to denormal floating numbers on CPU?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the command that disables denormal floating numbers on CPU?": {
        "answer": "Note",
        "question": "What is the name of the command that disables denormal floating numbers on CPU?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what in the inputtensor?": {
        "answer": "total number of elements",
        "question": "Returns what in the inputtensor?",
        "context": "Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is set to floating point tensor typet?": {
        "answer": "defaulttorch.Tensortype",
        "question": "What is set to floating point tensor typet?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the variable that can be used to set denormal floating numbers on the CPU?": {
        "answer": "Note",
        "question": "What is the name of the variable that can be used to set denormal floating numbers on the CPU?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are listed under Random sampling?": {
        "answer": "Random sampling creation ops",
        "question": "What are listed under Random sampling?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to a tensor?": {
        "answer": "Splits a tensor into a specific number of chunks",
        "question": "What does it do to a tensor?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the return return?": {
        "answer": "the total number of elements in theinputtensor",
        "question": "What does the return return?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of creation ops are listed under Random sampling?": {
        "answer": "Random sampling",
        "question": "What type of creation ops are listed under Random sampling?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is constructed withdata?": {
        "answer": "a tensor",
        "question": "What is constructed withdata?",
        "context": "Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do?": {
        "answer": "Constructs a tensor withdata",
        "question": "What does it do?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do on the CPU?": {
        "answer": "Disables denormal floating numbers",
        "question": "What does it do on the CPU?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it construct withdata?": {
        "answer": "tensor",
        "question": "What does it construct withdata?",
        "context": "Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to disable denormal floating numbers on CPU?": {
        "answer": "Set options for printing",
        "question": "What does it do to disable denormal floating numbers on CPU?",
        "context": "Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor does it construct?": {
        "answer": "tensor withdata",
        "question": "What type of tensor does it construct?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What format is the asparse tensor in?": {
        "answer": "COO(rdinate) format",
        "question": "What format is the asparse tensor in?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What creation ops are listed under Random sampling?": {
        "answer": "Random sampling",
        "question": "What creation ops are listed under Random sampling?",
        "context": "Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does asparse tensor in COO(rdinate) format contain?": {
        "answer": "specified values at the givenindices",
        "question": "What does asparse tensor in COO(rdinate) format contain?",
        "context": "Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What do you convert the data into?": {
        "answer": "atorch.Tensor",
        "question": "What do you convert the data into?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the asparse tensor contain?": {
        "answer": "specified values at the givenindices",
        "question": "What does the asparse tensor contain?",
        "context": "Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the data converted into?": {
        "answer": "atorch.Tensor",
        "question": "What is the data converted into?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Convert the data into what?": {
        "answer": "atorch.Tensor",
        "question": "Convert the data into what?",
        "context": "Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Create a view of an existingtorch.Tensorinputwith what?": {
        "answer": "specifiedsize,strideandstorage_offset",
        "question": "Create a view of an existingtorch.Tensorinputwith what?",
        "context": "Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where is the aTensor created from?": {
        "answer": "anumpy.ndarray",
        "question": "Where is the aTensor created from?",
        "context": "Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the size of the scalar value0?": {
        "answer": "the same size asinput",
        "question": "What is the size of the scalar value0?",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the shape of the scalar value1?": {
        "answer": "the shape defined by the variable argumentsize",
        "question": "What is the shape of the scalar value1?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the size of the scalar value1?": {
        "answer": "the same size asinput",
        "question": "What is the size of the scalar value1?",
        "context": "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the shape of the scalar value0?": {
        "answer": "the shape defined by the variable argumentsize",
        "question": "What is the shape of the scalar value0?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the aTensor created from?": {
        "answer": "anumpy.ndarray",
        "question": "What is the name of the aTensor created from?",
        "context": "Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the shape defined by the variable argumentsize. Returns a tensor filled with what value": {
        "answer": "scalar value1",
        "question": "Returns a tensor filled with the shape defined by the variable argumentsize. Returns a tensor filled with what value",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the scalar value0 return?": {
        "answer": "the shape defined by the variable argumentsize",
        "question": "What does the scalar value0 return?",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when the scalar value0 is returned?": {
        "answer": "a tensor",
        "question": "What is returned when the scalar value0 is returned?",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value0, with what as input?": {
        "answer": "same size",
        "question": "Returns a tensor filled with the scalar value0, with what as input?",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize. Returns a": {
        "answer": "same size",
        "question": "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize. Returns a",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned with the same size asinput?": {
        "answer": "a tensor filled with the scalar value0",
        "question": "What is returned with the same size asinput?",
        "context": "Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What shape does the scalar value1 have?": {
        "answer": "the shape defined by the variable argumentsize",
        "question": "What shape does the scalar value1 have?",
        "context": "Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the shape defined by the variable argumentsize?": {
        "answer": "scalar value0",
        "question": "What is the shape defined by the variable argumentsize?",
        "context": "Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the size of the tensor?": {
        "answer": "1-D",
        "question": "What is the size of the tensor?",
        "context": "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value1 with what?": {
        "answer": "the shape defined by the variable argumentsize",
        "question": "Returns a tensor filled with the scalar value1 with what?",
        "context": "Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value1, with what as input?": {
        "answer": "same size",
        "question": "Returns a tensor filled with the scalar value1, with what as input?",
        "context": "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what tensor of sizeendstartstepleftlceil fractextend - ": {
        "answer": "1-D",
        "question": "Returns what tensor of sizeendstartstepleftlceil fractextend - ",
        "context": "Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What defines the shape of the tensor?": {
        "answer": "variable argumentsize",
        "question": "What defines the shape of the tensor?",
        "context": "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what type of tensor?": {
        "answer": "a 1-D tensor",
        "question": "Returns what type of tensor?",
        "context": "Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the tensor of sizeendstartstepleftlceil fractextend?": {
        "answer": "1-D",
        "question": "What is the tensor of sizeendstartstepleftlceil fractextend?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the tensor of sizeendstartstep+1leftlfloor fractextend?": {
        "answer": "1-D",
        "question": "What is the tensor of sizeendstartstep+1leftlfloor fractextend?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what type of scalar value?": {
        "answer": "a tensor",
        "question": "Returns what type of scalar value?",
        "context": "Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are the values from the interval[start,end]taken?": {
        "answer": "fromstart",
        "question": "Where are the values from the interval[start,end]taken?",
        "context": "Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value of how many tensors?": {
        "answer": "1",
        "question": "Returns a tensor filled with the scalar value of how many tensors?",
        "context": "Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the tensor of sizeendstartstep?": {
        "answer": "1-D",
        "question": "What is the tensor of sizeendstartstep?",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How big is the tensor of sizeendstartstep?": {
        "answer": "1-D",
        "question": "How big is the tensor of sizeendstartstep?",
        "context": "Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is created when the values are evenly spaced fromstarttoend?": {
        "answer": "one-dimensional",
        "question": "What type of tensor is created when the values are evenly spaced fromstarttoend?",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are the values from the interval[start,end] taken?": {
        "answer": "fromstart",
        "question": "Where are the values from the interval[start,end] taken?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How many tensors does this function return?": {
        "answer": "1",
        "question": "How many tensors does this function return?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor of sizesteps is created?": {
        "answer": "one-dimensional",
        "question": "What type of tensor of sizesteps is created?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of sizesteps of how many dimensions?": {
        "answer": "1",
        "question": "Returns a tensor of sizesteps of how many dimensions?",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the logarithmic scale of the tensor?": {
        "answer": "basebase",
        "question": "What is the logarithmic scale of the tensor?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is returned with zeros and ones on the diagonal?": {
        "answer": "2-D",
        "question": "What type of tensor is returned with zeros and ones on the diagonal?",
        "context": " Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "On a logarithmic scale, what is used to create a one-dimensional tensor of sizesteps?": {
        "answer": "basebase",
        "question": "On a logarithmic scale, what is used to create a one-dimensional tensor of sizesteps?",
        "context": "Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a 2-D tensor with what?": {
        "answer": "ones on the diagonal and zeros elsewhere",
        "question": "Returns a 2-D tensor with what?",
        "context": " Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with what?": {
        "answer": "uninitialized data",
        "question": "Returns a tensor filled with what?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is created?": {
        "answer": "one-dimensional",
        "question": "What type of tensor is created?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns an uninitialized tensor with the same size as input?": {
        "answer": "an uninitialized tensor with the same size asinput",
        "question": "What returns an uninitialized tensor with the same size as input?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the Splitsinput do?": {
        "answer": "Concatenates the given sequence ofseqtensors in the given dimension",
        "question": "What does the Splitsinput do?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What splits a tensor with three or more dimensions into multiple tensors depthwise according toindices_or_section": {
        "answer": "Splitsinput",
        "question": "What splits a tensor with three or more dimensions into multiple tensors depthwise according toindices_or_section",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How does one create a new tensor?": {
        "answer": "horizontally stacking",
        "question": "How does one create a new tensor?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence depthwise (along what axis)?": {
        "answer": "third axis",
        "question": "Stack tensors in sequence depthwise (along what axis)?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the axis specified by?": {
        "answer": "bydim",
        "question": "What is the axis specified by?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the given sequence ofseqtensors in the given dimension do?": {
        "answer": "Concatenates",
        "question": "What does the given sequence ofseqtensors in the given dimension do?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens when a tensor is broken into chunks?": {
        "answer": "Splits",
        "question": "What happens when a tensor is broken into chunks?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Splitsinput use to split a tensor into multiple tensors depthwise?": {
        "answer": "indices_or_sections",
        "question": "What does Splitsinput use to split a tensor into multiple tensors depthwise?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to create a new tensor?": {
        "answer": "Stack tensors",
        "question": "What does it do to create a new tensor?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the axis where values are collected?": {
        "answer": "bydim",
        "question": "What is the name of the axis where values are collected?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splits a tensor into a specific number of what?": {
        "answer": "chunks",
        "question": "Splits a tensor into a specific number of what?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How many dimensions does a Splitsinput have?": {
        "answer": "three or more",
        "question": "How many dimensions does a Splitsinput have?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Splitsinput do?": {
        "answer": "Gathers values along an axis specified bydim",
        "question": "What does Splitsinput do?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How many dimensions does a tensor have?": {
        "answer": "one or more dimensions",
        "question": "How many dimensions does a tensor have?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Splits a tensor into?": {
        "answer": "a specific number of chunks",
        "question": "What does Splits a tensor into?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How many tensors does Splitsinput split into?": {
        "answer": "multiple tensors depthwise",
        "question": "How many tensors does Splitsinput split into?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a tensor do in sequence depthwise?": {
        "answer": "Stack tensors",
        "question": "What does a tensor do in sequence depthwise?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the axis specified by Splitsinput?": {
        "answer": "bydim",
        "question": "What is the axis specified by Splitsinput?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How many tensors can a tensor with one or more dimensions be split into?": {
        "answer": "multiple tensors horizontally",
        "question": "How many tensors can a tensor with one or more dimensions be split into?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a tensor with three or more dimensions called?": {
        "answer": "Splitsinput",
        "question": "What is a tensor with three or more dimensions called?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splitsinput is a tensor with how many dimensions?": {
        "answer": "one or more dimensions",
        "question": "Splitsinput is a tensor with how many dimensions?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence where?": {
        "answer": "horizontally",
        "question": "Stack tensors in sequence where?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Splitsinput use to split a tensor?": {
        "answer": "indices_or_sections",
        "question": "What does Splitsinput use to split a tensor?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Splitsinput do to create a new tensor?": {
        "answer": "Stack tensors",
        "question": "What does Splitsinput do to create a new tensor?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What do tensors with one or more dimensions splitsinput into?": {
        "answer": "multiple tensors horizontally",
        "question": "What do tensors with one or more dimensions splitsinput into?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence horizontally (what?": {
        "answer": "column wise",
        "question": "Stack tensors in sequence horizontally (what?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_section": {
        "answer": "Splitsinput",
        "question": "What does a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_section",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How do you stack tensors in order to create a new tensor?": {
        "answer": "Stack tensors in sequence horizontally",
        "question": "How do you stack tensors in order to create a new tensor?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the index of the new tensor that indexes theinputtensor along dimensiondimusing the entries inindex?": {
        "answer": "aLongTensor",
        "question": "What is the index of the new tensor that indexes theinputtensor along dimensiondimusing the entries inindex?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where do tensors stack in sequence?": {
        "answer": "depthwise",
        "question": "Where do tensors stack in sequence?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Stack tensors do?": {
        "answer": "Gathers values along an axis specified bydim",
        "question": "What does Stack tensors do?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensor that splitsinput into multiple tensors horizontally?": {
        "answer": "indices_or_sections",
        "question": "What is the name of the tensor that splitsinput into multiple tensors horizontally?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence horizontally (what way)?": {
        "answer": "column wise",
        "question": "Stack tensors in sequence horizontally (what way)?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does aLongTensor do?": {
        "answer": "indexes theinputtensor along dimensiondimusing the entries inindex",
        "question": "What does aLongTensor do?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a tensor with one or more dimensions called?": {
        "answer": "Splitsinput",
        "question": "What is a tensor with one or more dimensions called?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence which way?": {
        "answer": "horizontally",
        "question": "Stack tensors in sequence which way?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the index of a new tensor that indexes theinputtensor along dimension?": {
        "answer": "aLongTensor",
        "question": "What is the index of a new tensor that indexes theinputtensor along dimension?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which tensor indexes theinputtensor according to the boolean maskmask?": {
        "answer": "1-D",
        "question": "Which tensor indexes theinputtensor according to the boolean maskmask?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is splitsinput?": {
        "answer": "a tensor with three or more dimensions",
        "question": "What is splitsinput?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the boolean maskmask?": {
        "answer": "aBoolTensor",
        "question": "What is the boolean maskmask?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the function that gathers values along an axis specified bydim?": {
        "answer": "Gathers values along an axis specified bydim",
        "question": "What is the function that gathers values along an axis specified bydim?",
        "context": "Gathers values along an axis specified bydim. For a 3-D tensor the output is specified by: inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other. input(Tensor) \u2013 the source tensor dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to gather sparse_grad(bool,optional) \u2013 IfTrue, gradient w.r.t.inputwill be a sparse tensor. out(Tensor,optional) \u2013 the destination tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather"
    },
    "What is the name of a tensor that indexes theinputtensor along dimensiondimusing the entries inindex?": {
        "answer": "Stack",
        "question": "What is the name of a tensor that indexes theinputtensor along dimensiondimusing the entries inindex?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensor that indexes theinputtensor along dimensiondimusing the entries inindex?": {
        "answer": "aLongTensor",
        "question": "What is the name of the tensor that indexes theinputtensor along dimensiondimusing the entries inindex?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor indexes theinputtensor according to the boolean maskmask?": {
        "answer": "1-D",
        "question": "What type of tensor indexes theinputtensor according to the boolean maskmask?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How do you stack tensors in sequence horizontally?": {
        "answer": "Stack tensors",
        "question": "How do you stack tensors in sequence horizontally?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of a tensor that splitsinput into multiple tensors horizontally?": {
        "answer": "Stack",
        "question": "What is the name of a tensor that splitsinput into multiple tensors horizontally?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the new tensor that indexes theinputtensor along dimensiondimusing the entries inindex?": {
        "answer": "aLongTensor",
        "question": "What is the name of the new tensor that indexes theinputtensor along dimensiondimusing the entries inindex?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does aBoolTensor do?": {
        "answer": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination",
        "question": "What does aBoolTensor do?",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a tensor with one or more dimensions do horizontally?": {
        "answer": "Stack tensors",
        "question": "What does a tensor with one or more dimensions do horizontally?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does move the dimension(s) ofinputat the position(s) insourceto the position(s) indestination?": {
        "answer": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination",
        "question": "What does move the dimension(s) ofinputat the position(s) insourceto the position(s) indestination?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How do you stack tensors in sequence?": {
        "answer": "horizontally",
        "question": "How do you stack tensors in sequence?",
        "context": "Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the index of the new tensor that indexes theinputtensor along dimension?": {
        "answer": "aLongTensor",
        "question": "What is the index of the new tensor that indexes theinputtensor along dimension?",
        "context": "Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor does aBoolTensor return?": {
        "answer": "1-D",
        "question": "What type of tensor does aBoolTensor return?",
        "context": "Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor that is a narrowed version ofinputtensor?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What is the name of the function that returns a new tensor that is a narrowed version ofinputtensor?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What kind of version of inputtensor is the new tensor?": {
        "answer": "narrowed",
        "question": "What kind of version of inputtensor is the new tensor?",
        "context": "Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence what?": {
        "answer": "horizontally",
        "question": "Stack tensors in sequence what?",
        "context": "Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does fortorch.movedim() do?": {
        "answer": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination",
        "question": "What does fortorch.movedim() do?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is used to move the dimension(s) ofinputat the position(s) insourceto the position(s) indestination?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What is used to move the dimension(s) ofinputat the position(s) insourceto the position(s) indestination?",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor that is what?": {
        "answer": "a narrowed version ofinputtensor",
        "question": "Returns a new tensor that is what?",
        "context": "Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor which indexes theinputtensor according to the boolean maskmask which is": {
        "answer": "1-D",
        "question": "Returns a new tensor which indexes theinputtensor according to the boolean maskmask which is",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What method returns a new tensor that is a narrowed version ofinputtensor?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What method returns a new tensor that is a narrowed version ofinputtensor?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the index that returns a new tensor that indexes theinputtensor along dimensiondimusing": {
        "answer": "aLongTensor",
        "question": "What is the name of the index that returns a new tensor that indexes theinputtensor along dimensiondimusing",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new 1-D tensor which indexes theinputtensor according to what boolean maskmask": {
        "answer": "aBoolTensor",
        "question": "Returns a new 1-D tensor which indexes theinputtensor according to what boolean maskmask",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor that indexes theinputtensor according to what boolean maskmask?": {
        "answer": "1-D",
        "question": "Returns a new tensor that indexes theinputtensor according to what boolean maskmask?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor that is a narrowed version ofinputtensor?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What returns a new tensor that is a narrowed version ofinputtensor?",
        "context": "Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is the new tensor?": {
        "answer": "narrowed",
        "question": "What type of tensor is the new tensor?",
        "context": "Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return a tensor with the same data and number of elements asinput, but with?": {
        "answer": "the specified shape",
        "question": "What does return a tensor with the same data and number of elements asinput, but with?",
        "context": "Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a tensor with the same data and number of elements asinput but with the specified shape?": {
        "answer": "Alias oftorch.vstack()",
        "question": "What returns a tensor with the same data and number of elements asinput but with the specified shape?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the version of oftorch.Tensor.scatter_()?": {
        "answer": "Out-of-place",
        "question": "What is the version of oftorch.Tensor.scatter_()?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does move the dimension(s) ofinput?": {
        "answer": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination",
        "question": "What does move the dimension(s) ofinput?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with the same data and number of elements asinput, but with what?": {
        "answer": "the specified shape",
        "question": "Returns a tensor with the same data and number of elements asinput, but with what?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a tensor with the same data and number of elements as input?": {
        "answer": "Alias oftorch.vstack()",
        "question": "What is the name of the function that returns a tensor with the same data and number of elements as input?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the version oftorch.Tensor.scatter_()?": {
        "answer": "Out-of-place",
        "question": "What is the name of the version oftorch.Tensor.scatter_()?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to the dimension(s) ofinput?": {
        "answer": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination",
        "question": "What does it do to the dimension(s) ofinput?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the tensor split into?": {
        "answer": "chunks",
        "question": "What is the tensor split into?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that moves the dimension(s) ofinput to the position(s) indestination?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What is the name of the function that moves the dimension(s) ofinput to the position(s) indestination?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with the same data and number of elements as input, but with what?": {
        "answer": "specified shape",
        "question": "Returns a tensor with the same data and number of elements as input, but with what?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Out-of-place version oftorch.Tensor.scatter_add_() Splits the tensor into": {
        "answer": "chunks",
        "question": "Out-of-place version oftorch.Tensor.scatter_add_() Splits the tensor into",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that splits a tensor into chunks?": {
        "answer": "Alias oftorch.vstack()",
        "question": "What is the name of the function that splits a tensor into chunks?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with all the dimensions of what?": {
        "answer": "size1removed",
        "question": "Returns a tensor with all the dimensions of what?",
        "context": "Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a new tensor that is a narrowed version ofinputtensor?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What function returns a new tensor that is a narrowed version ofinputtensor?",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned with the same data and number of elements as input but with the specified shape?": {
        "answer": "a tensor",
        "question": "What is returned with the same data and number of elements as input but with the specified shape?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with what?": {
        "answer": "all the dimensions ofinputof size1removed",
        "question": "Returns a tensor with what?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens to a sequence of tensors along a new dimension?": {
        "answer": "Concatenates",
        "question": "What happens to a sequence of tensors along a new dimension?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that concatenates a sequence of tensors along a new dimension?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What is the name of the function that concatenates a sequence of tensors along a new dimension?",
        "context": "Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that converts a sequence of tensors along a new dimension?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What is the name of the function that converts a sequence of tensors along a new dimension?",
        "context": "Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return a tensor with the same data and number of elements as input but with?": {
        "answer": "the specified shape",
        "question": "What does return a tensor with the same data and number of elements as input but with?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with all the dimensions ofinputof what?": {
        "answer": "size1removed",
        "question": "Returns a tensor with all the dimensions ofinputof what?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.transpose() do?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What does Alias fortorch.transpose() do?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What splits the tensor into chunks?": {
        "answer": "Out-of-place version oftorch.Tensor.scatter_()",
        "question": "What splits the tensor into chunks?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with what data removed?": {
        "answer": "all the dimensions",
        "question": "Returns a tensor with what data removed?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is another name for fortorch.transpose()?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What is another name for fortorch.transpose()?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the generator object produce?": {
        "answer": "pseudo random numbers",
        "question": "What does the generator object produce?",
        "context": "  Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of random number is the seed for generating random numbers?": {
        "answer": "non-deterministic",
        "question": "What type of random number is the seed for generating random numbers?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to a non-deterministic random number?": {
        "answer": "Sets the seed for generating random numbers",
        "question": "What does it do to a non-deterministic random number?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the initial seed for generating random numbers?": {
        "answer": "Pythonlong",
        "question": "What is the initial seed for generating random numbers?",
        "context": "Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the random number generator state?": {
        "answer": "atorch.ByteTensor",
        "question": "What is the random number generator state?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does atorch.ByteTensor set?": {
        "answer": "random number generator state",
        "question": "What does atorch.ByteTensor set?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the random number generator state?": {
        "answer": "atorch.ByteTensor",
        "question": "What is the name of the random number generator state?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does each row containnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of ": {
        "answer": "tensor",
        "question": "What does each row containnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of ",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does atorch.ByteTensor do?": {
        "answer": "Sets the random number generator state",
        "question": "What does atorch.ByteTensor do?",
        "context": "Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the random number generator state as what?": {
        "answer": "atorch.ByteTensor",
        "question": "Returns the random number generator state as what?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row": {
        "answer": "tensor",
        "question": "What is returned when each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are given to the tensor of random numbers drawn from separate normal distributions?": {
        "answer": "mean and standard deviation",
        "question": "What are given to the tensor of random numbers drawn from separate normal distributions?",
        "context": "Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what of random numbers drawn from separate normal distributions whose mean and standard deviation are given?": {
        "answer": "tensor",
        "question": "Returns a what of random numbers drawn from separate normal distributions whose mean and standard deviation are given?",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the function do that draws binary random numbers from a Bernoulli distribution?": {
        "answer": "Draws binary random numbers",
        "question": "What does the function do that draws binary random numbers from a Bernoulli distribution?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are given to the random numbers drawn from separate normal distributions?": {
        "answer": "mean and standard deviation",
        "question": "What are given to the random numbers drawn from separate normal distributions?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does each element in the tensor have?": {
        "answer": "rate parameter given by the corresponding element ininputi",
        "question": "What does each element in the tensor have?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of random numbers drawn from separate normal distributions what are given?": {
        "answer": "whose mean and standard deviation",
        "question": "Returns a tensor of random numbers drawn from separate normal distributions what are given?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "The tensor returns a tensor of the same size as input with each element sampled from what distribution?": {
        "answer": "Poisson",
        "question": "The tensor returns a tensor of the same size as input with each element sampled from what distribution?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What distribution is each element sampled from?": {
        "answer": "Poisson distribution",
        "question": "What distribution is each element sampled from?",
        "context": "Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned with each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininput?": {
        "answer": "a tensor of the same size asinput",
        "question": "What is returned with each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininput?",
        "context": "Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with what from a uniform distribution on the interval?": {
        "answer": "random numbers",
        "question": "Returns a tensor filled with what from a uniform distribution on the interval?",
        "context": "Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of distribution is the tensor filled with random numbers from?": {
        "answer": "uniform distribution",
        "question": "What type of distribution is the tensor filled with random numbers from?",
        "context": "Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are the random integers generated uniformly?": {
        "answer": "betweenlow(inclusive) andhigh(exclusive)",
        "question": "Where are the random integers generated uniformly?",
        "context": "Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1) Returns a ": {
        "answer": "a tensor",
        "question": "What is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1) Returns a ",
        "context": "Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?": {
        "answer": "exclusive",
        "question": "Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?",
        "context": "Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned with the same shape as Tensorinput?": {
        "answer": "tensor",
        "question": "What is returned with the same shape as Tensorinput?",
        "context": "Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of distribution is used to fill a tensor with the same size as input?": {
        "answer": "uniform distribution",
        "question": "What type of distribution is used to fill a tensor with the same size as input?",
        "context": "Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Random integers are generated uniformly betweenlow(inclusive) andhigh(exclusive)?": {
        "answer": "exclusive",
        "question": "Random integers are generated uniformly betweenlow(inclusive) andhigh(exclusive)?",
        "context": "Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1]?": {
        "answer": "a tensor",
        "question": "What is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1]?",
        "context": "Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?": {
        "answer": "tensor",
        "question": "What is filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?",
        "context": "Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What shape does a tensor have?": {
        "answer": "same shape",
        "question": "What shape does a tensor have?",
        "context": "Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the standard normal distribution?": {
        "answer": "mean0and variance1",
        "question": "What is the standard normal distribution?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How are the random integers generated?": {
        "answer": "uniformly betweenlow(inclusive) andhigh(exclusive)",
        "question": "How are the random integers generated?",
        "context": "Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with the same size as inputthat is filled with random numbers from a normal distribution with what?": {
        "answer": "mean 0 and variance 1.",
        "question": "Returns a tensor with the same size as inputthat is filled with random numbers from a normal distribution with what?",
        "context": "Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a tensor with the same size as input?": {
        "answer": "random permutation of integers from0ton-1",
        "question": "What returns a tensor with the same size as input?",
        "context": "Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with what?": {
        "answer": "mean 0 and variance 1.",
        "question": "Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with what?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a random permutation of integers?": {
        "answer": "from0ton-1",
        "question": "What is a random permutation of integers?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are a few more in-place random sampling functions defined?": {
        "answer": "Tensors",
        "question": "Where are a few more in-place random sampling functions defined?",
        "context": "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How do you refer to the documentation of in-place random sampling functions?": {
        "answer": "Click through",
        "question": "How do you refer to the documentation of in-place random sampling functions?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is another name for a normal distribution with mean0and variance1?": {
        "answer": "standard normal distribution",
        "question": "What is another name for a normal distribution with mean0and variance1?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when a tensor is filled with random numbers from a normal distribution with mean 0 and variance 1?": {
        "answer": "random permutation of integers from0ton-1",
        "question": "What is returned when a tensor is filled with random numbers from a normal distribution with mean 0 and variance 1?",
        "context": "Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are there a few more defined on Tensors?": {
        "answer": "in-place random sampling functions",
        "question": "What are there a few more defined on Tensors?",
        "context": "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Click through to refer to what?": {
        "answer": "their documentation",
        "question": "Click through to refer to what?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What distribution does Tensor.log_normal_() sample from?": {
        "answer": "log-normal",
        "question": "What distribution does Tensor.log_normal_() sample from?",
        "context": "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of distribution are random numbers sampled from?": {
        "answer": "discrete uniform distribution",
        "question": "What type of distribution are random numbers sampled from?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are numbers sampled from the discrete uniform distribution torch?": {
        "answer": "Tensor.random_()",
        "question": "What are numbers sampled from the discrete uniform distribution torch?",
        "context": "torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of distribution are the numbers in the Tensor.uniform_() sampled from?": {
        "answer": "continuous uniform distribution",
        "question": "What type of distribution are the numbers in the Tensor.uniform_() sampled from?",
        "context": "torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of distribution are the numbers sampled from?": {
        "answer": "continuous uniform distribution",
        "question": "What type of distribution are the numbers sampled from?",
        "context": "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the engine that generates Sobol sequences?": {
        "answer": "SobolEngine Thetorch.quasirandom",
        "question": "What is the name of the engine that generates Sobol sequences?",
        "context": "quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of sequence is generated by the SobolEngine Thetorch?": {
        "answer": "quasirandom",
        "question": "What type of sequence is generated by the SobolEngine Thetorch?",
        "context": "quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does withtorch.save() save to a disk file?": {
        "answer": "an object",
        "question": "What does withtorch.save() save to a disk file?",
        "context": "  Saves an object to a disk file.   Loads an object saved withtorch.save()from a file. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What method saves an object from a file?": {
        "answer": "withtorch.save()",
        "question": "What method saves an object from a file?",
        "context": "  Saves an object to a disk file.   Loads an object saved withtorch.save()from a file. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do when an object is saved to a disk file?": {
        "answer": "Saves an object to a disk file",
        "question": "What does it do when an object is saved to a disk file?",
        "context": "  Saves an object to a disk file.   Loads an object saved withtorch.save()from a file. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Loads an object saved what from a file?": {
        "answer": "withtorch.save()",
        "question": "Loads an object saved what from a file?",
        "context": "  Saves an object to a disk file.   Loads an object saved withtorch.save()from a file. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Return?": {
        "answer": "the number of threads used for parallelizing CPU operations",
        "question": "What does Return?",
        "context": "  Returns the number of threads used for parallelizing CPU operations   Sets the number of threads used for intraop parallelism on CPU.   Returns the number of threads used for inter-op parallelism on CPU (e.g.   Sets the number of threads used for interop parallelism (e.g. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does this return?": {
        "answer": "the number of threads used for inter-op parallelism on CPU",
        "question": "What does this return?",
        "context": "  Returns the number of threads used for parallelizing CPU operations   Sets the number of threads used for intraop parallelism on CPU.   Returns the number of threads used for inter-op parallelism on CPU (e.g.   Sets the number of threads used for interop parallelism (e.g. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Sets the number of threads used for inter-op parallelism on CPU?": {
        "answer": "the number of threads used for interop parallelism",
        "question": "What does Sets the number of threads used for inter-op parallelism on CPU?",
        "context": "  Returns the number of threads used for parallelizing CPU operations   Sets the number of threads used for intraop parallelism on CPU.   Returns the number of threads used for inter-op parallelism on CPU (e.g.   Sets the number of threads used for interop parallelism (e.g. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the number of threads used for parallelizing CPU operations?": {
        "answer": "Returns the number of threads used for parallelizing CPU operations",
        "question": "What returns the number of threads used for parallelizing CPU operations?",
        "context": "  Returns the number of threads used for parallelizing CPU operations   Sets the number of threads used for intraop parallelism on CPU.   Returns the number of threads used for inter-op parallelism on CPU (e.g.   Sets the number of threads used for interop parallelism (e.g. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the number of threads used for what parallelism on CPU?": {
        "answer": "inter-op",
        "question": "Returns the number of threads used for what parallelism on CPU?",
        "context": "  Returns the number of threads used for parallelizing CPU operations   Sets the number of threads used for intraop parallelism on CPU.   Returns the number of threads used for inter-op parallelism on CPU (e.g.   Sets the number of threads used for interop parallelism (e.g. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns the number of threads used for inter-op parallelism on CPU?": {
        "answer": "Sets the number of threads used for interop parallelism",
        "question": "What does Returns the number of threads used for inter-op parallelism on CPU?",
        "context": "  Returns the number of threads used for parallelizing CPU operations   Sets the number of threads used for intraop parallelism on CPU.   Returns the number of threads used for inter-op parallelism on CPU (e.g.   Sets the number of threads used for interop parallelism (e.g. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a context-manager do?": {
        "answer": "disabled gradient calculation",
        "question": "What does a context-manager do?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a context-manager enable?": {
        "answer": "gradient calculation",
        "question": "What does a context-manager enable?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does context-manager set gradient calculation to?": {
        "answer": "on or off",
        "question": "What does context-manager set gradient calculation to?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does grad mode return if grad mode is currently enabled?": {
        "answer": "True",
        "question": "What does grad mode return if grad mode is currently enabled?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a Context-manager that enables or disables inference mode return if inference mode is currently enabled?": {
        "answer": "True",
        "question": "What does a Context-manager that enables or disables inference mode return if inference mode is currently enabled?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the manager that disabled gradient calculation?": {
        "answer": "Context-manager",
        "question": "What is the name of the manager that disabled gradient calculation?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a Context-manager do?": {
        "answer": "enables gradient calculation",
        "question": "What does a Context-manager do?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a Context-manager set gradient calculation to?": {
        "answer": "on or off",
        "question": "What does a Context-manager set gradient calculation to?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is currently enabled by the Context-manager?": {
        "answer": "grad mode",
        "question": "What is currently enabled by the Context-manager?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What mode does a Context-manager enable or disable?": {
        "answer": "inference mode",
        "question": "What mode does a Context-manager enable or disable?",
        "context": "Examples:   Context-manager that disabled gradient calculation.   Context-manager that enables gradient calculation.   Context-manager that sets gradient calculation to on or off.   Returns True if grad mode is currently enabled.   Context-manager that enables or disables inference mode   Returns True if inference mode is currently enabled. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.abs() compute of each element ininput?": {
        "answer": "absolute value",
        "question": "What does Alias fortorch.abs() compute of each element ininput?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.abs() compute?": {
        "answer": "inverse cosine",
        "question": "What does Alias fortorch.abs() compute?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the inverse hyperbolic cosine of the elements ofinput?": {
        "answer": "Alias fortorch.acosh()",
        "question": "What returns a new tensor with the inverse hyperbolic cosine of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acos() return a new tensor with?": {
        "answer": "inverse hyperbolic cosine",
        "question": "What does Alias fortorch.acos() return a new tensor with?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acosh() do?": {
        "answer": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor",
        "question": "What does Alias fortorch.acosh() do?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the element-wise division oftensor1bytensor2 do?": {
        "answer": "multiply the result by the scalarvalueand add it toinput",
        "question": "What does the element-wise division oftensor1bytensor2 do?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What computes the inverse cosine of each element ininput?": {
        "answer": "Alias fortorch.acos()",
        "question": "What computes the inverse cosine of each element ininput?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a new tensor with the inverse hyperbolic cosine of the elements ofinput?": {
        "answer": "Alias fortorch.acosh()",
        "question": "What function returns a new tensor with the inverse hyperbolic cosine of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.acos() returns a new tensor with what cosine of the elements of input?": {
        "answer": "inverse hyperbolic",
        "question": "Alias fortorch.acos() returns a new tensor with what cosine of the elements of input?",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the element-wise division performed by Alias fortorch.acosh?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the element-wise division performed by Alias fortorch.acosh?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acos() return?": {
        "answer": "inverse hyperbolic cosine",
        "question": "What does Alias fortorch.acos() return?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acosh() add to each element of inputinput?": {
        "answer": "scalarotherto",
        "question": "What does Alias fortorch.acosh() add to each element of inputinput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the inverse hyperbolic cosine of the elements of input": {
        "answer": "Alias fortorch.acosh()",
        "question": "What is the name of the function that returns a new tensor with the inverse hyperbolic cosine of the elements of input",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the element-wise division performed by Alias fortorch.acosh()?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the element-wise division performed by Alias fortorch.acosh()?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acos() compute of each element ininput?": {
        "answer": "inverse cosine",
        "question": "What does Alias fortorch.acos() compute of each element ininput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computes the inverse cosine of each element ininput?": {
        "answer": "Alias fortorch.acos()",
        "question": "What is the name of the function that computes the inverse cosine of each element ininput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of cosine does Alias fortorch.acos() compute?": {
        "answer": "hyperbolic",
        "question": "What type of cosine does Alias fortorch.acos() compute?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the cosine of each element in input?": {
        "answer": "inverse",
        "question": "What is the cosine of each element in input?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what cosine of the elements of input?": {
        "answer": "inverse hyperbolic",
        "question": "Returns a new tensor with what cosine of the elements of input?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the inverse hyperbolic cosine of the elements ofin": {
        "answer": "Alias fortorch.acosh()",
        "question": "What is the name of the function that returns a new tensor with the inverse hyperbolic cosine of the elements ofin",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of cosine of the elements of input is returned by Alias fortorch.acos()?": {
        "answer": "hyperbolic",
        "question": "What type of cosine of the elements of input is returned by Alias fortorch.acos()?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acosh() add to each element of the inputinput?": {
        "answer": "scalarotherto",
        "question": "What does Alias fortorch.acosh() add to each element of the inputinput?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acos() perform?": {
        "answer": "the element-wise multiplication",
        "question": "What does Alias fortorch.acos() perform?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of cosine does Alias fortorch.acos() return?": {
        "answer": "inverse hyperbolic",
        "question": "What type of cosine does Alias fortorch.acos() return?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise multiplication performed by Alias fortorch.acosh?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise multiplication performed by Alias fortorch.acosh?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the inverse of the elements of input?": {
        "answer": "hyperbolic sine",
        "question": "What is the inverse of the elements of input?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What performs oftensor1bytensor2?": {
        "answer": "the element-wise division",
        "question": "What performs oftensor1bytensor2?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does oftensor1bytensor2 perform?": {
        "answer": "element-wise division",
        "question": "What does oftensor1bytensor2 perform?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In what unit is the element-wise angle of the given inputtensor calculated?": {
        "answer": "radians",
        "question": "In what unit is the element-wise angle of the given inputtensor calculated?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the cosine of the elements of input?": {
        "answer": "inverse hyperbolic",
        "question": "What is the cosine of the elements of input?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise division?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise division?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise multiplication?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise multiplication?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what of the given inputtensor?": {
        "answer": "element-wise angle",
        "question": "Computes what of the given inputtensor?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that adds the scalarotherto each element of the inputinput?": {
        "answer": "Alias fortorch.acosh()",
        "question": "What is the name of the function that adds the scalarotherto each element of the inputinput?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does oftensor1bytensor do?": {
        "answer": "element-wise division",
        "question": "What does oftensor1bytensor do?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the value of the element-wise angle of the given inputtensor?": {
        "answer": "radians",
        "question": "What is the value of the element-wise angle of the given inputtensor?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "The new tensor is returned with what element of the elements of input?": {
        "answer": "arcsine",
        "question": "The new tensor is returned with what element of the elements of input?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that adds the scalarotherto each element of the input?": {
        "answer": "Alias fortorch.acosh()",
        "question": "What is the name of the function that adds the scalarotherto each element of the input?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise division performed by Alias fortorch.acosh?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise division performed by Alias fortorch.acosh?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what of the elements of input?": {
        "answer": "inverse hyperbolic sine",
        "question": "Returns a new tensor with what of the elements of input?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Adds what to each element of the inputinput?": {
        "answer": "scalarotherto",
        "question": "Adds what to each element of the inputinput?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does oftensor1bytensor perform?": {
        "answer": "element-wise division",
        "question": "What does oftensor1bytensor perform?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element that returns a new tensor?": {
        "answer": "arcsine",
        "question": "What is the name of the element that returns a new tensor?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensor that returns a new tensor with the arcsine of the elements ofinput": {
        "answer": "Alias fortorch.asin",
        "question": "What is the name of the tensor that returns a new tensor with the arcsine of the elements ofinput",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new resulting tensor?": {
        "answer": "Adds the scalarotherto each element of the inputinput",
        "question": "What returns a new resulting tensor?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the arcsine of the elements ofinput?": {
        "answer": "Alias fortorch.asin()",
        "question": "What is the name of the function that returns a new tensor with the arcsine of the elements ofinput?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the result of the element-wise multiplication oftensor1bytensor2 multiplied by?": {
        "answer": "scalarvalue",
        "question": "What is the result of the element-wise multiplication oftensor1bytensor2 multiplied by?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the inverse hyperbolic sine of the elements of input?": {
        "answer": "arctangent",
        "question": "What is the inverse hyperbolic sine of the elements of input?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the arcsine of the elements ofinput?": {
        "answer": "Alias fortorch.asin()",
        "question": "What returns a new tensor with the arcsine of the elements ofinput?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the arcsine of the elements of input?": {
        "answer": "inverse hyperbolic sine",
        "question": "What is the arcsine of the elements of input?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the inverse hyperbolic sine of the elements ofinput?": {
        "answer": "Alias fortorch.asin()",
        "question": "What returns a new tensor with the inverse hyperbolic sine of the elements ofinput?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the element-wise division?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the element-wise division?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what of the elements ofinput?": {
        "answer": "cosine",
        "question": "Returns a new tensor with what of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does oftensor1bytensor2 multiply the result by?": {
        "answer": "scalarvalue",
        "question": "What does oftensor1bytensor2 multiply the result by?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the arctangent of the elements ofinput?": {
        "answer": "Alias fortorch.asinh()",
        "question": "What returns a new tensor with the arctangent of the elements ofinput?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the element-wise multiplication?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the element-wise multiplication?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the element-wise angle of the given inputtensor?": {
        "answer": "radians",
        "question": "What is the element-wise angle of the given inputtensor?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.asin() return a new tensor with?": {
        "answer": "inverse hyperbolic sine",
        "question": "What does Alias fortorch.asin() return a new tensor with?",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.asinh(). Returns a new tensor with what of the elements ofinput": {
        "answer": "arctangent",
        "question": "Alias fortorch.asinh(). Returns a new tensor with what of the elements ofinput",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In what unit is the element-wise angle of a given inputtensor computed?": {
        "answer": "radians",
        "question": "In what unit is the element-wise angle of a given inputtensor computed?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.asinh() return?": {
        "answer": "arctangent",
        "question": "What does Alias fortorch.asinh() return?",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?": {
        "answer": "Alias fortorch.atanh()",
        "question": "What returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.atan() return?": {
        "answer": "inverse hyperbolic tangent",
        "question": "What does Alias fortorch.atan() return?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the sine of the elements of input?": {
        "answer": "inverse hyperbolic",
        "question": "What is the sine of the elements of input?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the inverse hyperbolic tangent of the elements ofinput?": {
        "answer": "arctangent",
        "question": "What is the inverse hyperbolic tangent of the elements ofinput?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.atan() return a new tensor with?": {
        "answer": "inverse hyperbolic tangent",
        "question": "What does Alias fortorch.atan() return a new tensor with?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of sine does Alias fortorch.asin() return?": {
        "answer": "inverse hyperbolic",
        "question": "What type of sine does Alias fortorch.asin() return?",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What element of input does Alias fortorch.asinh() return?": {
        "answer": "arctangent",
        "question": "What element of input does Alias fortorch.asinh() return?",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensor returned by Alias fortorch.asin?": {
        "answer": "inverse hyperbolic sine",
        "question": "What is the name of the tensor returned by Alias fortorch.asin?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What element of the elements of input does Alias fortorch.asinh() return?": {
        "answer": "arctangent",
        "question": "What element of the elements of input does Alias fortorch.asinh() return?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the Alias fortorch.atan() return?": {
        "answer": "inverse hyperbolic tangent",
        "question": "What does the Alias fortorch.atan() return?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the inverse hyperbolic sine of the elements ofinput?": {
        "answer": "Alias fortorch.atanh()",
        "question": "What is the name of the function that returns a new tensor with the inverse hyperbolic sine of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "With consideration of what is the arctangent ofinputi/otheri / textother_iinput": {
        "answer": "the quadrant",
        "question": "With consideration of what is the arctangent ofinputi/otheri / textother_iinput",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the inverse hyperbolic tangent of the elements of input?": {
        "answer": "arctangent",
        "question": "What is the inverse hyperbolic tangent of the elements of input?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what of the given input tensor?": {
        "answer": "bitwise NOT",
        "question": "Computes what of the given input tensor?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what sine of the elements of input?": {
        "answer": "inverse hyperbolic",
        "question": "Returns a new tensor with what sine of the elements of input?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Inputi/otheritextinput_i / textother_iinputi": {
        "answer": "the quadrant",
        "question": "Inputi/otheritextinput_i / textother_iinputi",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what of the given input tensor?": {
        "answer": "bitwise",
        "question": "Computes the what of the given input tensor?",
        "context": "Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tangent does the new tensor have?": {
        "answer": "hyperbolic",
        "question": "What type of tangent does the new tensor have?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do with the inverse hyperbolic tangent of the elements of input?": {
        "answer": "Computes the bitwise NOT of the given input tensor",
        "question": "What does it do with the inverse hyperbolic tangent of the elements of input?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the Alias fortorch.atanh() do?": {
        "answer": "Computes the bitwise OR ofinputandother",
        "question": "What does the Alias fortorch.atanh() do?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the arctangent of the elements of input?": {
        "answer": "Alias fortorch.asinh()",
        "question": "What returns a new tensor with the arctangent of the elements of input?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor with the inverse hyperbolic tangent of the elements of input?": {
        "answer": "Alias fortorch.atan()",
        "question": "What returns a new tensor with the inverse hyperbolic tangent of the elements of input?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the inverse hyperbolic tangent of the elements of input": {
        "answer": "Alias fortorch.atanh()",
        "question": "What is the name of the function that returns a new tensor with the inverse hyperbolic tangent of the elements of input",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.atanh() do?": {
        "answer": "Computes the bitwise AND ofinputandother",
        "question": "What does Alias fortorch.atanh() do?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the bitwise OR of inputandother.": {
        "answer": "AND",
        "question": "Computes the bitwise OR of inputandother.",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the indices of the maximum value of all elements in what?": {
        "answer": "theinputtensor",
        "question": "Returns the indices of the maximum value of all elements in what?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the indices of the minimum value of what?": {
        "answer": "the flattened tensor or along a dimension",
        "question": "Returns the indices of the minimum value of what?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens if all elements ininputevaluate toTrue?": {
        "answer": "Tests",
        "question": "What happens if all elements ininputevaluate toTrue?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which element returns the maximum value of all elements in theinputtensor?": {
        "answer": "input tensor",
        "question": "Which element returns the maximum value of all elements in theinputtensor?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the inputevaluate return?": {
        "answer": "the maximum value of all elements in theinputtensor",
        "question": "What does the inputevaluate return?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the indices of the maximum value of all elements in the inputtensor?": {
        "answer": "Returns the indices of the maximum value of all elements in theinputtensor",
        "question": "What returns the indices of the maximum value of all elements in the inputtensor?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what?": {
        "answer": "True ifobjis a PyTorch tensor",
        "question": "Returns what?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value of the inputtensor in the given dimension(s)dim?": {
        "answer": "the minimum value of each slice",
        "question": "Returns what value of the inputtensor in the given dimension(s)dim?",
        "context": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the maximum value of all elements ininputtensor.": {
        "answer": "Tests if all elements ininputevaluate toTrue",
        "question": "Returns the maximum value of all elements ininputtensor.",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which element returns the maximum value of all elements ininputtensor?": {
        "answer": "input tensor",
        "question": "Which element returns the maximum value of all elements ininputtensor?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value of all elements in the inputtensor?": {
        "answer": "mean value",
        "question": "Returns what value of all elements in the inputtensor?",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return?": {
        "answer": "the minimum value of each slice of theinputtensor in the given dimension(s)dim",
        "question": "What does return?",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the return return return?": {
        "answer": "the product of all elements in theinputtensor",
        "question": "What does the return return return?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the minimum value of all elements in what?": {
        "answer": "theinputtensor",
        "question": "Returns the minimum value of all elements in what?",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of (input-other)?": {
        "answer": "p-norm",
        "question": "Returns what of (input-other)?",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the maximum value of each slice of the inputtensor in the given dimension(s)dim?": {
        "answer": "the indices of the minimum value(s) of the flattened tensor or along a dimension",
        "question": "What returns the maximum value of each slice of the inputtensor in the given dimension(s)dim?",
        "context": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do when all elements ininputevaluate toTrue?": {
        "answer": "Tests if all elements ininputevaluate toTrue",
        "question": "What does it do when all elements ininputevaluate toTrue?",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the minimum value of all elements in the inputtensor?": {
        "answer": "Returns the minimum value of all elements in theinputtensor",
        "question": "What returns the minimum value of all elements in the inputtensor?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the what of (input-other)?": {
        "answer": "p-norm",
        "question": "Returns the what of (input-other)?",
        "context": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return the maximum value of each slice of theinputtensor in the given dimensiondim?": {
        "answer": "the minimum value of each slice of theinputtensor in the given dimension(s)dim",
        "question": "What does return the maximum value of each slice of theinputtensor in the given dimensiondim?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the input tensor do?": {
        "answer": "Tests if all elements ininputevaluate toTrue",
        "question": "What does the input tensor do?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return the maximum value of all elements in the inputtensor?": {
        "answer": "the minimum value of all elements in theinputtensor",
        "question": "What does return the maximum value of all elements in the inputtensor?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the value of (input-other)?": {
        "answer": "p-norm",
        "question": "What is the value of (input-other)?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value of each slice of theinputtensor in the given dimension(s)dim?": {
        "answer": "minimum value",
        "question": "Returns what value of each slice of theinputtensor in the given dimension(s)dim?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the minimum value of each slice of theinputtensor in the given dimension(s)dim?": {
        "answer": "Returns the minimum value of each slice",
        "question": "What returns the minimum value of each slice of theinputtensor in the given dimension(s)dim?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the minimum value of all elements in theinputtensor?": {
        "answer": "Returns the minimum value of all elements in theinputtensor",
        "question": "What returns the minimum value of all elements in theinputtensor?",
        "context": "Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned for each row of the inputtensor in the given dimensiondim?": {
        "answer": "the p-norm of (input-other) Returns the log of summed exponentials",
        "question": "What is returned for each row of the inputtensor in the given dimensiondim?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned in the given dimension(s)dim?": {
        "answer": "the minimum value of each slice of theinputtensor",
        "question": "What is returned in the given dimension(s)dim?",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.": {
        "answer": "p-norm",
        "question": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of each row of the inputtensor in the given dimensiondim?": {
        "answer": "the p-norm of (input-other) Returns the log of summed exponentials",
        "question": "Returns what of each row of the inputtensor in the given dimensiondim?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the maximum value of all elements in theinputtensor?": {
        "answer": "Returns the maximum value of all elements in theinputtensor",
        "question": "What returns the maximum value of all elements in theinputtensor?",
        "context": "Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What value does the input tensor return?": {
        "answer": "the minimum value of all elements in theinputtensor",
        "question": "What value does the input tensor return?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the p-norm of (input-other) return?": {
        "answer": "the mean value of all elements in theinputtensor",
        "question": "What does the p-norm of (input-other) return?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when the p-norm of (input-other) returns the log of summed exponentials of each row of": {
        "answer": "the mean value of all elements in theinputtensor",
        "question": "What is returned when the p-norm of (input-other) returns the log of summed exponentials of each row of",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the value of the values ininput?": {
        "answer": "median",
        "question": "What is the value of the values ininput?",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does ignoringNaNvalues return?": {
        "answer": "the median of the values ininput",
        "question": "What does ignoringNaNvalues return?",
        "context": "Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it test if all elements ininputevaluate toTrue?": {
        "answer": "Tests if all elements ininputevaluate toTrue",
        "question": "What does it test if all elements ininputevaluate toTrue?",
        "context": "Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is used to test if all elements ininputevaluate toTrue?": {
        "answer": "input tensor",
        "question": "What is used to test if all elements ininputevaluate toTrue?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the input tensor return?": {
        "answer": "the minimum value of all elements in theinputtensor",
        "question": "What does the input tensor return?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value of the values ininput?": {
        "answer": "median",
        "question": "Returns what value of the values ininput?",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value ignoringNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "Returns what value ignoringNaNvalues?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What value of the values in input is returned?": {
        "answer": "median",
        "question": "What value of the values in input is returned?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned ignoringNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "What is returned ignoringNaNvalues?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the maximum value of all elements in the inputtensor?": {
        "answer": "input tensor",
        "question": "What returns the maximum value of all elements in the inputtensor?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the inputtensor return?": {
        "answer": "the p-norm of (input-other)",
        "question": "What does the inputtensor return?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the input tensor return ignoringNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "What does the input tensor return ignoringNaNvalues?",
        "context": "the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What value of all elements in theinputtensor is returned?": {
        "answer": "maximum value",
        "question": "What value of all elements in theinputtensor is returned?",
        "context": "Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the log of summed exponentials of each row of theinputtensor in the given dimensiondim?": {
        "answer": "p-norm",
        "question": "What is the log of summed exponentials of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value of all elements in theinputtensor?": {
        "answer": "minimum value",
        "question": "Returns what value of all elements in theinputtensor?",
        "context": "Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the median of the values ininput, ignoring what?": {
        "answer": "NaNvalues",
        "question": "Returns the median of the values ininput, ignoring what?",
        "context": "Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the minimum value of all elements in theinputtensor?": {
        "answer": "p-norm",
        "question": "What is the minimum value of all elements in theinputtensor?",
        "context": "Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned, ignoringNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "What is returned, ignoringNaNvalues?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the mode value of each row of theinputtensor in the given dimensiondim?": {
        "answer": "a namedtuple",
        "question": "What is the mode value of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim?": {
        "answer": "the p-norm of (input-other) Returns the log of summed exponentials",
        "question": "What returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of the values ininput, ignoringNaNvalues?": {
        "answer": "the median",
        "question": "Returns what of the values ininput, ignoringNaNvalues?",
        "context": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim?": {
        "answer": "p-norm",
        "question": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the mode value of a given tensor?": {
        "answer": "matrix norm or vector norm",
        "question": "What is the mode value of a given tensor?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return the log of summed exponentials of each row of theinputtensor in the given dimensiondim?": {
        "answer": "the p-norm",
        "question": "What does return the log of summed exponentials of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of the values ininput?": {
        "answer": "median",
        "question": "Returns what of the values ininput?",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does each row of the inputtensor in the given dimensiondim return?": {
        "answer": "the log of summed exponentials",
        "question": "What does each row of the inputtensor in the given dimensiondim return?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the function return?": {
        "answer": "the sum of all elements in theinputtensor",
        "question": "What does the function return?",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the mode value of each row of the inputtensor in the given dimensiondim?": {
        "answer": "a namedtuple",
        "question": "What is the mode value of each row of the inputtensor in the given dimensiondim?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of each row of theinputtensor in the given dimensiondim?": {
        "answer": "the log of summed exponentials",
        "question": "Returns what of each row of theinputtensor in the given dimensiondim?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value in the inputtensor?": {
        "answer": "mean value of all elements",
        "question": "Returns what value in the inputtensor?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the mean value of all elements in what?": {
        "answer": "theinputtensor",
        "question": "Returns the mean value of all elements in what?",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of norm does a given tensor return?": {
        "answer": "matrix norm or vector norm",
        "question": "What type of norm does a given tensor return?",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the sum of all elements, treating Not a Numbers (NaNs) as what?": {
        "answer": "zero",
        "question": "Returns the sum of all elements, treating Not a Numbers (NaNs) as what?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it return, ignoringNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "What does it return, ignoringNaNvalues?",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are Not a Numbers (NaNs) treated as?": {
        "answer": "zero",
        "question": "What are Not a Numbers (NaNs) treated as?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when calculating the sum of all elements in the inputtensor?": {
        "answer": "the product of all elements in theinputtensor",
        "question": "What is returned when calculating the sum of all elements in the inputtensor?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are the quantiles of each row of theinputtensor along the dimensiondim?": {
        "answer": "q-th",
        "question": "What are the quantiles of each row of theinputtensor along the dimensiondim?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the median of the values ininput, what?": {
        "answer": "ignoringNaNvalues",
        "question": "Returns the median of the values ininput, what?",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the what of a given tensor?": {
        "answer": "matrix norm or vector norm",
        "question": "Returns the what of a given tensor?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does this function check if allinputandothersatisfy the condition?": {
        "answer": "Returns the indices that sort a tensor along a given dimension in ascending order by value",
        "question": "What does this function check if allinputandothersatisfy the condition?",
        "context": "This function checks if allinputandothersatisfy the condition:   Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "If two tensors have the same size and elements, what is element-wise equality?": {
        "answer": "Trueif two tensors have the same size and elements",
        "question": "If two tensors have the same size and elements, what is element-wise equality?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns the indices that sort a tensor along a given dimension in ascending order by": {
        "answer": "Alias fortorch.ge()",
        "question": "What is the name of the function that returns the indices that sort a tensor along a given dimension in ascending order by",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.gt() do?": {
        "answer": "Computesinput",
        "question": "What does Alias fortorch.gt() do?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function checks if allinputandothersatisfy the condition?": {
        "answer": "Alias fortorch.gt()",
        "question": "What function checks if allinputandothersatisfy the condition?",
        "context": "This function checks if allinputandothersatisfy the condition:   Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computes othertextinput > textotherinput>otherelement-": {
        "answer": "Alias fortorch.gt()",
        "question": "What is the name of the function that computes othertextinput > textotherinput>otherelement-",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is true if two tensors have the same size and elements?": {
        "answer": "Trueif two tensors have the same size and elements",
        "question": "What is true if two tensors have the same size and elements?",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computes othertextinput geq textotherinputother": {
        "answer": "Alias fortorch.ge()",
        "question": "What is the name of the function that computes othertextinput geq textotherinputother",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.ge() do?": {
        "answer": "Computesinput",
        "question": "What does Alias fortorch.ge() do?",
        "context": "Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computesinput>othertextinput > textotherinputother": {
        "answer": "Alias fortorch.gt()",
        "question": "What is the name of the function that computesinput>othertextinput > textotherinputother",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return a new tensor with if each element ofinputis \"close\" to the corresponding element ofother?": {
        "answer": "boolean elements",
        "question": "What does return a new tensor with if each element ofinputis \"close\" to the corresponding element ofother?",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what representation if each element isfiniteor not?": {
        "answer": "boolean elements",
        "question": "Returns a new tensor with what representation if each element isfiniteor not?",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Computesinput>othertextinput > textotherinput>otherelement-wise?": {
        "answer": "Alias fortorch.ge()",
        "question": "What does Computesinput>othertextinput > textotherinput>otherelement-wise?",
        "context": "Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computesinput>othertextinput > textotherinput>other": {
        "answer": "Alias fortorch.gt()",
        "question": "What is the name of the function that computesinput>othertextinput > textotherinput>other",
        "context": "Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what?": {
        "answer": "elements ofinputat the given indices",
        "question": "Returns a new tensor with what?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Tests if each element ofinputis what?": {
        "answer": "positive infinity",
        "question": "Tests if each element ofinputis what?",
        "context": "Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Tests if each element ofinputis what or not?": {
        "answer": "positive infinity",
        "question": "Tests if each element ofinputis what or not?",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the Alias fortorch.gt() do?": {
        "answer": "Computesinput",
        "question": "What does the Alias fortorch.gt() do?",
        "context": "Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computes input>othertextinput > textotherinput>othere": {
        "answer": "Alias fortorch.gt()",
        "question": "What is the name of the function that computes input>othertextinput > textotherinput>othere",
        "context": "Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with boolean elements?": {
        "answer": "Alias fortorch.gt()",
        "question": "What is the name of the function that returns a new tensor with boolean elements?",
        "context": "Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the value of each element of input?": {
        "answer": "infinite",
        "question": "What is the value of each element of input?",
        "context": "Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.gt() do if each element ofinputis negative infinity or not?": {
        "answer": "Tests",
        "question": "What does Alias fortorch.gt() do if each element ofinputis negative infinity or not?",
        "context": "Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a new tensor with boolean elements represent?": {
        "answer": "if each element ofinputis \u201cclose\u201d to the corresponding element ofother",
        "question": "What does a new tensor with boolean elements represent?",
        "context": "Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Is each element ofinput positive or negative infinity or not?": {
        "answer": "infinite",
        "question": "Is each element ofinput positive or negative infinity or not?",
        "context": "Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Tests if each element ofinputis what infinity or not?": {
        "answer": "negative",
        "question": "Tests if each element ofinputis what infinity or not?",
        "context": "Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what representation if each element ofinputis close to the corresponding element ofother?": {
        "answer": "boolean elements",
        "question": "Returns a new tensor with what representation if each element ofinputis close to the corresponding element ofother?",
        "context": "Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Is each element of input infinite or not?": {
        "answer": "infinite",
        "question": "Is each element of input infinite or not?",
        "context": "Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do if each element ofinputis negative infinity or not?": {
        "answer": "Tests",
        "question": "What does it do if each element ofinputis negative infinity or not?",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do if each element ofinputis positive infinity or not?": {
        "answer": "Tests",
        "question": "What does it do if each element ofinputis positive infinity or not?",
        "context": "Returns the indices that sort a tensor along a given dimension in ascending order by value.   Computes element-wise equality   Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What element represents if each element ofinputis NaN or not?": {
        "answer": "boolean elements",
        "question": "What element represents if each element ofinputis NaN or not?",
        "context": "Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what representation if each element ofinputis real-valued or not?": {
        "answer": "boolean elements",
        "question": "Returns a new tensor with what representation if each element ofinputis real-valued or not?",
        "context": "Trueif two tensors have the same size and elements,Falseotherwise.   Computesinput\u2265other\\text{input} \\geq \\text{other}input\u2265otherelement-wise.   Alias fortorch.ge().   Computesinput>other\\text{input} > \\text{other}input>otherelement-wise.   Alias fortorch.gt().   Returns a new tensor with boolean elements representing if each element ofinputis \u201cclose\u201d to the corresponding element ofother.   Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what elements?": {
        "answer": "boolean elements",
        "question": "Returns a new tensor with what elements?",
        "context": "Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the value of each element ofinput?": {
        "answer": "infinite",
        "question": "What is the value of each element ofinput?",
        "context": "Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the infinity of each element ofinput?": {
        "answer": "negative",
        "question": "What is the infinity of each element ofinput?",
        "context": "Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with boolean elements representing if each element ofinputis what?": {
        "answer": "NaN",
        "question": "Returns a new tensor with boolean elements representing if each element ofinputis what?",
        "context": "Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with boolean elements representing if each element ofinput is what?": {
        "answer": "real-valued",
        "question": "Returns a new tensor with boolean elements representing if each element ofinput is what?",
        "context": "Returns a new tensor with boolean elements representing if each element isfiniteor not.   Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Is each element of input infinite or infinite?": {
        "answer": "infinite",
        "question": "Is each element of input infinite or infinite?",
        "context": "Tests if each element ofinputis infinite (positive or negative infinity) or not.   Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what type of elements?": {
        "answer": "boolean elements",
        "question": "Returns a new tensor with what type of elements?",
        "context": "Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what elements representing if each element ofinputis NaN or not?": {
        "answer": "boolean",
        "question": "Returns a new tensor with what elements representing if each element ofinputis NaN or not?",
        "context": "Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensor that returns the smallest element of each row of the inputtensor in the given dimensiondim": {
        "answer": "namedtuple",
        "question": "What is the name of the tensor that returns the smallest element of each row of the inputtensor in the given dimensiondim",
        "context": "Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensor wherevaluesis thekth smallest element of each row of the inputtensor in the": {
        "answer": "namedtuple",
        "question": "What is the name of the tensor wherevaluesis thekth smallest element of each row of the inputtensor in the",
        "context": "Tests if each element ofinputis positive infinity or not.   Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do if each element ofinput is negative infinity or not?": {
        "answer": "Tests",
        "question": "What does it do if each element ofinput is negative infinity or not?",
        "context": "Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the value of a namedtuple?": {
        "answer": "thekth smallest element of each row of theinputtensor in the given dimensiondim",
        "question": "What is the value of a namedtuple?",
        "context": "Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computesinputothertextinput leq textotherin": {
        "answer": "Alias fortorch.le()",
        "question": "What is the name of the function that computesinputothertextinput leq textotherin",
        "context": "Tests if each element ofinputis negative infinity or not.   Returns a new tensor with boolean elements representing if each element ofinputis NaN or not.   Returns a new tensor with boolean elements representing if each element ofinputis real-valued or not.   Returns a namedtuple(values,indices)wherevaluesis thekth smallest element of each row of theinputtensor in the given dimensiondim.   Computesinput\u2264other\\text{input} \\leq \\text{other}input\u2264otherelement-wise.   Alias fortorch.le().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is STFT?": {
        "answer": "Short-time Fourier transform",
        "question": "What is STFT?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the short time Fourier Transform?": {
        "answer": "Inverse",
        "question": "What is the short time Fourier Transform?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Who created the Blackman window function?": {
        "answer": "Bartlett",
        "question": "Who created the Blackman window function?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which window function computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta?": {
        "answer": "Hann",
        "question": "Which window function computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the Kaiser window computed with?": {
        "answer": "window lengthwindow_lengthand shape parameterbeta",
        "question": "What is the Kaiser window computed with?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is another name for Short-time Fourier transform?": {
        "answer": "Inverse short time Fourier Transform",
        "question": "What is another name for Short-time Fourier transform?",
        "context": "  Short-time Fourier transform (STFT).   Inverse short time Fourier Transform.   Bartlett window function.   Blackman window function.   Hamming window function.   Hann window function.   Computes the Kaiser window with window lengthwindow_lengthand shape parameterbeta. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the view of each input tensor with zero dimensions?": {
        "answer": "3-dimensional",
        "question": "What is the view of each input tensor with zero dimensions?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does each value count in an array of non-negative ints?": {
        "answer": "frequency",
        "question": "What does each value count in an array of non-negative ints?",
        "context": "Returns a 1-dimensional view of each input tensor with zero dimensions.   Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do with provided tensors?": {
        "answer": "Create a block diagonal matrix",
        "question": "What does it do with provided tensors?",
        "context": "Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Broadcast the given tensors according to?": {
        "answer": "Broadcasting semantics",
        "question": "What does Broadcast the given tensors according to?",
        "context": "Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Broadcastsinputto what?": {
        "answer": "shapeshape",
        "question": "Broadcastsinputto what?",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of input is Broadcast_tensors() used for?": {
        "answer": "shapes",
        "question": "What type of input is Broadcast_tensors() used for?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Count the what of each value in an array of non-negative ints?": {
        "answer": "frequency",
        "question": "Count the what of each value in an array of non-negative ints?",
        "context": "Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a 3-dimensional view of each input tensor with what dimension?": {
        "answer": "zero",
        "question": "Returns a 3-dimensional view of each input tensor with what dimension?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the count of each value in an array of non-negative ints?": {
        "answer": "frequency",
        "question": "What is the count of each value in an array of non-negative ints?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What do you do with the provided tensors?": {
        "answer": "Create a block diagonal matrix",
        "question": "What do you do with the provided tensors?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of input is broadcasted?": {
        "answer": "shapeshape",
        "question": "What type of input is broadcasted?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are the indices of the buckets to which each value in the inputbelongs?": {
        "answer": "the boundaries of the buckets are set byboundaries",
        "question": "Where are the indices of the buckets to which each value in the inputbelongs?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the same as Broadcast_tensors() but for?": {
        "answer": "shapes",
        "question": "What is the same as Broadcast_tensors() but for?",
        "context": "Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are the indices of the buckets to which each value in theinputbelongs?": {
        "answer": "the boundaries of the buckets are set byboundaries",
        "question": "Where are the indices of the buckets to which each value in theinputbelongs?",
        "context": "Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the given sequence of tensors?": {
        "answer": "Do cartesian product",
        "question": "What is the name of the given sequence of tensors?",
        "context": "Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is batched between each pair of the two collections of row vectors?": {
        "answer": "p-norm distance",
        "question": "What is batched between each pair of the two collections of row vectors?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when calculating the p-norm distance between each pair of the two collections of row vectors?": {
        "answer": "copy ofinput",
        "question": "What is returned when calculating the p-norm distance between each pair of the two collections of row vectors?",
        "context": "Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the input to the shapeshape?": {
        "answer": "Broadcastsinput",
        "question": "What is the name of the input to the shapeshape?",
        "context": "Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Broadcastsinputto what shape?": {
        "answer": "shapes",
        "question": "Broadcastsinputto what shape?",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Broadcastsinput return?": {
        "answer": "the indices of the buckets",
        "question": "What does Broadcastsinput return?",
        "context": "Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned by Broadcastsinput to the shapeshape?": {
        "answer": "Do cartesian product of the given sequence of tensors",
        "question": "What is returned by Broadcastsinput to the shapeshape?",
        "context": "Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes batched what?": {
        "answer": "p-norm distance between each pair of the two collections of row vectors",
        "question": "Computes batched what?",
        "context": "Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when the p-norm distance between each pair of row vectors is computed?": {
        "answer": "a copy ofinput",
        "question": "What is returned when the p-norm distance between each pair of row vectors is computed?",
        "context": "Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do to return a copy ofinput?": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "What does it do to return a copy ofinput?",
        "context": "Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the product of the given sequence of tensors?": {
        "answer": "Do cartesian",
        "question": "What is the product of the given sequence of tensors?",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the function that returns the cross product of vectors in dimensiondimofinputandother?": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "What is the function that returns the cross product of vectors in dimensiondimofinputandother?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does dimensiondimofinputandother return?": {
        "answer": "the cross product of vectors",
        "question": "What does dimensiondimofinputandother return?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the cumulative maximum of elements ofinputin the dimensiondim?": {
        "answer": "a namedtuple",
        "question": "What is the cumulative maximum of elements ofinputin the dimensiondim?",
        "context": "Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the cumulative maximum of elements ofinputin the dimensiondim?": {
        "answer": "namedtuple",
        "question": "What returns the cumulative maximum of elements ofinputin the dimensiondim?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the cumulative minimum of elements ofinputin the dimensiondim?": {
        "answer": "namedtuple",
        "question": "What returns the cumulative minimum of elements ofinputin the dimensiondim?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when a namedtuple(values,indices) returns the cumulative minimum of elements ofinputin the dimensiondim": {
        "answer": "cumulative product of elements ofinputin the dimensiondim",
        "question": "What is returned when a namedtuple(values,indices) returns the cumulative minimum of elements ofinputin the dimensiondim",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns the cumulative product of elements ofinputin the dimensiondim?": {
        "answer": "the cumulative sum of elements ofinputin the dimensiondim",
        "question": "What does Returns the cumulative product of elements ofinputin the dimensiondim?",
        "context": "Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the sum of elements ofinputin the dimensiondim?": {
        "answer": "cumulative product",
        "question": "What is the sum of elements ofinputin the dimensiondim?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when a namedtuple(values,indices) returns the cumulative product of elements ofinputin the dimensiondim": {
        "answer": "cumulative sum of elements ofinputin the dimensiondim",
        "question": "What is returned when a namedtuple(values,indices) returns the cumulative product of elements ofinputin the dimensiondim",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is reduced in the batch matrix-matrix product of matrices stored inbatch1andbatch2?": {
        "answer": "add step",
        "question": "What is reduced in the batch matrix-matrix product of matrices stored inbatch1andbatch2?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is performed of the matricesmat1andmat2?": {
        "answer": "matrix multiplication",
        "question": "What is performed of the matricesmat1andmat2?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the matrixmatand the vectorvec perform?": {
        "answer": "matrix-vector product",
        "question": "What does the matrixmatand the vectorvec perform?",
        "context": "Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it perform and adds it to the matrixinput?": {
        "answer": "outer-product of vectorsvec1andvec2",
        "question": "What does it perform and adds it to the matrixinput?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it perform of matrices inbatch1andbatch2?": {
        "answer": "batch matrix-matrix product",
        "question": "What does it perform of matrices inbatch1andbatch2?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens to all matrix multiplications along the first dimension?": {
        "answer": "all matrix multiplications get accumulated along the first dimension",
        "question": "What happens to all matrix multiplications along the first dimension?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the matrix multiplication of matrices perform?": {
        "answer": "matricesmat1andmat2",
        "question": "What does the matrix multiplication of matrices perform?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of the matrixmatand the vectorvec?": {
        "answer": "matrix-vector product",
        "question": "What product of the matrixmatand the vectorvec?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens to the outer-product of vectorsvec1andvec2?": {
        "answer": "adds it to the matrixinput",
        "question": "What happens to the outer-product of vectorsvec1andvec2?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the matrices that performs a batch matrix-matrix product?": {
        "answer": "inbatch1andbatch2",
        "question": "What is the name of the matrices that performs a batch matrix-matrix product?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what of the matricesmat1 andmat2?": {
        "answer": "matrix multiplication",
        "question": "Performs what of the matricesmat1 andmat2?",
        "context": "Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of vectorsvec1 andvec2 is added to the matrixinput?": {
        "answer": "outer-product",
        "question": "What product of vectorsvec1 andvec2 is added to the matrixinput?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What performs a batch matrix-matrix product of matrices stored ininputandmat2?": {
        "answer": "batch matrix-matrix product of matrices inbatch1andbatch2.",
        "question": "What performs a batch matrix-matrix product of matrices stored ininputandmat2?",
        "context": "Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are matrices stored?": {
        "answer": "ininputandmat2",
        "question": "Where are matrices stored?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the matrix product of?": {
        "answer": "NNN2-D tensors",
        "question": "What is the matrix product of?",
        "context": "Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is performed of the matrixmatand the vectorvec?": {
        "answer": "matrix-vector product",
        "question": "What is performed of the matrixmatand the vectorvec?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the matrix-vector product of matrices perform?": {
        "answer": "batch matrix-matrix product of matrices inbatch1andbatch2",
        "question": "What does the matrix-vector product of matrices perform?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the matrix product of what?": {
        "answer": "NNN2-D tensors",
        "question": "Returns the matrix product of what?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Who computes the decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices": {
        "answer": "Cholesky",
        "question": "Who computes the decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs the outer-product of what and adds it to the matrixinput?": {
        "answer": "vectorsvec1andvec2",
        "question": "Performs the outer-product of what and adds it to the matrixinput?",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What performs the outer-product of vectorsvec1 andvec2?": {
        "answer": "batch matrix-matrix product of matrices inbatch1andbatch2",
        "question": "What performs the outer-product of vectorsvec1 andvec2?",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What decomposition of a symmetric positive-definite matrixAAor is computed for batches of symmetric positive-definite matrices": {
        "answer": "Cholesky",
        "question": "What decomposition of a symmetric positive-definite matrixAAor is computed for batches of symmetric positive-definite matrices",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the inverse of a symmetric positive-definite matrix?": {
        "answer": "returns matrixinv",
        "question": "What returns the inverse of a symmetric positive-definite matrix?",
        "context": " Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a linear system of equations with a positive semidefinite matrix to be inverted do?": {
        "answer": "Solves",
        "question": "What does a linear system of equations with a positive semidefinite matrix to be inverted do?",
        "context": "Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is used to perform a batch matrix-matrix product?": {
        "answer": "matrices stored ininputandmat2",
        "question": "What is used to perform a batch matrix-matrix product?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the matrix product of theNNN2-D tensors?": {
        "answer": "Returns the matrix product of theNNN2-D tensors",
        "question": "What returns the matrix product of theNNN2-D tensors?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices": {
        "answer": "Cholesky",
        "question": "Computes the decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the inverse of a symmetric positive-definite matrixAAAusing what?": {
        "answer": "Cholesky factoruuu",
        "question": "Computes the inverse of a symmetric positive-definite matrixAAAusing what?",
        "context": "Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu(). ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Solves what with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu?": {
        "answer": "a linear system of equations",
        "question": "Solves what with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu?",
        "context": "Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the Cholesky factoruuu return?": {
        "answer": "returns matrixinv",
        "question": "What does the Cholesky factoruuu return?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the Cholesky factoruuu compute?": {
        "answer": "dot product of two 1D tensors",
        "question": "What does the Cholesky factoruuu compute?",
        "context": "Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of theNNN2-D tensors?": {
        "answer": "matrix product",
        "question": "Returns what of theNNN2-D tensors?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu return?": {
        "answer": "matrixinv",
        "question": "What does the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu return?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the Cholesky decomposition of for batches of symmetric positive-definite matrices?": {
        "answer": "symmetric positive-definite matrixAAAor",
        "question": "What is the Cholesky decomposition of for batches of symmetric positive-definite matrices?",
        "context": "Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the inverse of a symmetric positive-definite matrix do?": {
        "answer": "returns matrixinv",
        "question": "What does the inverse of a symmetric positive-definite matrix do?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a real square matrix compute?": {
        "answer": "eigenvalues and eigenvectors",
        "question": "What does a real square matrix compute?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned by Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu?": {
        "answer": "matrixinv",
        "question": "What is returned by Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu?",
        "context": "Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what of a real square matrix?": {
        "answer": "eigenvalues and eigenvectors",
        "question": "Computes what of a real square matrix?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Solves a linear system of equations with a positive semidefinite matrix to be inverted given what?": {
        "answer": "Cholesky factor matrixuuu",
        "question": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given what?",
        "context": " Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the dot product of two 1D tensors?": {
        "answer": "dot product of two 1D tensors",
        "question": "What is the dot product of two 1D tensors?",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does this low-level function call directly?": {
        "answer": "LAPACK\u2019s geqrf",
        "question": "What does this low-level function call directly?",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the low-level function for calling LAPACK's geqrf directly?": {
        "answer": "Alias oftorch.outer()",
        "question": "What is the low-level function for calling LAPACK's geqrf directly?",
        "context": " Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the dot product for?": {
        "answer": "1D tensors",
        "question": "What is the dot product for?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the matrixuuu of a positive semidefinite matrix?": {
        "answer": "Cholesky factor",
        "question": "What is the matrixuuu of a positive semidefinite matrix?",
        "context": " Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is this function for calling LAPACK's geqrf directly?": {
        "answer": "low-level function",
        "question": "What is this function for calling LAPACK's geqrf directly?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the dot product for what?": {
        "answer": "1D tensors",
        "question": "Computes the dot product for what?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a linear system of equations with a positive semidefinite matrix have to be inverted given?": {
        "answer": "Cholesky factor matrixuuu",
        "question": "What does a linear system of equations with a positive semidefinite matrix have to be inverted given?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does this function compute?": {
        "answer": "the base two exponential function ofinput",
        "question": "What does this function compute?",
        "context": "Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the eigenvalues and eigenvectors of what?": {
        "answer": "real square matrix",
        "question": "Computes the eigenvalues and eigenvectors of what?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias oftorch.outer compute the dot product for?": {
        "answer": "1D tensors",
        "question": "What does Alias oftorch.outer compute the dot product for?",
        "context": "Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that computes the dot product for 1D tensors?": {
        "answer": "Alias oftorch.outer()",
        "question": "What is the name of the function that computes the dot product for 1D tensors?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "A linear system of equations with a positive semidefinite matrix to be inverted given what matrix?": {
        "answer": "Cholesky factor matrix",
        "question": "A linear system of equations with a positive semidefinite matrix to be inverted given what matrix?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the low-level function for calling LAPACK\u2019s geqrf directly?": {
        "answer": "Alias oftorch.outer()",
        "question": "What is the low-level function for calling LAPACK\u2019s geqrf directly?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a low-level function for calling LAPACK\u2019s geqrf directly?": {
        "answer": "eigenvalues and eigenvectors of a real square matrix",
        "question": "What is a low-level function for calling LAPACK\u2019s geqrf directly?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is this function for calling LAPACK\u2019s geqrf directly?": {
        "answer": "low-level function",
        "question": "What is this function for calling LAPACK\u2019s geqrf directly?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias oftorch.outer() compute the dot product for?": {
        "answer": "1D tensors",
        "question": "What does Alias oftorch.outer() compute the dot product for?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.linalg.det() call?": {
        "answer": "Alias fortorch.linalg.inv()",
        "question": "What does Alias fortorch.linalg.det() call?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the eigenvalues and eigenvectors of a real square matrix?": {
        "answer": "dot product",
        "question": "Computes the eigenvalues and eigenvectors of a real square matrix?",
        "context": "Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Is this a low-level function for calling LAPACK's geqrf directly?": {
        "answer": "low-level function",
        "question": "Is this a low-level function for calling LAPACK's geqrf directly?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What calculates the dot product for 1D tensors?": {
        "answer": "Alias oftorch.outer()",
        "question": "What calculates the dot product for 1D tensors?",
        "context": "Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.linalg.det() calculate of a square matrix or batches of square matrices": {
        "answer": "log determinant",
        "question": "What does Alias fortorch.linalg.det() calculate of a square matrix or batches of square matrices",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What calculates the log determinant of a square matrix or batches of square matrices?": {
        "answer": "Alias fortorch.linalg.slogdet",
        "question": "What calculates the log determinant of a square matrix or batches of square matrices?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.linalg.det() calculate?": {
        "answer": "log determinant",
        "question": "What does Alias fortorch.linalg.det() calculate?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What computes the dot product for 1D tensors?": {
        "answer": "Alias oftorch.outer()",
        "question": "What computes the dot product for 1D tensors?",
        "context": "  Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the dot product for 1D tensors?": {
        "answer": "Alias oftorch.outer()",
        "question": "Computes the dot product for 1D tensors?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a low-level function for calling LAPACK's geqrf directly?": {
        "answer": "Alias oftorch.outer()",
        "question": "What is a low-level function for calling LAPACK's geqrf directly?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias oftorch.outer() do?": {
        "answer": "Computes the dot product for 1D tensors",
        "question": "What does Alias oftorch.outer() do?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What problems does Alias fortorch.linalg.slogdet() solve?": {
        "answer": "least squares and least norm problems",
        "question": "What problems does Alias fortorch.linalg.slogdet() solve?",
        "context": "  Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what of a matrix or batches of matricesA?": {
        "answer": "LU factorization",
        "question": "Computes what of a matrix or batches of matricesA?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the smallest size and scalar kind?": {
        "answer": "thetorch.dtype",
        "question": "What returns the smallest size and scalar kind?",
        "context": "  Returns thetorch.dtypewith the smallest size and scalar kind that is not smaller nor of lower kind than eithertype1ortype2.   Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms.   Returns True if the global deterministic flag is turned on.   When this flag is False (default) then some PyTorch warnings may only appear once per process.   Returns True if the global warn_always flag is turned on.   A wrapper around Python\u2019s assert which is symbolically traceable. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does thetorch.dtype do?": {
        "answer": "Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms",
        "question": "What does thetorch.dtype do?",
        "context": "  Returns thetorch.dtypewith the smallest size and scalar kind that is not smaller nor of lower kind than eithertype1ortype2.   Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms.   Returns True if the global deterministic flag is turned on.   When this flag is False (default) then some PyTorch warnings may only appear once per process.   Returns True if the global warn_always flag is turned on.   A wrapper around Python\u2019s assert which is symbolically traceable. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "If the global deterministic flag is turned on, what does it return?": {
        "answer": "True",
        "question": "If the global deterministic flag is turned on, what does it return?",
        "context": "  Returns thetorch.dtypewith the smallest size and scalar kind that is not smaller nor of lower kind than eithertype1ortype2.   Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms.   Returns True if the global deterministic flag is turned on.   When this flag is False (default) then some PyTorch warnings may only appear once per process.   Returns True if the global warn_always flag is turned on.   A wrapper around Python\u2019s assert which is symbolically traceable. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "When the global deterministic flag is turned on, some PyTorch warnings may only appear how many times per process?": {
        "answer": "once per process",
        "question": "When the global deterministic flag is turned on, some PyTorch warnings may only appear how many times per process?",
        "context": "  Returns thetorch.dtypewith the smallest size and scalar kind that is not smaller nor of lower kind than eithertype1ortype2.   Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms.   Returns True if the global deterministic flag is turned on.   When this flag is False (default) then some PyTorch warnings may only appear once per process.   Returns True if the global warn_always flag is turned on.   A wrapper around Python\u2019s assert which is symbolically traceable. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what if the global warn_always flag is turned on?": {
        "answer": "True",
        "question": "Returns what if the global warn_always flag is turned on?",
        "context": "  Returns thetorch.dtypewith the smallest size and scalar kind that is not smaller nor of lower kind than eithertype1ortype2.   Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms.   Returns True if the global deterministic flag is turned on.   When this flag is False (default) then some PyTorch warnings may only appear once per process.   Returns True if the global warn_always flag is turned on.   A wrapper around Python\u2019s assert which is symbolically traceable. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "A wrapper around what's assert which is symbolically traceable?": {
        "answer": "Python",
        "question": "A wrapper around what's assert which is symbolically traceable?",
        "context": "  Returns thetorch.dtypewith the smallest size and scalar kind that is not smaller nor of lower kind than eithertype1ortype2.   Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms.   Returns True if the global deterministic flag is turned on.   When this flag is False (default) then some PyTorch warnings may only appear once per process.   Returns True if the global warn_always flag is turned on.   A wrapper around Python\u2019s assert which is symbolically traceable. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Warning More than one element of a created tensor may refer to what?": {
        "answer": "a single memory location",
        "question": "Warning More than one element of a created tensor may refer to what?",
        "context": "Warning More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What can in-place operations result in?": {
        "answer": "incorrect behavior",
        "question": "What can in-place operations result in?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What should you do if you need to write to the tensors?": {
        "answer": "clone them first",
        "question": "What should you do if you need to write to the tensors?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What returns a view of a tensor?": {
        "answer": "PyTorch functions",
        "question": "What returns a view of a tensor?",
        "context": "Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. size(tupleorints) \u2013 the shape of the output tensor stride(tupleorints) \u2013 the stride of the output tensor storage_offset(int,optional) \u2013 the offset in the underlying storage of the output tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "Why are the functions liketorch.Tensor.expand() more advisable to use?": {
        "answer": "easier to read",
        "question": "Why are the functions liketorch.Tensor.expand() more advisable to use?",
        "context": "Warning More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "More than one element of a created tensor may refer to what?": {
        "answer": "single memory location",
        "question": "More than one element of a created tensor may refer to what?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What may result in incorrect behavior?": {
        "answer": "in-place operations",
        "question": "What may result in incorrect behavior?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What should you do if you need to write to the tensors first?": {
        "answer": "clone",
        "question": "What should you do if you need to write to the tensors first?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What are PyTorch functions that return a view of a tensor called?": {
        "answer": "liketorch.Tensor.expand()",
        "question": "What are PyTorch functions that return a view of a tensor called?",
        "context": "Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. size(tupleorints) \u2013 the shape of the output tensor stride(tupleorints) \u2013 the stride of the output tensor storage_offset(int,optional) \u2013 the offset in the underlying storage of the output tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "Why is liketorch.Tensor.expand() more advisable to use?": {
        "answer": "easier to read",
        "question": "Why is liketorch.Tensor.expand() more advisable to use?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "More than one element of a created tensor may refer to a single what?": {
        "answer": "memory location",
        "question": "More than one element of a created tensor may refer to a single what?",
        "context": "More than one element of a created tensor may refer to a single memory\nlocation. As a result, in-place operations (especially ones that are\nvectorized) may result in incorrect behavior. If you need to write to\nthe tensors, please clone them first. Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "Why are PyTorch functions liketorch.Tensor.expand() more advisable to use?": {
        "answer": "easier to read",
        "question": "Why are PyTorch functions liketorch.Tensor.expand() more advisable to use?",
        "context": "Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. size(tupleorints) \u2013 the shape of the output tensor stride(tupleorints) \u2013 the stride of the output tensor storage_offset(int,optional) \u2013 the offset in the underlying storage of the output tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What is the shape of the output tensor stride?": {
        "answer": "size(tupleorints)",
        "question": "What is the shape of the output tensor stride?",
        "context": "Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. size(tupleorints) \u2013 the shape of the output tensor stride(tupleorints) \u2013 the stride of the output tensor storage_offset(int,optional) \u2013 the offset in the underlying storage of the output tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What is size(tupleorints)?": {
        "answer": "the shape of the output tensor stride(tupleorints)",
        "question": "What is size(tupleorints)?",
        "context": "Many PyTorch functions, which return a view of a tensor, are internally\nimplemented with this function. Those functions, liketorch.Tensor.expand(), are easier to read and are therefore more\nadvisable to use. input(Tensor) \u2013 the input tensor. size(tupleorints) \u2013 the shape of the output tensor stride(tupleorints) \u2013 the stride of the output tensor storage_offset(int,optional) \u2013 the offset in the underlying storage of the output tensor Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided"
    },
    "What is a transposed version of input?": {
        "answer": "tensor",
        "question": "What is a transposed version of input?",
        "context": "Returns a tensor that is a transposed version ofinput.\nThe given dimensionsdim0anddim1are swapped. The resultingouttensor shares its underlying storage with theinputtensor, so changing the content of one would change the content\nof the other. input(Tensor) \u2013 the input tensor. dim0(int) \u2013 the first dimension to be transposed dim1(int) \u2013 the second dimension to be transposed Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose"
    },
    "What happens when a tensor is a transposed version of input?": {
        "answer": "dimensionsdim0anddim1are swapped",
        "question": "What happens when a tensor is a transposed version of input?",
        "context": "Returns a tensor that is a transposed version ofinput.\nThe given dimensionsdim0anddim1are swapped. The resultingouttensor shares its underlying storage with theinputtensor, so changing the content of one would change the content\nof the other. input(Tensor) \u2013 the input tensor. dim0(int) \u2013 the first dimension to be transposed dim1(int) \u2013 the second dimension to be transposed Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose"
    },
    "The resultingouttensor shares its underlying storage with what?": {
        "answer": "theinputtensor",
        "question": "The resultingouttensor shares its underlying storage with what?",
        "context": "Returns a tensor that is a transposed version ofinput.\nThe given dimensionsdim0anddim1are swapped. The resultingouttensor shares its underlying storage with theinputtensor, so changing the content of one would change the content\nof the other. input(Tensor) \u2013 the input tensor. dim0(int) \u2013 the first dimension to be transposed dim1(int) \u2013 the second dimension to be transposed Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose"
    },
    "What is the second dimension to be transposed?": {
        "answer": "dim1(int)",
        "question": "What is the second dimension to be transposed?",
        "context": "Returns a tensor that is a transposed version ofinput.\nThe given dimensionsdim0anddim1are swapped. The resultingouttensor shares its underlying storage with theinputtensor, so changing the content of one would change the content\nof the other. input(Tensor) \u2013 the input tensor. dim0(int) \u2013 the first dimension to be transposed dim1(int) \u2013 the second dimension to be transposed Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose"
    },
    "Returns the cross product of vectors in what?": {
        "answer": "dimensiondimofinputandother",
        "question": "Returns the cross product of vectors in what?",
        "context": "Returns the cross product of vectors in dimensiondimofinputandother. inputandothermust have the same size, and the size of theirdimdimension should be 3. Ifdimis not given, it defaults to the first dimension found with the\nsize 3. Note that this might be unexpected. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor dim(int,optional) \u2013 the dimension to take the cross-product in. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross"
    },
    "The size of theirdimdimension should be what?": {
        "answer": "3",
        "question": "The size of theirdimdimension should be what?",
        "context": "Returns the cross product of vectors in dimensiondimofinputandother. inputandothermust have the same size, and the size of theirdimdimension should be 3. Ifdimis not given, it defaults to the first dimension found with the\nsize 3. Note that this might be unexpected. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor dim(int,optional) \u2013 the dimension to take the cross-product in. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross"
    },
    "Ifdimis is not given, what happens?": {
        "answer": "defaults to the first dimension found with the size 3",
        "question": "Ifdimis is not given, what happens?",
        "context": "Returns the cross product of vectors in dimensiondimofinputandother. inputandothermust have the same size, and the size of theirdimdimension should be 3. Ifdimis not given, it defaults to the first dimension found with the\nsize 3. Note that this might be unexpected. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor dim(int,optional) \u2013 the dimension to take the cross-product in. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross"
    },
    "What might happen if the size of inputandother is not given?": {
        "answer": "unexpected",
        "question": "What might happen if the size of inputandother is not given?",
        "context": "Returns the cross product of vectors in dimensiondimofinputandother. inputandothermust have the same size, and the size of theirdimdimension should be 3. Ifdimis not given, it defaults to the first dimension found with the\nsize 3. Note that this might be unexpected. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor dim(int,optional) \u2013 the dimension to take the cross-product in. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross"
    },
    "What is the second input tensor dim(int,optional)?": {
        "answer": "other(Tensor)",
        "question": "What is the second input tensor dim(int,optional)?",
        "context": "Returns the cross product of vectors in dimensiondimofinputandother. inputandothermust have the same size, and the size of theirdimdimension should be 3. Ifdimis not given, it defaults to the first dimension found with the\nsize 3. Note that this might be unexpected. input(Tensor) \u2013 the input tensor. other(Tensor) \u2013 the second input tensor dim(int,optional) \u2013 the dimension to take the cross-product in. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross"
    },
    "How far can a n-D tensor be rotated?": {
        "answer": "90 degrees",
        "question": "How far can a n-D tensor be rotated?",
        "context": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\nRotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0. input(Tensor) \u2013 the input tensor. k(int) \u2013 number of times to rotate dims(a listortuple) \u2013 axis to rotate Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90"
    },
    "What is the number of times to rotate dims?": {
        "answer": "k(int)",
        "question": "What is the number of times to rotate dims?",
        "context": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\nRotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0. input(Tensor) \u2013 the input tensor. k(int) \u2013 number of times to rotate dims(a listortuple) \u2013 axis to rotate Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90"
    },
    "Rotate a n-D tensor by what degree in the plane specified by dims axis?": {
        "answer": "90 degrees",
        "question": "Rotate a n-D tensor by what degree in the plane specified by dims axis?",
        "context": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\nRotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0. input(Tensor) \u2013 the input tensor. k(int) \u2013 number of times to rotate dims(a listortuple) \u2013 axis to rotate Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90"
    },
    "What does a listortuple represent?": {
        "answer": "axis",
        "question": "What does a listortuple represent?",
        "context": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.\nRotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0. input(Tensor) \u2013 the input tensor. k(int) \u2013 number of times to rotate dims(a listortuple) \u2013 axis to rotate Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90"
    },
    "What does asscatter_() do?": {
        "answer": "Adds all values from the tensorotherintoself",
        "question": "What does asscatter_() do?",
        "context": "Adds all values from the tensorotherintoselfat the indices\nspecified in theindextensor in a similar fashion asscatter_(). For each value insrc, it is added to\nan index inselfwhich is specified by its index insrcfordimension!=dimand by the corresponding value inindexfordimension=dim. For a 3-D tensor,selfis updated as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "For each value insrc, it is added to what?": {
        "answer": "index inself",
        "question": "For each value insrc, it is added to what?",
        "context": "Adds all values from the tensorotherintoselfat the indices\nspecified in theindextensor in a similar fashion asscatter_(). For each value insrc, it is added to\nan index inselfwhich is specified by its index insrcfordimension!=dimand by the corresponding value inindexfordimension=dim. For a 3-D tensor,selfis updated as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "What happens to a 3-D tensor for a 3-D tensor?": {
        "answer": "selfis updated as:",
        "question": "What happens to a 3-D tensor for a 3-D tensor?",
        "context": "Adds all values from the tensorotherintoselfat the indices\nspecified in theindextensor in a similar fashion asscatter_(). For each value insrc, it is added to\nan index inselfwhich is specified by its index insrcfordimension!=dimand by the corresponding value inindexfordimension=dim. For a 3-D tensor,selfis updated as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "Where can this operation behave nondeterministically when given tensors?": {
        "answer": "CUDA device",
        "question": "Where can this operation behave nondeterministically when given tensors?",
        "context": "Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "What does the backward pass implement only forsrc.shape==index.shape?": {
        "answer": "SeeReproducibility",
        "question": "What does the backward pass implement only forsrc.shape==index.shape?",
        "context": "Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "What is the backward pass implemented only?": {
        "answer": "forsrc.shape==index.shape",
        "question": "What is the backward pass implemented only?",
        "context": "Adds all values from the tensorotherintoselfat the indices\nspecified in theindextensor in a similar fashion asscatter_(). For each value insrc, it is added to\nan index inselfwhich is specified by its index insrcfordimension!=dimand by the corresponding value inindexfordimension=dim. For a 3-D tensor,selfis updated as: self,indexandsrcshould have same number of\ndimensions. It is also required thatindex.size(d)<=src.size(d)for all\ndimensionsd, and thatindex.size(d)<=self.size(d)for all dimensionsd!=dim. Note thatindexandsrcdo not broadcast. Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "What is the axis along which to index index(LongTensor)?": {
        "answer": "dim(int)",
        "question": "What is the axis along which to index index(LongTensor)?",
        "context": "Adds all values from the tensorotherintoselfat the indices\nspecified in theindextensor in a similar fashion asscatter_(). For each value insrc, it is added to\nan index inselfwhich is specified by its index insrcfordimension!=dimand by the corresponding value inindexfordimension=dim. For a 3-D tensor,selfis updated as: self,indexandsrcshould have same number of\ndimensions. It is also required thatindex.size(d)<=src.size(d)for all\ndimensionsd, and thatindex.size(d)<=self.size(d)for all dimensionsd!=dim. Note thatindexandsrcdo not broadcast. Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "When empty, what does the operation return?": {
        "answer": "returnsselfunchanged",
        "question": "When empty, what does the operation return?",
        "context": "Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "What is the source element to scatter and add?": {
        "answer": "src(Tensor)",
        "question": "What is the source element to scatter and add?",
        "context": "Adds all values from the tensorotherintoselfat the indices\nspecified in theindextensor in a similar fashion asscatter_(). For each value insrc, it is added to\nan index inselfwhich is specified by its index insrcfordimension!=dimand by the corresponding value inindexfordimension=dim. For a 3-D tensor,selfis updated as: self,indexandsrcshould have same number of\ndimensions. It is also required thatindex.size(d)<=src.size(d)for all\ndimensionsd, and thatindex.size(d)<=self.size(d)for all dimensionsd!=dim. Note thatindexandsrcdo not broadcast. Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "When given tensors on what device may this operation behave nondeterministically?": {
        "answer": "CUDA",
        "question": "When given tensors on what device may this operation behave nondeterministically?",
        "context": "Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "What is the name of the operation that may behave nondeterministically when given tensors on a CUDA device?": {
        "answer": "Reproducibility",
        "question": "What is the name of the operation that may behave nondeterministically when given tensors on a CUDA device?",
        "context": "Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "When empty, the operation returns what?": {
        "answer": "selfunchanged",
        "question": "When empty, the operation returns what?",
        "context": "Note This operation may behave nondeterministically when given tensors on a CUDA device. SeeReproducibilityfor more information. Note The backward pass is implemented only forsrc.shape==index.shape. dim(int) \u2013 the axis along which to index index(LongTensor) \u2013 the indices of elements to scatter and add, can be\neither empty or of the same dimensionality assrc. When empty, the\noperation returnsselfunchanged. src(Tensor) \u2013 the source elements to scatter and add Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_"
    },
    "The upper triangular part of a matrix returns how many tensors?": {
        "answer": "2",
        "question": "The upper triangular part of a matrix returns how many tensors?",
        "context": "Returns the upper triangular part of a matrix (2-D tensor) or batch of matricesinput, the other elements of the result tensoroutare set to 0. The upper triangular part of the matrix is defined as the elements on and\nabove the diagonal. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu"
    },
    "What is the upper triangular part of a matrix defined as?": {
        "answer": "the elements on and above the diagonal",
        "question": "What is the upper triangular part of a matrix defined as?",
        "context": "Returns the upper triangular part of a matrix (2-D tensor) or batch of matricesinput, the other elements of the result tensoroutare set to 0. The upper triangular part of the matrix is defined as the elements on and\nabove the diagonal. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu"
    },
    "What part of a matrix is defined as the elements on and above the diagonal?": {
        "answer": "the upper triangular part",
        "question": "What part of a matrix is defined as the elements on and above the diagonal?",
        "context": "Returns the upper triangular part of a matrix (2-D tensor) or batch of matricesinput, the other elements of the result tensoroutare set to 0. The upper triangular part of the matrix is defined as the elements on and\nabove the diagonal. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu"
    },
    "What is the upper triangular part of the matrix defined as?": {
        "answer": "the elements on and above the diagonal",
        "question": "What is the upper triangular part of the matrix defined as?",
        "context": "The upper triangular part of the matrix is defined as the elements on and\nabove the diagonal. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu"
    },
    "What is n0n geq 0n0 called?": {
        "answer": "the order of the polygamma function",
        "question": "What is n0n geq 0n0 called?",
        "context": "Computes thenthn^{th}nthderivative of the digamma function oninput.n\u22650n \\geq 0n\u22650is called the order of the polygamma function. Note This function is implemented only for nonnegative integersn\u22650n \\geq 0n\u22650. n(int) \u2013 the order of the polygamma function input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.polygamma.html#torch.polygamma"
    },
    "The order of the polygamma function is implemented only for what?": {
        "answer": "nonnegative integers",
        "question": "The order of the polygamma function is implemented only for what?",
        "context": "Computes thenthn^{th}nthderivative of the digamma function oninput.n\u22650n \\geq 0n\u22650is called the order of the polygamma function. Note This function is implemented only for nonnegative integersn\u22650n \\geq 0n\u22650. n(int) \u2013 the order of the polygamma function input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.polygamma.html#torch.polygamma"
    },
    "What is the input tensor of the polygamma function?": {
        "answer": "input(Tensor)",
        "question": "What is the input tensor of the polygamma function?",
        "context": "Computes thenthn^{th}nthderivative of the digamma function oninput.n\u22650n \\geq 0n\u22650is called the order of the polygamma function. Note This function is implemented only for nonnegative integersn\u22650n \\geq 0n\u22650. n(int) \u2013 the order of the polygamma function input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.polygamma.html#torch.polygamma"
    },
    "What is an example of the order of the polygamma function?": {
        "answer": "Example",
        "question": "What is an example of the order of the polygamma function?",
        "context": "Computes thenthn^{th}nthderivative of the digamma function oninput.n\u22650n \\geq 0n\u22650is called the order of the polygamma function. Note This function is implemented only for nonnegative integersn\u22650n \\geq 0n\u22650. n(int) \u2013 the order of the polygamma function input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.polygamma.html#torch.polygamma"
    },
    "What is the default value for Bessel's correction?": {
        "answer": "IfunbiasedisTrue",
        "question": "What is the default value for Bessel's correction?",
        "context": "input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "If unbiasedisTrue, what is calculated, without any correction?": {
        "answer": "the sample deviation",
        "question": "If unbiasedisTrue, what is calculated, without any correction?",
        "context": "unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is the dimension or dimensions to reduce?": {
        "answer": "dim",
        "question": "What is the dimension or dimensions to reduce?",
        "context": "dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is the name of Bessel's correction?": {
        "answer": "IfunbiasedisTrue",
        "question": "What is the name of Bessel's correction?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Calculates the variance of all elements in what?": {
        "answer": "theinputtensor",
        "question": "Calculates the variance of all elements in what?",
        "context": "IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample variance is calculated, without any correction. input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is calculated if Bessel's correction is used?": {
        "answer": "the sample variance",
        "question": "What is calculated if Bessel's correction is used?",
        "context": "IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample variance is calculated, without any correction. input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is the name of the dimension or dimensions to reduce?": {
        "answer": "dim",
        "question": "What is the name of the dimension or dimensions to reduce?",
        "context": "input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What does out(Tensor,optional) calculate?": {
        "answer": "the variance of all elements in theinputtensor",
        "question": "What does out(Tensor,optional) calculate?",
        "context": "unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is calculated in the inputtensor?": {
        "answer": "the variance of all elements",
        "question": "What is calculated in the inputtensor?",
        "context": "input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "When will Bessel's correction be used?": {
        "answer": "IfunbiasedisTrue",
        "question": "When will Bessel's correction be used?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is calculated without any correction if unbiasedisTrue?": {
        "answer": "the sample deviation",
        "question": "What is calculated without any correction if unbiasedisTrue?",
        "context": "input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What does unbiased(bool) mean?": {
        "answer": "whether to use Bessel\u2019s correction",
        "question": "What does unbiased(bool) mean?",
        "context": "input(Tensor) \u2013 the input tensor. dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What bool indicates whether to use Bessel's correction?": {
        "answer": "unbiased",
        "question": "What bool indicates whether to use Bessel's correction?",
        "context": "dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "Out(Tensor,optional) - what is the output tensor?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) - what is the output tensor?",
        "context": "This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does the output tensor calculate?": {
        "answer": "the variance of all elements",
        "question": "What does the output tensor calculate?",
        "context": "dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is calculated if unbiasedisTrue?": {
        "answer": "the sample deviation",
        "question": "What is calculated if unbiasedisTrue?",
        "context": "dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is unbiased(bool)?": {
        "answer": "whether to use Bessel\u2019s correction",
        "question": "What is unbiased(bool)?",
        "context": "unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is the default value of Bessel's correction?": {
        "answer": "IfunbiasedisTrue",
        "question": "What is the default value of Bessel's correction?",
        "context": "dim(intortuple of python:ints) \u2013 the dimension or dimensions to reduce. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "Whether the output tensor hasdimretained or not?": {
        "answer": "keepdim",
        "question": "Whether the output tensor hasdimretained or not?",
        "context": "unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "If Bessel\u2019s correction is used, what will be used?": {
        "answer": "IfunbiasedisTrue",
        "question": "If Bessel\u2019s correction is used, what will be used?",
        "context": "unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is an example of a function that uses Bessel's correction?": {
        "answer": "Example",
        "question": "What is an example of a function that uses Bessel's correction?",
        "context": "unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(Tensor,optional) \u2013 the output tensor. Calculates the variance of all elements in theinputtensor. IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction. input(Tensor) \u2013 the input tensor. unbiased(bool) \u2013 whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1). Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var"
    },
    "What is modeled after SciPy'sspecialmodule?": {
        "answer": "The torch.special module",
        "question": "What is modeled after SciPy'sspecialmodule?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the torch.special module modeled after?": {
        "answer": "SciPy",
        "question": "What is the torch.special module modeled after?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What version of PyTorch is the torch.special module in?": {
        "answer": "BETA",
        "question": "What version of PyTorch is the torch.special module in?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the status of the torch.special module?": {
        "answer": "New functions are still being added",
        "question": "What is the status of the torch.special module?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Where can you find more information about the torch.special module?": {
        "answer": "the documentation of each function for details",
        "question": "Where can you find more information about the torch.special module?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the entropy oninput, what is it?": {
        "answer": "elementwise",
        "question": "Computes the entropy oninput, what is it?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Out(Tensor,optional) - what does out(Tensor,optional) represent?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) - what does out(Tensor,optional) represent?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does the torch.special module compute?": {
        "answer": "error function ofinput",
        "question": "What does the torch.special module compute?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the error function of input defined as?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "What is the error function of input defined as?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is still being added to the torch.special module?": {
        "answer": "New functions",
        "question": "What is still being added to the torch.special module?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of each function in the torch.special module?": {
        "answer": "documentation",
        "question": "What is the name of each function in the torch.special module?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What version of PyTorch is this module in?": {
        "answer": "BETA",
        "question": "What version of PyTorch is this module in?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Some functions may change in future what?": {
        "answer": "PyTorch releases",
        "question": "Some functions may change in future what?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of each function in the PyTorch module?": {
        "answer": "documentation",
        "question": "What is the name of each function in the PyTorch module?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what elementwise?": {
        "answer": "entropy oninput",
        "question": "Computes what elementwise?",
        "context": "Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is out(Tensor,optional) defined as?": {
        "answer": "output tensor",
        "question": "What is out(Tensor,optional) defined as?",
        "context": "Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a PyTorch module?": {
        "answer": "Example:",
        "question": "What is an example of a PyTorch module?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the function that computes the error function of input?": {
        "answer": "Computes the error function ofinput",
        "question": "What is the function that computes the error function of input?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the error function of input?": {
        "answer": "complementary error function ofinput",
        "question": "What is the error function of input?",
        "context": "Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the complementary error function of input?": {
        "answer": "inverse error function ofinput",
        "question": "What is the complementary error function of input?",
        "context": "Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the inverse error function of input?": {
        "answer": "Computes the inverse error function ofinput",
        "question": "What is the inverse error function of input?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the complementary error function defined as?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "What is the complementary error function defined as?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What error function is defined in the range(1,1)(-1,1)(1,1)?": {
        "answer": "inverse error function",
        "question": "What error function is defined in the range(1,1)(-1,1)(1,1)?",
        "context": "Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is defined in the range(1,1)(-1, 1)(1,1)?": {
        "answer": "inverse error function",
        "question": "What is defined in the range(1,1)(-1, 1)(1,1)?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is another name for the logistic sigmoid function?": {
        "answer": "expit",
        "question": "What is another name for the logistic sigmoid function?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What error function is defined in the range(1,1)(-1, 1)(1,1)?": {
        "answer": "inverse error function",
        "question": "What error function is defined in the range(1,1)(-1, 1)(1,1)?",
        "context": "Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the input tensor defined as?": {
        "answer": "input(Tensor)",
        "question": "What is the input tensor defined as?",
        "context": "Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the expit also known as?": {
        "answer": "the logistic sigmoid function",
        "question": "What is the expit also known as?",
        "context": "Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what error function of input?": {
        "answer": "inverse error function",
        "question": "Computes what error function of input?",
        "context": "Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the logistic sigmoid function?": {
        "answer": "expit",
        "question": "What is the logistic sigmoid function?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the exponential of the elements minus what ofinput?": {
        "answer": "1",
        "question": "Computes the exponential of the elements minus what ofinput?",
        "context": "Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of the function that computes the exponential of the elements minus 1 ofinput?": {
        "answer": "Note",
        "question": "What is the name of the function that computes the exponential of the elements minus 1 ofinput?",
        "context": "Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what of the elements minus 1 ofinput?": {
        "answer": "exponential",
        "question": "Computes what of the elements minus 1 ofinput?",
        "context": "Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does the exponential of the elements minus 1 ofinput do?": {
        "answer": "Note",
        "question": "What does the exponential of the elements minus 1 ofinput do?",
        "context": "Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Out(Tensor,optional) is what?": {
        "answer": "output tensor",
        "question": "Out(Tensor,optional) is what?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of the function that computes the exponential of the elements minus 1 of input?": {
        "answer": "Note",
        "question": "What is the name of the function that computes the exponential of the elements minus 1 of input?",
        "context": "Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What function is defined in the range(1,1)(-1, 1)(1,1)?": {
        "answer": "inverse error function",
        "question": "What function is defined in the range(1,1)(-1, 1)(1,1)?",
        "context": "Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what function of input?": {
        "answer": "inverse error function",
        "question": "Computes what function of input?",
        "context": "Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What function provides greater precision than the exponential of the elements minus 1 ofinput?": {
        "answer": "exp(x) - 1",
        "question": "What function provides greater precision than the exponential of the elements minus 1 ofinput?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the base of the exponential function of input?": {
        "answer": "base two",
        "question": "What is the base of the exponential function of input?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What function provides greater precision than exp(x) - 1 for small values of x?": {
        "answer": "Computes the exponential of the elements minus 1 ofinput",
        "question": "What function provides greater precision than exp(x) - 1 for small values of x?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does the exponential of the elements minus 1 ofinput provide?": {
        "answer": "greater precision",
        "question": "What does the exponential of the elements minus 1 ofinput provide?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the input(Tensor)?": {
        "answer": "input tensor",
        "question": "What is the input(Tensor)?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "The exponential of the elements minus 1 ofinput provides greater precision than what for small values of x?": {
        "answer": "exp(x) - 1",
        "question": "The exponential of the elements minus 1 ofinput provides greater precision than what for small values of x?",
        "context": "Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the function that computes the exponential of the elements minus 1 ofinput?": {
        "answer": "base two exponential function ofinput",
        "question": "What is the function that computes the exponential of the elements minus 1 ofinput?",
        "context": "Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what of the elements minus 1 of input?": {
        "answer": "exponential",
        "question": "Computes what of the elements minus 1 of input?",
        "context": "Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the expit also known as what?": {
        "answer": "the logistic sigmoid function",
        "question": "Computes the expit also known as what?",
        "context": "Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "This function provides greater precision than what for small values of x?": {
        "answer": "exp(x) - 1",
        "question": "This function provides greater precision than what for small values of x?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the natural what of the absolute value of the gamma function oninput?": {
        "answer": "logarithm",
        "question": "Computes the natural what of the absolute value of the gamma function oninput?",
        "context": "Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does this function provide than exp(x) - 1 for small values of x?": {
        "answer": "greater precision",
        "question": "What does this function provide than exp(x) - 1 for small values of x?",
        "context": "Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does Compute?": {
        "answer": "the natural logarithm of the absolute value of the gamma function oninput",
        "question": "What does Compute?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What type of function is computed for each element of input?": {
        "answer": "exponentially scaled zeroth order modified Bessel function",
        "question": "What type of function is computed for each element of input?",
        "context": "Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the exponentially scaled zeroth order modified Bessel function of what kind?": {
        "answer": "first kind",
        "question": "Computes the exponentially scaled zeroth order modified Bessel function of what kind?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a function that computes the base two exponential function of input?": {
        "answer": "Computes the base two exponential function ofinput",
        "question": "What is an example of a function that computes the base two exponential function of input?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the absolute value of the gamma function oninput?": {
        "answer": "natural logarithm",
        "question": "What is the absolute value of the gamma function oninput?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What order modified Bessel function is computed for each element of input?": {
        "answer": "zeroth",
        "question": "What order modified Bessel function is computed for each element of input?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the exponentially scaled zeroth order modified Bessel function of?": {
        "answer": "first kind",
        "question": "What is the exponentially scaled zeroth order modified Bessel function of?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the base two exponential function of input?": {
        "answer": "Computes the base two exponential function ofinput",
        "question": "What is the base two exponential function of input?",
        "context": "Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is computed for each element of input?": {
        "answer": "exponentially scaled zeroth order modified Bessel function",
        "question": "What is computed for each element of input?",
        "context": "Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the result of the natural logarithm of the absolute value of the gamma function oninput?": {
        "answer": "Computes the natural logarithm of the absolute value of the gamma function oninput",
        "question": "What is the result of the natural logarithm of the absolute value of the gamma function oninput?",
        "context": "Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Input is clamped to what when eps is not None?": {
        "answer": "eps",
        "question": "Input is clamped to what when eps is not None?",
        "context": "Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "When eps is None andinput 0 orinput> 1, the function will yield what?": {
        "answer": "NaN",
        "question": "When eps is None andinput 0 orinput> 1, the function will yield what?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Inputis clamped to what when eps is not None?": {
        "answer": "eps",
        "question": "Inputis clamped to what when eps is not None?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the epsilon for input clamp bound?": {
        "answer": "float",
        "question": "What is the epsilon for input clamp bound?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does out(Tensor,optional) return?": {
        "answer": "output tensor",
        "question": "What does out(Tensor,optional) return?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a function that computes input*log1p?": {
        "answer": "Computesinput*log1p(other)with the following cases",
        "question": "What is an example of a function that computes input*log1p?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is'sscipy.special.xlog1py' similar to?": {
        "answer": "SciPy",
        "question": "What is'sscipy.special.xlog1py' similar to?",
        "context": "Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "How does this function check if allinputandothersatisfy the condition?": {
        "answer": "elementwise",
        "question": "How does this function check if allinputandothersatisfy the condition?",
        "context": "This function checks if allinputandothersatisfy the condition: elementwise, for all elements ofinputandother. The behaviour of this function is analogous tonumpy.allclose input(Tensor) \u2013 first tensor to compare other(Tensor) \u2013 second tensor to compare atol(float,optional) \u2013 absolute tolerance. Default: 1e-08 rtol(float,optional) \u2013 relative tolerance. Default: 1e-05 equal_nan(bool,optional) \u2013 ifTrue, then twoNaNs will be considered equal. Default:False Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose"
    },
    "Atol(float,optional) is used to compare atol(float,optional) to what?": {
        "answer": "absolute tolerance",
        "question": "Atol(float,optional) is used to compare atol(float,optional) to what?",
        "context": "This function checks if allinputandothersatisfy the condition: elementwise, for all elements ofinputandother. The behaviour of this function is analogous tonumpy.allclose input(Tensor) \u2013 first tensor to compare other(Tensor) \u2013 second tensor to compare atol(float,optional) \u2013 absolute tolerance. Default: 1e-08 rtol(float,optional) \u2013 relative tolerance. Default: 1e-05 equal_nan(bool,optional) \u2013 ifTrue, then twoNaNs will be considered equal. Default:False Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose"
    },
    "Default: 1e-08 rtol(float,optional) \u2013 what?": {
        "answer": "relative tolerance",
        "question": "Default: 1e-08 rtol(float,optional) \u2013 what?",
        "context": "This function checks if allinputandothersatisfy the condition: elementwise, for all elements ofinputandother. The behaviour of this function is analogous tonumpy.allclose input(Tensor) \u2013 first tensor to compare other(Tensor) \u2013 second tensor to compare atol(float,optional) \u2013 absolute tolerance. Default: 1e-08 rtol(float,optional) \u2013 relative tolerance. Default: 1e-05 equal_nan(bool,optional) \u2013 ifTrue, then twoNaNs will be considered equal. Default:False Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose"
    },
    "What is the default value of _nan(bool,optional)?": {
        "answer": "equal",
        "question": "What is the default value of _nan(bool,optional)?",
        "context": "This function checks if allinputandothersatisfy the condition: elementwise, for all elements ofinputandother. The behaviour of this function is analogous tonumpy.allclose input(Tensor) \u2013 first tensor to compare other(Tensor) \u2013 second tensor to compare atol(float,optional) \u2013 absolute tolerance. Default: 1e-08 rtol(float,optional) \u2013 relative tolerance. Default: 1e-05 equal_nan(bool,optional) \u2013 ifTrue, then twoNaNs will be considered equal. Default:False Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose"
    },
    "What is the default value of equal_nan(bool,optional)?": {
        "answer": "False Example",
        "question": "What is the default value of equal_nan(bool,optional)?",
        "context": "This function checks if allinputandothersatisfy the condition: elementwise, for all elements ofinputandother. The behaviour of this function is analogous tonumpy.allclose input(Tensor) \u2013 first tensor to compare other(Tensor) \u2013 second tensor to compare atol(float,optional) \u2013 absolute tolerance. Default: 1e-08 rtol(float,optional) \u2013 relative tolerance. Default: 1e-05 equal_nan(bool,optional) \u2013 ifTrue, then twoNaNs will be considered equal. Default:False Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose"
    },
    "How can a TorchScript program be saved from a Python process and loaded in a process where there is no Python dependency?": {
        "answer": "Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency",
        "question": "How can a TorchScript program be saved from a Python process and loaded in a process where there is no Python dependency?",
        "context": "Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what language can a TorchScript program be run independently from Python?": {
        "answer": "C++",
        "question": "In what language can a TorchScript program be run independently from Python?",
        "context": "Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions": {
        "answer": "Python Functions and Modules",
        "question": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions",
        "context": "PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer?": {
        "answer": "Python Language Reference Comparison Debugging",
        "question": "What Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer?",
        "context": "PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the introduction to TorchScripttutorial?": {
        "answer": "introduction to TorchScript",
        "question": "What is the introduction to TorchScripttutorial?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What Python Functions and Modules?": {
        "answer": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer",
        "question": "What Python Functions and Modules?",
        "context": "Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Why is it possible to export a model via TorchScript to a production environment?": {
        "answer": "Python programs may be disadvantageous for performance and multi-threading reasons",
        "question": "Why is it possible to export a model via TorchScript to a production environment?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API": {
        "answer": "Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer",
        "question": "What is Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API",
        "context": "Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what language is it possible to train models in PyTorch using familiar tools?": {
        "answer": "Python",
        "question": "In what language is it possible to train models in PyTorch using familiar tools?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is one way to disable JIT for Debugging?": {
        "answer": "Disable JIT for Debugging",
        "question": "What is one way to disable JIT for Debugging?",
        "context": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive": {
        "answer": "Inspecting Code Interpreting Graphs Tracer",
        "question": "What is the name of the Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive",
        "context": "Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do we provide to incrementally transition a model from a pure Python program to a TorchScript program that can be run independently from Python": {
        "answer": "tools",
        "question": "What do we provide to incrementally transition a model from a pure Python program to a TorchScript program that can be run independently from Python",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript a way to do from PyTorch code?": {
        "answer": "create serializable and optimizable models",
        "question": "What is TorchScript a way to do from PyTorch code?",
        "context": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References?": {
        "answer": "Frequently Asked Questions",
        "question": "What Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References?",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "References TorchScript is a way to do what from PyTorch code?": {
        "answer": "create serializable and optimizable models",
        "question": "References TorchScript is a way to do what from PyTorch code?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript provide?": {
        "answer": "tools to incrementally transition a model from a pure Python program to a TorchScript program that can be run independently from Python",
        "question": "What does TorchScript provide?",
        "context": "Creating TorchScript Code Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript a way to do?": {
        "answer": "create serializable and optimizable models from PyTorch code",
        "question": "What is TorchScript a way to do?",
        "context": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a benefit of using TorchScript?": {
        "answer": "Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency",
        "question": "What is a benefit of using TorchScript?",
        "context": "TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does ornn.Module compile the source code as?": {
        "answer": "TorchScript code",
        "question": "What does ornn.Module compile the source code as?",
        "context": "For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript do?": {
        "answer": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution",
        "question": "What does TorchScript do?",
        "context": "Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the end-to-end example of converting a PyTorch model to TorchScript and running it in C++?": {
        "answer": "theLoading a PyTorch Model in C++tutorial",
        "question": "What is the end-to-end example of converting a PyTorch model to TorchScript and running it in C++?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "A wrapper around C++torch::jit::Module. Functionally equivalent to what?": {
        "answer": "aScriptModule",
        "question": "A wrapper around C++torch::jit::Module. Functionally equivalent to what?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Scripting a function ornn.Module compile as?": {
        "answer": "TorchScript code",
        "question": "What does Scripting a function ornn.Module compile as?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Trace a module and return an executableScriptModulethat will be optimized using what?": {
        "answer": "just-in-time compilation",
        "question": "Trace a module and return an executableScriptModulethat will be optimized using what?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of version of a script module can be saved for use in a separate process?": {
        "answer": "offline",
        "question": "What type of version of a script module can be saved for use in a separate process?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Load aScriptModuleorScriptFunctionpreviously saved what?": {
        "answer": "withtorch.jit.save",
        "question": "Load aScriptModuleorScriptFunctionpreviously saved what?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to optimize aScriptModule?": {
        "answer": "just-in-time compilation",
        "question": "What is used to optimize aScriptModule?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of version of aScriptModule can be saved for use in a separate process?": {
        "answer": "offline",
        "question": "What type of version of aScriptModule can be saved for use in a separate process?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Torch.jit.Future[T]asynchronous task do?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What does Torch.jit.Future[T]asynchronous task do?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where can you save a version of aScriptModule for use in a separate process?": {
        "answer": "offline",
        "question": "Where can you save a version of aScriptModule for use in a separate process?",
        "context": "A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the TorchScript function that provides for conatiner type refinement?": {
        "answer": "a pass-through function that returnsvalue",
        "question": "What is the TorchScript function that provides for conatiner type refinement?",
        "context": "A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the TorchScript method that provides for conatiner type refinement?": {
        "answer": "a pass-through function that returnsvalue",
        "question": "What is the TorchScript method that provides for conatiner type refinement?",
        "context": "Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What version of aScriptModule can you save for use in a separate process?": {
        "answer": "offline",
        "question": "What version of aScriptModule can you save for use in a separate process?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the left-hand expression used to indicate to the TorchScript compiler?": {
        "answer": "a class instance attribute with type oftype",
        "question": "What is the left-hand expression used to indicate to the TorchScript compiler?",
        "context": "  Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does returnsthe_value hint TorchScript compiler?": {
        "answer": "the type ofthe_value",
        "question": "What does returnsthe_value hint TorchScript compiler?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can call traced functions?": {
        "answer": "Scripted functions",
        "question": "What can call traced functions?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What inside of a script function called by a traced function is preserved correctly?": {
        "answer": "Control-flow",
        "question": "What inside of a script function called by a traced function is preserved correctly?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a script function called by a traced function?": {
        "answer": "a traced function",
        "question": "What is an example of a script function called by a traced function?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a traced function particularly useful for?": {
        "answer": "when you need to use control-flow around a simple feed-forward model",
        "question": "What is a traced function particularly useful for?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can a scripted function call an encoder module generated using?": {
        "answer": "tracing",
        "question": "What can a scripted function call an encoder module generated using?",
        "context": "Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can be used to generate a submodule using tracing that can be called from the methods of a script module?": {
        "answer": "fornn.Modules",
        "question": "What can be used to generate a submodule using tracing that can be called from the methods of a script module?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can a submodule be called from the methods of a script module?": {
        "answer": "using a traced module",
        "question": "How can a submodule be called from the methods of a script module?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Debugging what script works except for when we invoke the@torch.jit.scriptfunction?": {
        "answer": "withpdb",
        "question": "Debugging what script works except for when we invoke the@torch.jit.scriptfunction?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can we do to make the @torch.jit.scriptfunction a normal Python function and not compile it?": {
        "answer": "globally disable JIT",
        "question": "What can we do to make the @torch.jit.scriptfunction a normal Python function and not compile it?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the above script?": {
        "answer": "disable_jit_example.py",
        "question": "What is the name of the above script?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can we step into the@torch.jit.scriptfunction as?": {
        "answer": "normal Python function",
        "question": "What can we step into the@torch.jit.scriptfunction as?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To disable what for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-print": {
        "answer": "TorchScript compiler",
        "question": "To disable what for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-print",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript provide for allScriptModuleinstances?": {
        "answer": "a code pretty-printer",
        "question": "What does TorchScript provide for allScriptModuleinstances?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you use TorchScript's compilation of the code for theforwardmethod?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "What can you use TorchScript's compilation of the code for theforwardmethod?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What produces the output of TorchScript's compilation of the code for theforwardmethod?": {
        "answer": "The example above",
        "question": "What produces the output of TorchScript's compilation of the code for theforwardmethod?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you use this output to do?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "What can you use this output to do?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a static single assignment (SSA) intermediate representation?": {
        "answer": "example",
        "question": "What is an example of a static single assignment (SSA) intermediate representation?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript's compilation of?": {
        "answer": "the code for theforwardmethod",
        "question": "What is TorchScript's compilation of?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What instruction produces the graph?": {
        "answer": "test.py:9:10",
        "question": "What instruction produces the graph?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript assign the output to?": {
        "answer": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1",
        "question": "What does TorchScript assign the output to?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,": {
        "answer": "test.py:9:10",
        "question": "What is the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does %rv.1:Tensormeans we assign the output to?": {
        "answer": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1",
        "question": "What does %rv.1:Tensormeans we assign the output to?",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What operator is equivalent to totorch.zeros?": {
        "answer": "aten::zerosis the operator",
        "question": "What operator is equivalent to totorch.zeros?",
        "context": "TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does graph follow the same rules described in theInspecting Codesection with regard to?": {
        "answer": "forwardmethod lookup",
        "question": "What does graph follow the same rules described in theInspecting Codesection with regard to?",
        "context": "graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the script assign the output to a (unique) value namedrv.1?": {
        "answer": "%rv.1:Tensormeans",
        "question": "What does the script assign the output to a (unique) value namedrv.1?",
        "context": "graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the operator (equivalent totorch.zeros)?": {
        "answer": "aten::zeros",
        "question": "What is the operator (equivalent totorch.zeros)?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the unique value that we assign the output to?": {
        "answer": "ofTensortype",
        "question": "What is the unique value that we assign the output to?",
        "context": "The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the file that generated the instruction%rv.1:Tensor=aten?": {
        "answer": "test.py",
        "question": "What is the name of the file that generated the instruction%rv.1:Tensor=aten?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does assign the output to a (unique) value namedrv.1?": {
        "answer": "%rv.1:Tensormeans",
        "question": "What does assign the output to a (unique) value namedrv.1?",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are some edge cases that exist where the trace of a given Python function/module will not be representative of the underlying code?": {
        "answer": "Tracing of control flow that is dependent on inputs",
        "question": "What are some edge cases that exist where the trace of a given Python function/module will not be representative of the underlying code?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g. what is on the left-hand side of an assignment)": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g. what is on the left-hand side of an assignment)",
        "context": "#test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g. in-place operations) on the left-hand side of": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g. in-place operations) on the left-hand side of",
        "context": "aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is thetorch.jit.trace()API.check_inputstakes?": {
        "answer": "check_inputson",
        "question": "What is thetorch.jit.trace()API.check_inputstakes?",
        "context": "Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of an edge case where the trace of a given Python function/module will not be representative of the underlying code?": {
        "answer": "example",
        "question": "What is an example of an edge case where the trace of a given Python function/module will not be representative of the underlying code?",
        "context": "Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the message indicate that the computation differed between when we first traced it and when we traced it?": {
        "answer": "thecheck_inputs",
        "question": "What does the message indicate that the computation differed between when we first traced it and when we traced it?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g. what on the left-hand side of an assignment) Note": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g. what on the left-hand side of an assignment) Note",
        "context": "Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the loop within the body ofloop_in_traced_fndepend on?": {
        "answer": "the shape of the inputx",
        "question": "What does the loop within the body ofloop_in_traced_fndepend on?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of what?": {
        "answer": "tensor views",
        "question": "Tracing of in-place operations of what?",
        "context": "Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a list of inputs that will be used to re-trace the computation and verify the results?": {
        "answer": "tuples",
        "question": "What is a list of inputs that will be used to re-trace the computation and verify the results?",
        "context": "Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what time frame may these cases be traceable?": {
        "answer": "future",
        "question": "In what time frame may these cases be traceable?",
        "context": "Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a list of inputs that will be used to retrace the computation and verify the results?": {
        "answer": "tuples",
        "question": "What is a list of inputs that will be used to retrace the computation and verify the results?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the list of tuples of inputs that will be used to re-trace the computation give us?": {
        "answer": "diagnostic information",
        "question": "What does the list of tuples of inputs that will be used to re-trace the computation give us?",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does a trace of a function that contains an in-place assignment on a slice (a view) of a Tensor produce": {
        "answer": "a graph",
        "question": "What does a trace of a function that contains an in-place assignment on a slice (a view) of a Tensor produce",
        "context": "One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The message indicates that the computation differed between when we first traced it and when we traced it with what?": {
        "answer": "check_inputs",
        "question": "The message indicates that the computation differed between when we first traced it and when we traced it with what?",
        "context": "Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The loop within the body ofloop_in_traced_fndepends on what of the inputx?": {
        "answer": "shape",
        "question": "The loop within the body ofloop_in_traced_fndepends on what of the inputx?",
        "context": "Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The example above produces this output: This is TorchScript's compilation of the code for what?": {
        "answer": "theforwardmethod",
        "question": "The example above produces this output: This is TorchScript's compilation of the code for what?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you use the code pretty-printer for allScriptModuleinstances?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "What can you use the code pretty-printer for allScriptModuleinstances?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the first step in converting a model from GPU to CPU?": {
        "answer": "convert your model from GPU to CPU and then save it",
        "question": "What is the first step in converting a model from GPU to CPU?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do you store on aScriptModule?": {
        "answer": "attributes",
        "question": "What do you store on aScriptModule?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is equivalent to an attribute (see 4) of typeTensor?": {
        "answer": "register_buffer",
        "question": "What is equivalent to an attribute (see 4) of typeTensor?",
        "context": "First convert your model from GPU to CPU and then save it, like so: This is recommended because the tracer may witness tensor creation on a\nspecific device, so casting an already-loaded model may have unexpected\neffects. Casting the modelbeforesaving it ensures that the tracer has\nthe correct device information. Q: How do I store attributes on aScriptModule? Say we have a model like: IfModelis instantiated it will result in a compilation error\nsince the compiler doesn\u2019t know aboutx. There are 4 ways to inform the\ncompiler of attributes onScriptModule: 1.nn.Parameter- Values wrapped innn.Parameterwill work as they\ndo onnn.Modules 2.register_buffer- Values wrapped inregister_bufferwill work as\nthey do onnn.Modules. This is equivalent to an attribute (see 4) of typeTensor. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To compile a method other thanforward that is not called fromforward, what is done?": {
        "answer": "add@torch.jit.export",
        "question": "To compile a method other thanforward that is not called fromforward, what is done?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What do these changes combine to provide for converting yournn.Modules intoScriptModules?": {
        "answer": "a simpler, easier-to-use API",
        "question": "What do these changes combine to provide for converting yournn.Modules intoScriptModules?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What module is compiled by default?": {
        "answer": "module\u2019sforward",
        "question": "What module is compiled by default?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How are methods called fromforward lazily compiled?": {
        "answer": "in the order they are used inforward",
        "question": "How are methods called fromforward lazily compiled?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To stop the compiler from compiling a method, what is done?": {
        "answer": "add@torch.jit.ignoreor@torch.jit.unused",
        "question": "To stop the compiler from compiling a method, what is done?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoreor do to a method?": {
        "answer": "@ignoreleaves the method as a call to python",
        "question": "What does @ignoreor do to a method?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What styleclass annotations are used for empty container types?": {
        "answer": "PEP 526",
        "question": "What styleclass annotations are used for empty container types?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoreor do to a method as a call to python?": {
        "answer": "@ignoreleaves",
        "question": "What does @ignoreor do to a method as a call to python?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of types can be annotated using PEP 526-styleclass annotations?": {
        "answer": "empty container types",
        "question": "What type of types can be annotated using PEP 526-styleclass annotations?",
        "context": "To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can empty container types be marked with aFinalclass annotation instead of adding the name of the member to__constants__?": {
        "answer": "annotate their types usingPEP 526-styleclass annotations",
        "question": "How can empty container types be marked with aFinalclass annotation instead of adding the name of the member to__constants__?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @unusedreplace a method with?": {
        "answer": "an exception",
        "question": "What does @unusedreplace a method with?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @torch.jit.ignore and @torch.jit.unused provide?": {
        "answer": "details",
        "question": "What does @torch.jit.ignore and @torch.jit.unused provide?",
        "context": "method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is required for empty container types?": {
        "answer": "annotate their types usingPEP 526-styleclass annotations",
        "question": "What is required for empty container types?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @torch.jit.ignore and @torch.jit.unused contain?": {
        "answer": "details",
        "question": "What does @torch.jit.ignore and @torch.jit.unused contain?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "In what version of Torch does the @torch.jit.ignoreannotation's behavior change?": {
        "answer": "PyTorch 1.2",
        "question": "In what version of Torch does the @torch.jit.ignoreannotation's behavior change?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What module's data is copied to aScriptModule when passed to thetorch.jit.scriptfunction?": {
        "answer": "atorch.nn.Module",
        "question": "What module's data is copied to aScriptModule when passed to thetorch.jit.scriptfunction?",
        "context": "When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How are methods called fromforward compiled?": {
        "answer": "in the order they are used inforward",
        "question": "How are methods called fromforward compiled?",
        "context": "The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How are functions and methods called fromforward compiled?": {
        "answer": "as they are seen by the compiler",
        "question": "How are functions and methods called fromforward compiled?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When does the @torch.jit.ignoreannotation's behavior change?": {
        "answer": "PyTorch 1.2",
        "question": "When does the @torch.jit.ignoreannotation's behavior change?",
        "context": "The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the @ignore decorator used to make a function or method callable from code that is exported?": {
        "answer": "@torch.jit.ignore",
        "question": "What is the name of the @ignore decorator used to make a function or method callable from code that is exported?",
        "context": "The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Everything in a user definedTorchScript Classis exported what?": {
        "answer": "by default",
        "question": "Everything in a user definedTorchScript Classis exported what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What was Torch.jit.annotate used for?": {
        "answer": "to tell the TorchScript compiler what the type should be",
        "question": "What was Torch.jit.annotate used for?",
        "context": "The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: TheFinaltype constructor can be used to mark members asconstant. If members are not marked constant, they will be copied to the resultingScriptModuleas an attribute. UsingFinalopens opportunities for optimization if the value is known to be fixed and gives additional type safety. Old API: New API: Containers are assumed to have typeTensorand be non-optional (seeDefault Typesfor more information). Previously,torch.jit.annotatewas used to\ntell the TorchScript compiler what the type should be. Python 3 style type hints are\nnow supported. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Einsum stand for?": {
        "answer": "Sums the product of the elements of the inputoperandsalong dimensions",
        "question": "What does Einsum stand for?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What allows computing many common multi-dimensional linear algebraic array operations by representing them in a short-hand format based on the Einstein summ": {
        "answer": "Einsum",
        "question": "What allows computing many common multi-dimensional linear algebraic array operations by representing them in a short-hand format based on the Einstein summ",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the general idea of Einsum?": {
        "answer": "label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output",
        "question": "What is the general idea of Einsum?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "How is the output computed?": {
        "answer": "by summing the product of the elements of theoperandsalong the dimensions whose subscripts are not part of the output",
        "question": "How is the output computed?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B)?": {
        "answer": "matrix multiplication",
        "question": "What can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B)?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the summation subscript?": {
        "answer": "j",
        "question": "What is the summation subscript?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the name of the Equation that allows multi-dimensional linear algebraic array operations?": {
        "answer": "Equation",
        "question": "What is the name of the Equation that allows multi-dimensional linear algebraic array operations?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What does Theequationstring separate subcripts for each operand by?": {
        "answer": "a comma",
        "question": "What does Theequationstring separate subcripts for each operand by?",
        "context": "Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "The dimensions labeled with the same subscript must be what?": {
        "answer": "broadcastable",
        "question": "The dimensions labeled with the same subscript must be what?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the exception?": {
        "answer": "if a subscript is repeated for the same input operand",
        "question": "What is the exception?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What will be part of the output?": {
        "answer": "The subscripts that appear exactly once in theequation",
        "question": "What will be part of the output?",
        "context": "Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What specifies the subscripts for each dimension of the inputoperands in the same order as the dimensions?": {
        "answer": "Theequationstring",
        "question": "What specifies the subscripts for each dimension of the inputoperands in the same order as the dimensions?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What will be part of the output, sorted in increasing alphabetical order?": {
        "answer": "The subscripts that appear exactly once in theequation",
        "question": "What will be part of the output, sorted in increasing alphabetical order?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What function returns the full window size?": {
        "answer": "Bartlett window function",
        "question": "What function returns the full window size?",
        "context": "Bartlett window function. whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the value of the Bartlett window function?": {
        "answer": "full window size",
        "question": "What is the value of the Bartlett window function?",
        "context": "Bartlett window function. whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is inputwindow_length?": {
        "answer": "a positive integer",
        "question": "What is inputwindow_length?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is true when the returned window is used as a periodic window?": {
        "answer": "ifperiodic",
        "question": "What is true when the returned window is used as a periodic window?",
        "context": "Bartlett window function. whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the size of the returned window periodic(bool,optional)?": {
        "answer": "window_length(int)",
        "question": "What is the size of the returned window periodic(bool,optional)?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the global default of the returned tensor?": {
        "answer": "ifNone",
        "question": "What is the global default of the returned tensor?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What type of tensor types are supported?": {
        "answer": "floating point types",
        "question": "What type of tensor types are supported?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the inputwindow_length a positive integer controlling the returned window size?": {
        "answer": "whereNNNis the full window size",
        "question": "What is the inputwindow_length a positive integer controlling the returned window size?",
        "context": "whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is true when the returned window is used as a periodic window with functions liketorch.stft()?": {
        "answer": "ifperiodic",
        "question": "What is true when the returned window is used as a periodic window with functions liketorch.stft()?",
        "context": "whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the size of returned window periodic(bool,optional)?": {
        "answer": "window_length(int)",
        "question": "What is the size of returned window periodic(bool,optional)?",
        "context": "whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is the global default?": {
        "answer": "ifNone",
        "question": "What is the global default?",
        "context": "whereNNNis the full window size. The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "What is true when the returned window is ready to be used as a periodic window with functions liketorch.stft()?": {
        "answer": "ifperiodic",
        "question": "What is true when the returned window is ready to be used as a periodic window with functions liketorch.stft()?",
        "context": "The inputwindow_lengthis a positive integer controlling the\nreturned window size.periodicflag determines whether the returned\nwindow trims off the last duplicate value from the symmetric window and is\nready to be used as a periodic window with functions liketorch.stft(). Therefore, ifperiodicis true, theNNNin\nabove formula is in factwindow_length+1\\text{window\\_length} + 1window_length+1. Also, we always havetorch.bartlett_window(L,periodic=True)equal totorch.bartlett_window(L+1,periodic=False)[:-1]). Note Ifwindow_length=1=1=1, the returned window contains a single value 1. window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "The input tensor's data type must be what?": {
        "answer": "floating point or complex type",
        "question": "The input tensor's data type must be what?",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "For complex inputs, the norm is calculated using what?": {
        "answer": "absolute value of each element",
        "question": "For complex inputs, the norm is calculated using what?",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. keepdim(bool,optional) \u2013 whether the output tensors havedimretained or not. Ignored ifdim=Noneandout=None. Default:False out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "If the input is complex and neitherdtypenoroutis specified, what will be the corresponding floating point type?": {
        "answer": "the result\u2019s data type",
        "question": "If the input is complex and neitherdtypenoroutis specified, what will be the corresponding floating point type?",
        "context": "Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What does p(int,float,inf,-inf,'fro','nuc',optional) return": {
        "answer": "the order of norm",
        "question": "What does p(int,float,inf,-inf,'fro','nuc',optional) return",
        "context": "Returns the matrix norm or vector norm of a given tensor. Warning torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. dim(int,tuple of python:ints,list of python:ints,optional) \u2013 Specifies which dimension or dimensions ofinputto\ncalculate the norm across. IfdimisNone, the norm will\nbe calculated across all dimensions ofinput. If the norm\ntype indicated bypdoes not support the specified number of\ndimensions, an error will occur. keepdim(bool,optional) \u2013 whether the output tensors havedimretained or not. Ignored ifdim=Noneandout=None. Default:False out(Tensor,optional) \u2013 the output tensor. Ignored ifdim=Noneandout=None. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the default value for the order of norm?": {
        "answer": "Default:'fro",
        "question": "What is the default value for the order of norm?",
        "context": "Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "The input tensor's data type must be either a what?": {
        "answer": "floating point or complex type",
        "question": "The input tensor's data type must be either a what?",
        "context": "Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "p(int,float,inf,-inf,'fro','nuc',optional) \u2013 what": {
        "answer": "the order of norm",
        "question": "p(int,float,inf,-inf,'fro','nuc',optional) \u2013 what",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the default name for the order of norm?": {
        "answer": "Default:'fro",
        "question": "What is the default name for the order of norm?",
        "context": "torch.norm is deprecated and may be removed in a future PyTorch release. Usetorch.linalg.norm(), instead, ortorch.linalg.vector_norm()when computing vector norms andtorch.linalg.matrix_norm()when\ncomputing matrix norms. Note, however, the signature for these functions\nis slightly different than the signature for torch.norm. input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "If input is complex and neitherdtypenoroutis specified, the result's data type will be what?": {
        "answer": "corresponding floating point type",
        "question": "If input is complex and neitherdtypenoroutis specified, the result's data type will be what?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the name of the nuclear norm?": {
        "answer": "Frobenius norm",
        "question": "What is the name of the nuclear norm?",
        "context": "input(Tensor) \u2013 The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neitherdtypenoroutis specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float ifinputis\ncomplexfloat). p(int,float,inf,-inf,'fro','nuc',optional) \u2013 the order of norm. Default:'fro'The following norms can be calculated: ord matrix norm vector norm \u2019fro\u2019 Frobenius norm \u2013 \u2018nuc\u2019 nuclear norm \u2013 Number \u2013 sum(abs(x)**ord)**(1./ord) The vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions ofinputare flattened into\none dimension, and the norm is calculated on the flattened\ndimension. Frobenius norm produces the same result asp=2in all cases\nexcept whendimis a list of three or more dims, in which\ncase Frobenius norm throws an error. Nuclear norm can only be calculated across exactly two dimensions. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm"
    },
    "What is the term for a feature that may change based on user feedback?": {
        "answer": "Beta",
        "question": "What is the term for a feature that may change based on user feedback?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What classification do we commit to seeing the feature through for Beta features?": {
        "answer": "Stable",
        "question": "What classification do we commit to seeing the feature through for Beta features?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What features are typically not available as part of binary distributions like PyPI or Conda?": {
        "answer": "Prototype",
        "question": "What features are typically not available as part of binary distributions like PyPI or Conda?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What feature is typically not available as part of binary distributions like PyPI or Conda?": {
        "answer": "Prototype",
        "question": "What feature is typically not available as part of binary distributions like PyPI or Conda?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "What is 111 Conv1,2,3D 111 Sigmoid 111 Tanh 53frac5335": {
        "answer": "gain Linear / Identity",
        "question": "What is 111 Conv1,2,3D 111 Sigmoid 111 Tanh 53frac5335",
        "context": "gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "The default gain forSELUsacrifices what effect for more stable gradient flow in rectangular layers?": {
        "answer": "the normalisation effect",
        "question": "The default gain forSELUsacrifices what effect for more stable gradient flow in rectangular layers?",
        "context": "Return the recommended gain value for the given nonlinearity function.\nThe values are as follows: nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the definition of Identity 111 Conv1,2,3D 111 Sigmoid 111 Tanh 53frac5": {
        "answer": "Linear",
        "question": "What is the definition of Identity 111 Conv1,2,3D 111 Sigmoid 111 Tanh 53frac5",
        "context": "Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is needed to induce a stable fixed point in the forward pass?": {
        "answer": "a variance of1/N",
        "question": "What is needed to induce a stable fixed point in the forward pass?",
        "context": "Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What do the initial weights have to have in order to induce a stable fixed point in the forward pass?": {
        "answer": "variance of1/N",
        "question": "What do the initial weights have to have in order to induce a stable fixed point in the forward pass?",
        "context": "Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the Sigmoid 111 Tanh?": {
        "answer": "Sigmoid 111 Tanh",
        "question": "What is the name of the Sigmoid 111 Tanh?",
        "context": "Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is Tanh's number?": {
        "answer": "111",
        "question": "What is Tanh's number?",
        "context": "111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does usingnonlinearity='selu' give the initial weights?": {
        "answer": "variance of1/N",
        "question": "What does usingnonlinearity='selu' give the initial weights?",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is param?": {
        "answer": "optional parameter",
        "question": "What is param?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does the input Tensor have to fill the tensor with?": {
        "answer": "scalar value",
        "question": "What value does the input Tensor have to fill the tensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does an n-dimensionaltorch fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What value does an n-dimensionaltorch fill the input Tensor with?",
        "context": "Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the 2-dimensional inputTensor with what?": {
        "answer": "identity matrix",
        "question": "Fills the 2-dimensional inputTensor with what?",
        "context": "Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Preserves the identity of the inputs inLinearlayers where?": {
        "answer": "as many inputs are preserved as possible",
        "question": "Preserves the identity of the inputs inLinearlayers where?",
        "context": "Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Fills the 2-dimensional inputTensorwith the identity matrix?": {
        "answer": "Preserves the identity of the inputs",
        "question": "What does Fills the 2-dimensional inputTensorwith the identity matrix?",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the a-b bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal distribution?": {
        "answer": "the lower bound of the uniform distribution",
        "question": "What is the a-b bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal distribution?",
        "context": "a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "InLinearlayers, where as many inputs are preserved as possible, what does Fills the 2-dimensional inputTensorwith the identity": {
        "answer": "Preserves the identity of the inputs",
        "question": "InLinearlayers, where as many inputs are preserved as possible, what does Fills the 2-dimensional inputTensorwith the identity",
        "context": "Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the 3, 4, 5-dimensional inputTensorwith what?": {
        "answer": "Dirac delta function",
        "question": "Fills the 3, 4, 5-dimensional inputTensorwith what?",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Where are as many input channels preserved as possible?": {
        "answer": "Convolutionallayers",
        "question": "Where are as many input channels preserved as possible?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of Glorot's paper Understanding the difficulty of training deep feedforward neural networks?": {
        "answer": "X",
        "question": "What is the name of Glorot's paper Understanding the difficulty of training deep feedforward neural networks?",
        "context": "Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Who wrote Understanding the difficulty of training deep feedforward neural networks?": {
        "answer": "Bengio",
        "question": "Who wrote Understanding the difficulty of training deep feedforward neural networks?",
        "context": "val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is used to fill the inputTensor with values according to the method described inUnderstanding the difficulty of training deep feedforward neural networks": {
        "answer": "uniform distribution",
        "question": "What is used to fill the inputTensor with values according to the method described inUnderstanding the difficulty of training deep feedforward neural networks",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the resulting tensor known as?": {
        "answer": "Glorot initialization",
        "question": "What is the resulting tensor known as?",
        "context": "std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the author of Understanding the difficulty of training deep feedforward neural networks?": {
        "answer": "X",
        "question": "What is the name of the author of Understanding the difficulty of training deep feedforward neural networks?",
        "context": "Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Moon-Penrose inverse stand for?": {
        "answer": "the pseudoinverse",
        "question": "What does Moon-Penrose inverse stand for?",
        "context": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "Ifhermitian= True,Ais assumed to be what if complex or symmetric if real?": {
        "answer": "Hermitian",
        "question": "Ifhermitian= True,Ais assumed to be what if complex or symmetric if real?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What function synchronizes that device with the CPU?": {
        "answer": "usestorch.linalg.svd()ifhermitian= False",
        "question": "What function synchronizes that device with the CPU?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is a possible way to multiply a matrix on the left by the pseudoinverse?": {
        "answer": "usingtorch.linalg.lstsq()",
        "question": "What is a possible way to multiply a matrix on the left by the pseudoinverse?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "The pseudoinverse can be defined algebraically but it is more computationally convenient to understand it through what?": {
        "answer": "SVD",
        "question": "The pseudoinverse can be defined algebraically but it is more computationally convenient to understand it through what?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does the pseudoinverse support?": {
        "answer": "batches of matrices",
        "question": "What does the pseudoinverse support?",
        "context": "The pseudoinverse may bedefined algebraicallybut it is more computationally convenient to understand itthrough the SVD Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is faster and more numerically stable than computing the pseudoinverse explicitly?": {
        "answer": "usingtorch.linalg.lstsq()",
        "question": "What is faster and more numerically stable than computing the pseudoinverse explicitly?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is a warning about usinglstsq() for multiplying a matrix on the left by the pseudoinverse?": {
        "answer": "Warning",
        "question": "What is a warning about usinglstsq() for multiplying a matrix on the left by the pseudoinverse?",
        "context": "Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions. Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What does usestorch.linalg.svd() do for CUDA inputs?": {
        "answer": "synchronizes that device with the CPU",
        "question": "What does usestorch.linalg.svd() do for CUDA inputs?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "What is the name of the warning that is issued when a matrix is multiplied by the pseudoinverse?": {
        "answer": "Warning",
        "question": "What is the name of the warning that is issued when a matrix is multiplied by the pseudoinverse?",
        "context": "Ifhermitian= True,Ais assumed to be Hermitian if complex or\nsymmetric if real, but this is not checked internally. Instead, just the lower\ntriangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation. Note This function usestorch.linalg.svd()ifhermitian= Falseandtorch.linalg.eigh()ifhermitian= True.\nFor CUDA inputs, this function synchronizes that device with the CPU. Note Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as: It is always prefered to uselstsq()when possible, as it is faster and more\nnumerically stable than computing the pseudoinverse explicitly. Warning ",
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv"
    },
    "How often does a value appear in a given row of the inputtensor?": {
        "answer": "most often",
        "question": "How often does a value appear in a given row of the inputtensor?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "If the output tensors are of the same size as input, what is the default?": {
        "answer": "IfkeepdimisTrue",
        "question": "If the output tensors are of the same size as input, what is the default?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "If keepdimisTrue, the output tensors are of the same size asinput except in the dimensiondimwhere they": {
        "answer": "1",
        "question": "If keepdimisTrue, the output tensors are of the same size asinput except in the dimensiondimwhere they",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What is the name of the function that returns whether the output tensor hasdimretained or not?": {
        "answer": "keepdim",
        "question": "What is the name of the function that returns whether the output tensor hasdimretained or not?",
        "context": "Returns a namedtuple(values,indices)wherevaluesis the mode\nvalue of each row of theinputtensor in the given dimensiondim, i.e. a value which appears most often\nin that row, andindicesis the index location of each mode value found. By default,dimis the last dimension of theinputtensor. IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput. Note This function is not defined fortorch.cuda.Tensoryet. input(Tensor) \u2013 the input tensor. dim(int) \u2013 the dimension to reduce. keepdim(bool) \u2013 whether the output tensor hasdimretained or not. out(tuple,optional) \u2013 the result tuple of two output tensors (values, indices) Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode"
    },
    "What does this class wrap around an arbitraryoptim.Optimizer?": {
        "answer": "shards",
        "question": "What does this class wrap around an arbitraryoptim.Optimizer?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "The optimizer instance in each rank is only responsible for what?": {
        "answer": "updating1/world_sizeparameters",
        "question": "The optimizer instance in each rank is only responsible for what?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "To whom will each rank broadcast its parameters after parameters are updated locally?": {
        "answer": "all other peers",
        "question": "To whom will each rank broadcast its parameters after parameters are updated locally?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does ZeroRedundancyOptimizer use to pack a number of parameters at each rank?": {
        "answer": "greedy algorithm",
        "question": "What does ZeroRedundancyOptimizer use to pack a number of parameters at each rank?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How does each parameter belong to a single rank?": {
        "answer": "not divided among ranks",
        "question": "How does each parameter belong to a single rank?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the partition of a zero redundancyoptimizer?": {
        "answer": "arbitrary",
        "question": "What is the partition of a zero redundancyoptimizer?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What class does optimizer_class(torch.nn.Optimizer) belong to?": {
        "answer": "local optimizer",
        "question": "What class does optimizer_class(torch.nn.Optimizer) belong to?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What does state_dict(dict) refer to?": {
        "answer": "optimizer state",
        "question": "What does state_dict(dict) refer to?",
        "context": "to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a single optimization step?": {
        "answer": "parameter update",
        "question": "What is a single optimization step?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is an object returned from a call tostate_dict() Gets this rank'sstate_dict?": {
        "answer": "state_dict(dict)",
        "question": "What is an object returned from a call tostate_dict() Gets this rank'sstate_dict?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What should be an object returned from a call?": {
        "answer": "tostate_dict()",
        "question": "What should be an object returned from a call?",
        "context": "Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Inverse short time Fourier Transform is expected to be what?": {
        "answer": "inverse ofstft()",
        "question": "Inverse short time Fourier Transform is expected to be what?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the envelop created by the summation of all the windows at certain point in time?": {
        "answer": "never zero",
        "question": "What is the envelop created by the summation of all the windows at certain point in time?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the envelop created by the summation of all the windows never zero at certain point in time?": {
        "answer": "0",
        "question": "What is the envelop created by the summation of all the windows never zero at certain point in time?",
        "context": "Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. Example: Suppose the last window is:[17,18,0,0,0]vs[18,0,0,0,0] ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What can be trimmed off precisely because they can be calculated?": {
        "answer": "Left padding",
        "question": "What can be trimmed off precisely because they can be calculated?",
        "context": "Inverse short time Fourier Transform. This is expected to be the inverse ofstft().\nIt has the same parameters (+ additional optional parameter oflength) and it should return the\nleast squares estimation of the original signal. The algorithm will check using the NOLA condition (\nnonzero overlap). Important consideration in the parameterswindowandcenterso that the envelop\ncreated by the summation of all the windows is never zero at certain point in time. Specifically,\u2211t=\u2212\u221e\u221e\u2223w\u22232[n\u2212t\u00d7hop_length]=0\\sum_{t=-\\infty}^{\\infty} |w|^2[n-t\\times hop\\_length] \\cancel{=} 0\u2211t=\u2212\u221e\u221e\u200b\u2223w\u22232[n\u2212t\u00d7hop_length]=\u200b0. Sincestft()discards elements at the end of the signal if they do not fit in a frame,istftmay return a shorter signal than the original signal (can occur ifcenteris False\nsince the signal isn\u2019t padded). IfcenterisTrue, then there will be padding e.g.'constant','reflect', etc.\nLeft padding can be trimmed off exactly because they can be calculated but right padding cannot be\ncalculated without additional information. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What are some examples of complex inputs?": {
        "answer": "channel,fft_size,n_frame",
        "question": "What are some examples of complex inputs?",
        "context": "The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Since what version is input(Tensor) deprecated?": {
        "answer": "1.8.0",
        "question": "Since what version is input(Tensor) deprecated?",
        "context": "input(Tensor) \u2013 The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the": {
        "answer": "normalized",
        "question": "Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the",
        "context": "Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What does Trueifn_fft! mean in the input size?": {
        "answer": "fft_size",
        "question": "What does Trueifn_fft! mean in the input size?",
        "context": "The input tensor. Expected to be output ofstft(),\ncan either be complex (channel,fft_size,n_frame), or real\n(channel,fft_size,n_frame, 2) where thechanneldimension is optional. Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is the default signal to trim?": {
        "answer": "whole",
        "question": "What is the default signal to trim?",
        "context": "Deprecated since version 1.8.0:Real input is deprecated, use complex inputs as returned bystft(...,return_complex=True)instead. n_fft(int) \u2013 Size of Fourier transform hop_length(Optional[int]) \u2013 The distance between neighboring sliding window frames.\n(Default:n_fft//4) win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Whether the STFT was normalized?": {
        "answer": "normalized",
        "question": "Whether the STFT was normalized?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Whether the STFT was onesided or false?": {
        "answer": "onesided",
        "question": "Whether the STFT was onesided or false?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "Whether the output should be complex or if the input should be assumed to derive from a real signal and window?": {
        "answer": "return_complex",
        "question": "Whether the output should be complex or if the input should be assumed to derive from a real signal and window?",
        "context": "win_length(Optional[int]) \u2013 The size of window frame and STFT filter. (Default:n_fft) window(Optional[torch.Tensor]) \u2013 The optional window function.\n(Default:torch.ones(win_length)) center(bool) \u2013 Whetherinputwas padded on both sides so that thettt-th frame is\ncentered at timet\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default:True) normalized(bool) \u2013 Whether the STFT was normalized. (Default:False) onesided(Optional[bool]) \u2013 Whether the STFT was onesided.\n(Default:Trueifn_fft!=fft_sizein the input size) length(Optional[int]) \u2013 The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal) return_complex(Optional[bool]) \u2013 Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible withonesided=True.\n(Default:False) Least squares estimation of the original signal of size (\u2026, signal_length) Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.istft.html#torch.istft"
    },
    "What is returned by sizeendstartstepleftlceil fractextend - textstart": {
        "answer": "1-D tensor",
        "question": "What is returned by sizeendstartstepleftlceil fractextend - textstart",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default for a global default?": {
        "answer": "ifNone",
        "question": "What is the default for a global default?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "If the data type is not given, infer the data type from the other input arguments.": {
        "answer": "Ifdtypeis not given",
        "question": "If the data type is not given, infer the data type from the other input arguments.",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What is the default dtype inferred to be?": {
        "answer": "betorch.int64",
        "question": "What is the default dtype inferred to be?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart. Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "Non-integerstep is subject to what when comparing againstend?": {
        "answer": "floating point rounding errors",
        "question": "Non-integerstep is subject to what when comparing againstend?",
        "context": "Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases. start(Number) \u2013 the starting value for the set of points. Default:0. end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What default uses a global default?": {
        "answer": "ifNone",
        "question": "What default uses a global default?",
        "context": "window_length(int) \u2013 the size of returned window periodic(bool,optional) \u2013 If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Only floating point types are supported. layout(torch.layout, optional) \u2013 the desired layout of returned window tensor. Onlytorch.strided(dense layout) is supported. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. requires_grad(bool,optional) \u2013 If autograd should record operations on the\nreturned tensor. Default:False. A 1-D tensor of size(window_length,)(\\text{window\\_length},)(window_length,)containing the window Tensor ",
        "source": "https://pytorch.org/docs/stable/generated/torch.bartlett_window.html#torch.bartlett_window"
    },
    "If any ofstart,end, orstopare floating-point, thedtypeis inferred to be what?": {
        "answer": "the default dtype",
        "question": "If any ofstart,end, orstopare floating-point, thedtypeis inferred to be what?",
        "context": "end(Number) \u2013 the ending value for the set of points step(Number) \u2013 the gap between each pair of adjacent points. Default:1. out(Tensor,optional) \u2013 the output tensor. dtype(torch.dtype, optional) \u2013 the desired data type of returned tensor.\nDefault: ifNone, uses a global default (seetorch.set_default_tensor_type()). Ifdtypeis not given, infer the data type from the other input\narguments. If any ofstart,end, orstopare floating-point, thedtypeis inferred to be the default dtype, seeget_default_dtype(). Otherwise, thedtypeis inferred to\nbetorch.int64. layout(torch.layout, optional) \u2013 the desired layout of returned Tensor.\nDefault:torch.strided. device(torch.device, optional) \u2013 the desired device of returned tensor.\nDefault: ifNone, uses the current device for the default tensor type\n(seetorch.set_default_tensor_type()).devicewill be the CPU\nfor CPU tensor types and the current CUDA device for CUDA tensor types. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange"
    },
    "What does the torch package provide for efficient serializing of Tensors and arbitrary types?": {
        "answer": "utilities",
        "question": "What does the torch package provide for efficient serializing of Tensors and arbitrary types?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch package return ifobjis a PyTorch tensor?": {
        "answer": "PyTorch storage object",
        "question": "What does the torch package return ifobjis a PyTorch tensor?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is not equal to zero after type conversions?": {
        "answer": "a single element tensor",
        "question": "What type of tensor is not equal to zero after type conversions?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch set?": {
        "answer": "default floating point dtype tod",
        "question": "What does the torch set?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch package get?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What does the torch package get?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what ifobjis a PyTorch tensor?": {
        "answer": "True",
        "question": "Returns what ifobjis a PyTorch tensor?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns True if theinputis a single element tensor which is not equal to zero after type conversions?": {
        "answer": "if theinputis a single element tensor",
        "question": "Returns True if theinputis a single element tensor which is not equal to zero after type conversions?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns the defaulttorch.Tensortype return?": {
        "answer": "total number of elements in theinputtensor",
        "question": "What does Returns the defaulttorch.Tensortype return?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What disables denormal floating numbers on CPU?": {
        "answer": "Disables",
        "question": "What disables denormal floating numbers on CPU?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is constructed?": {
        "answer": "a tensor withdata",
        "question": "What type of tensor is constructed?",
        "context": "Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Constructs asparse tensor in COO(rdinate) formatwith what?": {
        "answer": "specified values at the givenindices",
        "question": "Constructs asparse tensor in COO(rdinate) formatwith what?",
        "context": "Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Constructs asparse tensor in COO(rdinate) format with what?": {
        "answer": "specified values at the givenindices",
        "question": "Constructs asparse tensor in COO(rdinate) format with what?",
        "context": "Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Creates aTensorfrom what?": {
        "answer": "anumpy.ndarray",
        "question": "Creates aTensorfrom what?",
        "context": "Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the defaulttorch.Tensortype?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What is the defaulttorch.Tensortype?",
        "context": "Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned by the defaulttorch.Tensortype to floating point tensor typet?": {
        "answer": "the total number of elements in theinputtensor",
        "question": "What is returned by the defaulttorch.Tensortype to floating point tensor typet?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In what format is the asparse tensor constructed?": {
        "answer": "COO(rdinate)",
        "question": "In what format is the asparse tensor constructed?",
        "context": "Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the asparse tensor in COO(rdinate) format contain?": {
        "answer": "specified values at the givenindices",
        "question": "What does the asparse tensor in COO(rdinate) format contain?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What tensor of sizeendstartstepleftlceil fractextend - text": {
        "answer": "1-D",
        "question": "What tensor of sizeendstartstepleftlceil fractextend - text",
        "context": "Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of sizeendstartstep+1leftlfloor fractextend ": {
        "answer": "1",
        "question": "Returns a tensor of sizeendstartstep+1leftlfloor fractextend ",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the tensorinput that creates a view of an existingtorch.Tensorinput": {
        "answer": "specifiedsize,strideandstorage_offset",
        "question": "What is the name of the tensorinput that creates a view of an existingtorch.Tensorinput",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a tensor filled with the scalar value0?": {
        "answer": "a tensor filled with the scalar value0",
        "question": "What returns a tensor filled with the scalar value0?",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the tensor of sizeendstartstepleftlceil fractextend - ": {
        "answer": "1-D",
        "question": "What is the tensor of sizeendstartstepleftlceil fractextend - ",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What tensor of sizeendstartstep+1leftlfloor fractextend - ": {
        "answer": "1-D tensor",
        "question": "What tensor of sizeendstartstep+1leftlfloor fractextend - ",
        "context": "Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor does anumpy.ndarray create?": {
        "answer": "one-dimensional",
        "question": "What type of tensor does anumpy.ndarray create?",
        "context": "Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is filled with the scalar value0?": {
        "answer": "a tensor",
        "question": "What is filled with the scalar value0?",
        "context": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "On a logarithmic scale with what is the value of a one-dimensional tensor of sizesteps?": {
        "answer": "basebase",
        "question": "On a logarithmic scale with what is the value of a one-dimensional tensor of sizesteps?",
        "context": "Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What tensor is created on a logarithmic scale with basebase?": {
        "answer": "a one-dimensional tensor of sizesteps",
        "question": "What tensor is created on a logarithmic scale with basebase?",
        "context": "Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what size tensor of sizeendstartstepleftlceil fractextend": {
        "answer": "1-D",
        "question": "Returns a what size tensor of sizeendstartstepleftlceil fractextend",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value of what?": {
        "answer": "1",
        "question": "Returns a tensor filled with the scalar value of what?",
        "context": "Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens when a tensor is filled with uninitialized data?": {
        "answer": "Returns an uninitialized tensor with the same size asinput",
        "question": "What happens when a tensor is filled with uninitialized data?",
        "context": "Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How many tensors does sizeendstartstep return?": {
        "answer": "1",
        "question": "How many tensors does sizeendstartstep return?",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "On what scale is a one-dimensional tensor of sizesteps created?": {
        "answer": "a logarithmic scale with basebase",
        "question": "On what scale is a one-dimensional tensor of sizesteps created?",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with what type of data?": {
        "answer": "uninitialized",
        "question": "Returns a tensor filled with what type of data?",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of sizesizefilled filled with uninitialized data. Returns a tensor with the": {
        "answer": "withfill_value",
        "question": "Returns a tensor of sizesizefilled filled with uninitialized data. Returns a tensor with the",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with what size asinputfilled withfill_value?": {
        "answer": "same size asinputfilled withfill_value",
        "question": "Returns a tensor with what size asinputfilled withfill_value?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Converts a float tensor to what with given scale and zero point?": {
        "answer": "quantized tensor",
        "question": "Converts a float tensor to what with given scale and zero point?",
        "context": "Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "On a logarithmic scale, what is the value of the one-dimensional tensor of sizesteps?": {
        "answer": "basebase",
        "question": "On a logarithmic scale, what is the value of the one-dimensional tensor of sizesteps?",
        "context": "Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Creates a tensor of sizesizefilled what?": {
        "answer": "withfill_value",
        "question": "Creates a tensor of sizesizefilled what?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a float tensor convert to?": {
        "answer": "per-channel quantized tensor with given scales and zero points",
        "question": "What does a float tensor convert to?",
        "context": " Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a float tensor converted to?": {
        "answer": "per-channel quantized tensor",
        "question": "What is a float tensor converted to?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is returned by dequantizing a quantized Tensor?": {
        "answer": "fp32",
        "question": "What type of tensor is returned by dequantizing a quantized Tensor?",
        "context": " Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is created when a tensor is filled with uninitialized data?": {
        "answer": "a tensor of sizesizefilled withfill_value",
        "question": "What is created when a tensor is filled with uninitialized data?",
        "context": " Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What tensor is converted to a quantized tensor with given scale and zero point?": {
        "answer": "float",
        "question": "What tensor is converted to a quantized tensor with given scale and zero point?",
        "context": "Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens to the given sequence ofseqtensors in the given dimension?": {
        "answer": "Concatenates",
        "question": "What happens to the given sequence ofseqtensors in the given dimension?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splits a tensor into what?": {
        "answer": "multiple sub-tensors",
        "question": "Splits a tensor into what?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splitsinput, a tensor with three or more dimensions, into what according toindices_or_sections?": {
        "answer": "multiple tensors depthwise",
        "question": "Splitsinput, a tensor with three or more dimensions, into what according toindices_or_sections?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens when horizontally stacking the tensors intensors?": {
        "answer": "Creates a new tensor",
        "question": "What happens when horizontally stacking the tensors intensors?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splitsinput, a tensor with one or more dimensions, into what according toindices_or_sections?": {
        "answer": "multiple tensors horizontally",
        "question": "Splitsinput, a tensor with one or more dimensions, into what according toindices_or_sections?",
        "context": "Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination?": {
        "answer": "Alias fortorch.movedim()",
        "question": "What function moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Split a tensor into?": {
        "answer": "a specific number of chunks",
        "question": "What does Split a tensor into?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Creates a new tensor by what?": {
        "answer": "horizontally stacking the tensors intensors",
        "question": "Creates a new tensor by what?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a tensor with one or more dimensions split into?": {
        "answer": "multiple tensors horizontally",
        "question": "What does a tensor with one or more dimensions split into?",
        "context": "Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that moves the dimension(s) ofinputat the position(s) insourceto the position(s)": {
        "answer": "Alias fortorch.movedim()",
        "question": "What is the name of the function that moves the dimension(s) ofinputat the position(s) insourceto the position(s)",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a tensor with the same data and number of elements asinput but with the specified shape": {
        "answer": "Alias oftorch.vstack()",
        "question": "What is the name of the function that returns a tensor with the same data and number of elements asinput but with the specified shape",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How do you create a new tensor by horizontally stacking the tensors intensors?": {
        "answer": "Stack tensors",
        "question": "How do you create a new tensor by horizontally stacking the tensors intensors?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens when a tensor is stacked horizontally?": {
        "answer": "Gathers values along an axis specified bydim",
        "question": "What happens when a tensor is stacked horizontally?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is used to split a tensor with one or more dimensions into multiple tensors horizontally?": {
        "answer": "indices_or_sections",
        "question": "What is used to split a tensor with one or more dimensions into multiple tensors horizontally?",
        "context": "Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What do tensors do in sequence depthwise?": {
        "answer": "Stack tensors",
        "question": "What do tensors do in sequence depthwise?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according to?": {
        "answer": "indices_or_sections",
        "question": "What does Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according to?",
        "context": "Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Gathers values along what specified bydim?": {
        "answer": "axis",
        "question": "Gathers values along what specified bydim?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does it do when a tensor is split into multiple tensors?": {
        "answer": "Stack tensors",
        "question": "What does it do when a tensor is split into multiple tensors?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which version oftorch.Tensor.scatter_add_() Splits the tensor into chunks?": {
        "answer": "Out-of-place version oftorch.Tensor.scatter_()",
        "question": "Which version oftorch.Tensor.scatter_add_() Splits the tensor into chunks?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a tensor with one or more dimensions do?": {
        "answer": "Splitsinput",
        "question": "What does a tensor with one or more dimensions do?",
        "context": "Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens when a tensor is returned with all the dimensions ofinputof size1removed?": {
        "answer": "Concatenates a sequence of tensors along a new dimension",
        "question": "What happens when a tensor is returned with all the dimensions ofinputof size1removed?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a tensor with all the dimensions ofinputof size1removed?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What function returns a tensor with all the dimensions ofinputof size1removed?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.transpose() call?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What does Alias fortorch.transpose() call?",
        "context": "Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What dimensions does Alias fortorch.transpose() transpose?": {
        "answer": "0 and 1",
        "question": "What dimensions does Alias fortorch.transpose() transpose?",
        "context": "Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with the elements of what?": {
        "answer": "given indices",
        "question": "Returns a new tensor with the elements of what?",
        "context": "Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Selects values from what indicesalong the givendim?": {
        "answer": "1-dimensional indices",
        "question": "Selects values from what indicesalong the givendim?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.movedim() do?": {
        "answer": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination",
        "question": "What does Alias fortorch.movedim() do?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what with all the dimensions ofinputof size1removed?": {
        "answer": "a tensor",
        "question": "Returns what with all the dimensions ofinputof size1removed?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that transforms a sequence of tensors along a new dimension?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What is the name of the function that transforms a sequence of tensors along a new dimension?",
        "context": "Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with the elements ofinputat what?": {
        "answer": "given indices",
        "question": "Returns a new tensor with the elements ofinputat what?",
        "context": "Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a new tensor that returns a new tensor that is?": {
        "answer": "a narrowed version ofinputtensor",
        "question": "What is a new tensor that returns a new tensor that is?",
        "context": "Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Selects values from what indices along the givendim?": {
        "answer": "1-dimensional indices",
        "question": "Selects values from what indices along the givendim?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are the sub-tensors all of which split a tensor into?": {
        "answer": "views ofinput",
        "question": "What are the sub-tensors all of which split a tensor into?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How does one construct a tensor?": {
        "answer": "by repeating the elements ofinput",
        "question": "How does one construct a tensor?",
        "context": "Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are the dimensions of a tensor?": {
        "answer": "0 and 1",
        "question": "What are the dimensions of a tensor?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with what removed?": {
        "answer": "all the dimensions ofinputof size1",
        "question": "Returns a tensor with what removed?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a tensor with all the dimensions ofinput of size1removed?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What is the name of the function that returns a tensor with all the dimensions ofinput of size1removed?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with the elements ofinputat the given what?": {
        "answer": "indices",
        "question": "Returns a new tensor with the elements ofinputat the given what?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How is a tensor constructed?": {
        "answer": "repeating the elements ofinput",
        "question": "How is a tensor constructed?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor that is what?": {
        "answer": "a transposed version ofinput",
        "question": "Returns a tensor that is what?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns a tensor that is a transposed version ofinput do?": {
        "answer": "Removes a tensor dimension",
        "question": "What does Returns a tensor that is a transposed version ofinput do?",
        "context": "     Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of the same size asinputwith each element sampled from what distribution with rate parameter given by the corresponding": {
        "answer": "Poisson",
        "question": "Returns a tensor of the same size asinputwith each element sampled from what distribution with rate parameter given by the corresponding",
        "context": "Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) and what (exclusive)?": {
        "answer": "high",
        "question": "Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) and what (exclusive)?",
        "context": "Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Draws binary random numbers (0 or 1) from what?": {
        "answer": "a Bernoulli distribution",
        "question": "Draws binary random numbers (0 or 1) from what?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Each element sampled from what distribution with rate parameter given by the corresponding element ininputi.e., Returns a tens": {
        "answer": "Poisson",
        "question": "Each element sampled from what distribution with rate parameter given by the corresponding element ininputi.e., Returns a tens",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when a tensor is filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?": {
        "answer": "tensor with the same shape",
        "question": "What is returned when a tensor is filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?",
        "context": "Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive": {
        "answer": "a tensor",
        "question": "Returns what with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive",
        "context": "Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with random numbers from a normal distribution with what?": {
        "answer": "mean0and variance1",
        "question": "Returns a tensor filled with random numbers from a normal distribution with what?",
        "context": "Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is defined on Tensors as well?": {
        "answer": "in-place random sampling functions",
        "question": "What is defined on Tensors as well?",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the log-normal distribution torch?": {
        "answer": "normal",
        "question": "What is the name of the log-normal distribution torch?",
        "context": "Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a tensor filled with random numbers from 0ton-1?": {
        "answer": "random permutation of integers",
        "question": "What returns a tensor filled with random numbers from 0ton-1?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where are the numbers sampled from?": {
        "answer": "discrete uniform distribution",
        "question": "Where are the numbers sampled from?",
        "context": "  Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Tensor.uniform_()- numbers sampled from what distribution?": {
        "answer": "continuous uniform distribution",
        "question": "Tensor.uniform_()- numbers sampled from what distribution?",
        "context": "There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.acos(). Returns a new tensor with what cosine of the elements of": {
        "answer": "inverse hyperbolic",
        "question": "Alias fortorch.acos(). Returns a new tensor with what cosine of the elements of",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise division performed by Alias fortorch?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise division performed by Alias fortorch?",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the arctangent of the elements ofinput?": {
        "answer": "Alias fortorch.atan()",
        "question": "What is the name of the function that returns a new tensor with the arctangent of the elements ofinput?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput. Alias fortorch": {
        "answer": "arctangent",
        "question": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput. Alias fortorch",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.atan(). Returns a new tensor with what of the elements ofinput?": {
        "answer": "inverse hyperbolic tangent",
        "question": "Alias fortorch.atan(). Returns a new tensor with what of the elements ofinput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the inverse hyperbolic tangent of the elements ofin": {
        "answer": "Alias fortorch.atanh()",
        "question": "What is the name of the function that returns a new tensor with the inverse hyperbolic tangent of the elements ofin",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what cosine of the elements ofinput?": {
        "answer": "hyperbolic",
        "question": "Returns a new tensor with what cosine of the elements ofinput?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise division performed by Alias fortorch.acosh()?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise division performed by Alias fortorch.acosh()?",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what sine of the elements ofinput?": {
        "answer": "inverse hyperbolic",
        "question": "Returns a new tensor with what sine of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.asinh(). Returns a new tensor with the inverse hyperbolic sine": {
        "answer": "arctangent",
        "question": "Alias fortorch.asinh(). Returns a new tensor with the inverse hyperbolic sine",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the element-wise multiplication performed by Alias fortorch.acos?": {
        "answer": "oftensor1bytensor2",
        "question": "What is the name of the element-wise multiplication performed by Alias fortorch.acos?",
        "context": "Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that adds the scalarotherto each element of the input input?": {
        "answer": "Alias fortorch.acosh()",
        "question": "What is the name of the function that adds the scalarotherto each element of the input input?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?": {
        "answer": "Alias fortorch.atanh()",
        "question": "What function returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a new tensor with the inverse hyperbolic sine of the elements ofinput?": {
        "answer": "Alias fortorch.asin()",
        "question": "What function returns a new tensor with the inverse hyperbolic sine of the elements ofinput?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the bitwise OR ofinputandother. Computes the bitwise XOR ofinputandother.": {
        "answer": "AND",
        "question": "Computes the bitwise OR ofinputandother. Computes the bitwise XOR ofinputandother.",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the bitwise what ofinputandother?": {
        "answer": "OR",
        "question": "Computes the bitwise what ofinputandother?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Computes the bitwise NOT of the given input tensor?": {
        "answer": "Computes the bitwise NOT",
        "question": "What does Computes the bitwise NOT of the given input tensor?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Computes the bitwise OR ofinputandother?": {
        "answer": "Computes the bitwise OR ofinputandother",
        "question": "What does Computes the bitwise OR ofinputandother?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what NOT of the given input tensor?": {
        "answer": "bitwise",
        "question": "Computes what NOT of the given input tensor?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.clamp() clamp?": {
        "answer": "all elements ininputinto the range[min,max]",
        "question": "What does Alias fortorch.clamp() clamp?",
        "context": "Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that clamps all elements ininputinto the range[min,max]?": {
        "answer": "Alias fortorch.clamp()",
        "question": "What is the name of the function that clamps all elements ininputinto the range[min,max]?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the bitwise NOT of the given input tensor. Computes the bitwise OR ofinputandother?": {
        "answer": "Computes the bitwise OR ofinputandother",
        "question": "Computes the bitwise NOT of the given input tensor. Computes the bitwise OR ofinputandother?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What computes the element-wise conjugate of the given inputtensor?": {
        "answer": "Alias fortorch.clamp()",
        "question": "What computes the element-wise conjugate of the given inputtensor?",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.clamp() compute?": {
        "answer": "the element-wise conjugate of the giveninputtensor",
        "question": "What does Alias fortorch.clamp() compute?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What computes the element-wise conjugate of the giveninputtensor?": {
        "answer": "Alias fortorch.clamp()",
        "question": "What computes the element-wise conjugate of the giveninputtensor?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.clamp() create a new floating-point tensor with?": {
        "answer": "the magnitude ofinputand the sign ofother",
        "question": "What does Alias fortorch.clamp() create a new floating-point tensor with?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Clamps which elements ininputinto the range[min,max]?": {
        "answer": "all elements ininputinto the range[min,max].",
        "question": "Clamps which elements ininputinto the range[min,max]?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What tangent does Alias fortorch.atan() return a new tensor with?": {
        "answer": "inverse hyperbolic tangent",
        "question": "What tangent does Alias fortorch.atan() return a new tensor with?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.clamp() do?": {
        "answer": "Clamps all elements ininputinto the range[min,max].",
        "question": "What does Alias fortorch.clamp() do?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the indices of the maximum value of all elements in theinputtensor?": {
        "answer": "Returns the indices of the maximum value of all elements in theinputtensor",
        "question": "What returns the indices of the maximum value of all elements in theinputtensor?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the maximum value of each slice of theinputtensor in the given dimension(s)dim?": {
        "answer": "the indices of the minimum value(s) of the flattened tensor or along a dimension",
        "question": "What returns the maximum value of each slice of theinputtensor in the given dimension(s)dim?",
        "context": "Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the maximum value of all elements in theinputtensor. Returns the minimum value of all elements in theinputtensor": {
        "answer": "input tensor",
        "question": "Returns the maximum value of all elements in theinputtensor. Returns the minimum value of all elements in theinputtensor",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of the minimum value(s) of the flattened tensor or along a dimension?": {
        "answer": "the indices",
        "question": "Returns what of the minimum value(s) of the flattened tensor or along a dimension?",
        "context": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value in the given dimension(s)dim?": {
        "answer": "the maximum value of each slice of theinputtensor",
        "question": "Returns what value in the given dimension(s)dim?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns ignoreNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "What does Returns ignoreNaNvalues?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns the matrix norm or vector norm of a given tensor return?": {
        "answer": "the sum of all elements",
        "question": "What does Returns the matrix norm or vector norm of a given tensor return?",
        "context": "Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What quantiles of each row of theinputtensor along the dimensiondim?": {
        "answer": "q-th",
        "question": "What quantiles of each row of theinputtensor along the dimensiondim?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Tests if all elements ininputevaluate to what?": {
        "answer": "True",
        "question": "Tests if all elements ininputevaluate to what?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value, ignoringNaNvalues?": {
        "answer": "the median of the values ininput",
        "question": "Returns what value, ignoringNaNvalues?",
        "context": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the variant oftorch.quantile() do?": {
        "answer": "ignores",
        "question": "What does the variant oftorch.quantile() do?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when Not a Numbers (NaNs) are treated as zero?": {
        "answer": "the sum of all elements",
        "question": "What is returned when Not a Numbers (NaNs) are treated as zero?",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns the sum of all elements in theinputtensor?": {
        "answer": "the product of all elements in theinputtensor",
        "question": "What does Returns the sum of all elements in theinputtensor?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "The variant oftorch.quantile()ignores what ifNaNvalues ininputdid not exist?": {
        "answer": "quantilesqas",
        "question": "The variant oftorch.quantile()ignores what ifNaNvalues ininputdid not exist?",
        "context": "Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is Bessel's correction?": {
        "answer": "IfunbiasedisTrue",
        "question": "What is Bessel's correction?",
        "context": "Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what value?": {
        "answer": "the minimum value of all elements in theinputtensor",
        "question": "Returns what value?",
        "context": "Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns treat Not a Numbers (NaNs) as zero?": {
        "answer": "the sum of all elements",
        "question": "What does Returns treat Not a Numbers (NaNs) as zero?",
        "context": "Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Bessel's correction will be used to calculate the standard deviation.": {
        "answer": "IfunbiasedisTrue",
        "question": "Bessel's correction will be used to calculate the standard deviation.",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "IfunbiasedisTrue, Bessel's correction will be used to calculate what?": {
        "answer": "standard deviation",
        "question": "IfunbiasedisTrue, Bessel's correction will be used to calculate what?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Bessel's correction return?": {
        "answer": "the sum of all elements in theinputtensor",
        "question": "What does Bessel's correction return?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "If Bessel's correction is used, what will be used to calculate the standard deviation?": {
        "answer": "IfunbiasedisTrue",
        "question": "If Bessel's correction is used, what will be used to calculate the standard deviation?",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the sum of all elements in the inputtensor.": {
        "answer": "unique elements",
        "question": "Returns the sum of all elements in the inputtensor.",
        "context": "Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of the input tensor?": {
        "answer": "unique elements",
        "question": "Returns what of the input tensor?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens to every consecutive group of equivalent elements?": {
        "answer": "Eliminates all but the first element",
        "question": "What happens to every consecutive group of equivalent elements?",
        "context": "Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what elements of the input tensor?": {
        "answer": "unique elements",
        "question": "Returns what elements of the input tensor?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Bessel's correction remove from every consecutive group of equivalent elements?": {
        "answer": "Eliminates all but the first element",
        "question": "What does Bessel's correction remove from every consecutive group of equivalent elements?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is Bessel's correction used for?": {
        "answer": "IfunbiasedisTrue",
        "question": "What is Bessel's correction used for?",
        "context": "Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are Broadcast_tensors() used for?": {
        "answer": "shapes",
        "question": "What are Broadcast_tensors() used for?",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of the buckets to which each value in theinputbelongs?": {
        "answer": "indices",
        "question": "Returns what of the buckets to which each value in theinputbelongs?",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when the indices of the buckets are set byboundaries?": {
        "answer": "Do cartesian product of the given sequence of tensors",
        "question": "What is returned when the indices of the buckets are set byboundaries?",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes batched the what?": {
        "answer": "p-norm distance between each pair of the two collections of row vectors",
        "question": "Computes batched the what?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does return a copy ofinput?": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "What does return a copy ofinput?",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the cumulative product of elements ofinputin the dimensiondim?": {
        "answer": "Returns the cumulative product of elements ofinputin the dimensiondim",
        "question": "What returns the cumulative product of elements ofinputin the dimensiondim?",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Ifinputis a vector (1-D tensor), then returns what?": {
        "answer": "a 2-D square tensor",
        "question": "Ifinputis a vector (1-D tensor), then returns what?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the indices of what?": {
        "answer": "buckets",
        "question": "Returns the indices of what?",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns the indices of the buckets to which each value in theinputbelongs?": {
        "answer": "Do cartesian product of the given sequence of tensors",
        "question": "What returns the indices of the buckets to which each value in theinputbelongs?",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the": {
        "answer": "the cumulative product of elements ofinputin the dimensiondim",
        "question": "What is returned when a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of the given sequence of tensors?": {
        "answer": "Do cartesian product",
        "question": "What product of the given sequence of tensors?",
        "context": "Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim": {
        "answer": "the cumulative product of elements ofinputin the dimensiondim",
        "question": "What does the namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim",
        "context": "Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned when calculating the p-norm distance between each pair of row vectors?": {
        "answer": "a copy ofinput",
        "question": "What is returned when calculating the p-norm distance between each pair of row vectors?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns a copy ofinput do?": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "What does Returns a copy ofinput do?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned in dimensiondimofinputandother?": {
        "answer": "the cross product of vectors",
        "question": "What is returned in dimensiondimofinputandother?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the forward difference along the given dimension?": {
        "answer": "n-th",
        "question": "What is the forward difference along the given dimension?",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what ofinputin the dimensiondim?": {
        "answer": "the cumulative product of elements",
        "question": "Returns what ofinputin the dimensiondim?",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of elements ofinputin the dimensiondim?": {
        "answer": "cumulative sum",
        "question": "Returns what of elements ofinputin the dimensiondim?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Ifinputis a vector, then returns a 2-D square tensor Creates a tensor whose diagonals": {
        "answer": "1-D tensor",
        "question": "Ifinputis a vector, then returns a 2-D square tensor Creates a tensor whose diagonals",
        "context": "  Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens with a reduced add step?": {
        "answer": "all matrix multiplications get accumulated along the first dimension",
        "question": "What happens with a reduced add step?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What performs a batch matrix-matrix product of matricesmat1andmat2?": {
        "answer": "matrix multiplication",
        "question": "What performs a batch matrix-matrix product of matricesmat1andmat2?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a batch matrix-matrix product of?": {
        "answer": "matrices stored ininputandmat2",
        "question": "What is a batch matrix-matrix product of?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the batch matrix-matrix product of matrices inbatch1andbatch2 perform?": {
        "answer": "matrices stored ininputandmat2",
        "question": "What does the batch matrix-matrix product of matrices inbatch1andbatch2 perform?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a positive semidefinite matrix to be inverted given?": {
        "answer": "Cholesky factor matrixuuu",
        "question": "What is a positive semidefinite matrix to be inverted given?",
        "context": "Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu(). ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the batch matrix-matrix product of matrices stored ininputandmat2 return?": {
        "answer": "matrix product of theNNN2-D tensors",
        "question": "What does the batch matrix-matrix product of matrices stored ininputandmat2 return?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the solution to what problems for a full rank matrixAAAof size(mn)(m times n": {
        "answer": "least squares and least norm",
        "question": "Computes the solution to what problems for a full rank matrixAAAof size(mn)(m times n",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A from": {
        "answer": "LU",
        "question": "What solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A from",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the positive semidefinite matrix to be inverted given?": {
        "answer": "Cholesky factor matrixuuu",
        "question": "What is the positive semidefinite matrix to be inverted given?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In what version of PyTorch is the torch.special module?": {
        "answer": "BETA",
        "question": "In what version of PyTorch is the torch.special module?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What are still being added to the torch.special module?": {
        "answer": "New functions",
        "question": "What are still being added to the torch.special module?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of each function that may change in future PyTorch releases?": {
        "answer": "documentation",
        "question": "What is the name of each function that may change in future PyTorch releases?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What does the torch.special module do?": {
        "answer": "Computes the inverse error function ofinput",
        "question": "What does the torch.special module do?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the complementary error function ofinput defined as?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "What is the complementary error function ofinput defined as?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of the function that computes the inverse error function ofinput?": {
        "answer": "Computes the inverse error function ofinput",
        "question": "What is the name of the function that computes the inverse error function ofinput?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a function that provides greater precision than exp(x) - 1 for small values of x?": {
        "answer": "Computes the exponential of the elements minus 1 ofinput",
        "question": "What is an example of a function that provides greater precision than exp(x) - 1 for small values of x?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what error function ofinput?": {
        "answer": "inverse error function",
        "question": "Computes what error function ofinput?",
        "context": "Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the complementary error function of input defined as?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "What is the complementary error function of input defined as?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the inverse error function defined as?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "What is the inverse error function defined as?",
        "context": "Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes what for each element of input?": {
        "answer": "the exponentially scaled zeroth order modified Bessel function",
        "question": "Computes what for each element of input?",
        "context": "Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked": {
        "answer": "Python Functions and Modules",
        "question": "What Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked",
        "context": "Creating TorchScript Code Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a script that will be optimized using?": {
        "answer": "just-in-time compilation",
        "question": "What is a script that will be optimized using?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When is it first called during tracing?": {
        "answer": "Compilesfn",
        "question": "When is it first called during tracing?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a scriptModule that will be optimized using?": {
        "answer": "just-in-time compilation",
        "question": "What is a scriptModule that will be optimized using?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a wrapper around for atorch.jit.Future[T]asynchronous tasks?": {
        "answer": "C++torch::jit::Module",
        "question": "What is a wrapper around for atorch.jit.Future[T]asynchronous tasks?",
        "context": "Creating TorchScript Code Mixing Tracing and Scripting TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tra": {
        "answer": "Python",
        "question": "Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tra",
        "context": "TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Any TorchScript program can be saved from a Python process and loaded in a process where there is no what?": {
        "answer": "Python dependency",
        "question": "Any TorchScript program can be saved from a Python process and loaded in a process where there is no what?",
        "context": "Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Python programs may be disadvantageous for what reasons?": {
        "answer": "performance and multi-threading reasons",
        "question": "Python programs may be disadvantageous for what reasons?",
        "context": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript is a way to create serializable and optimizable models from PyTorch code.": {
        "answer": "TorchScript",
        "question": "TorchScript is a way to create serializable and optimizable models from PyTorch code.",
        "context": "TorchScript Language Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to compile TorchScript code?": {
        "answer": "TorchScript compiler",
        "question": "What is used to compile TorchScript code?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to optimize a script?": {
        "answer": "just-in-time compilation",
        "question": "What is used to optimize a script?",
        "context": "Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When it is first called during tracing?": {
        "answer": "Compilesfn",
        "question": "When it is first called during tracing?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an executableScriptModule that will be optimized using?": {
        "answer": "just-in-time compilation",
        "question": "What is an executableScriptModule that will be optimized using?",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a wrapper around C++torch::jit::Module?": {
        "answer": "wrapper around C++torch::jit::Module",
        "question": "What is a wrapper around C++torch::jit::Module?",
        "context": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a Wrapper around C++torch::jit::Module?": {
        "answer": "represents a single function and does not have any attributes or Parameters",
        "question": "What is a Wrapper around C++torch::jit::Module?",
        "context": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a gentle introduction to?": {
        "answer": "TorchScript",
        "question": "What is a gentle introduction to?",
        "context": "Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When it is first called during tracing, what does Compilesfn do?": {
        "answer": "Compilesfn",
        "question": "When it is first called during tracing, what does Compilesfn do?",
        "context": "Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is created by the asynchronous task executingfuncand a reference to the value of the result of this execution?": {
        "answer": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution",
        "question": "What is created by the asynchronous task executingfuncand a reference to the value of the result of this execution?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the wrapper around C++torch::jit::Module?": {
        "answer": "Functionally equivalent to aScriptModule",
        "question": "What is the wrapper around C++torch::jit::Module?",
        "context": "Built-in Functions and Modules PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the benefit of using TorchScript?": {
        "answer": "Any TorchScript program can be saved from a Python process and loaded in a process where there is no Python dependency",
        "question": "What is the benefit of using TorchScript?",
        "context": "PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a TorchScript program that can be run independently from Python?": {
        "answer": "a standalone C++ program",
        "question": "What is an example of a TorchScript program that can be run independently from Python?",
        "context": "PyTorch Functions and Modules Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is functionally equivalent to aScriptModule?": {
        "answer": "represents a single function and does not have any attributes or Parameters",
        "question": "What is functionally equivalent to aScriptModule?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Python Functions and Modules Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently As": {
        "answer": "Python Language Reference Comparison",
        "question": "Python Functions and Modules Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently As",
        "context": "Python Functions and Modules Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where can a TorchScript program be run independently from Python?": {
        "answer": "a standalone C++ program",
        "question": "Where can a TorchScript program be run independently from Python?",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix": {
        "answer": "Python Language Reference Comparison Debugging",
        "question": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix",
        "context": "Python Language Reference Comparison Debugging Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "A wrapper around what. Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or": {
        "answer": "C++torch::jit::Module",
        "question": "A wrapper around what. Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or",
        "context": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does JIT do for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Append": {
        "answer": "Disable JIT",
        "question": "What does JIT do for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Append",
        "context": "Disable JIT for Debugging Inspecting Code Interpreting Graphs Tracer Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What action does TorchScript perform?": {
        "answer": "Forces completion of atorch.jit.Future[T]asynchronous task",
        "question": "What action does TorchScript perform?",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Freezing aScriptModulewill what?": {
        "answer": "clone it",
        "question": "Freezing aScriptModulewill what?",
        "context": "Frequently Asked Questions Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create": {
        "answer": "Known Issues",
        "question": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create",
        "context": "Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is saved an offline version of aScriptModule?": {
        "answer": "Save an offline version",
        "question": "What is saved an offline version of aScriptModule?",
        "context": "Known Issues Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Any TorchScript program can be saved from a what process?": {
        "answer": "Python",
        "question": "Any TorchScript program can be saved from a what process?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you do to save an offline version of this module?": {
        "answer": "Save an offline version of this module",
        "question": "What can you do to save an offline version of this module?",
        "context": "Appendix Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will be used to optimize a script?": {
        "answer": "just-in-time compilation",
        "question": "What will be used to optimize a script?",
        "context": "Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What version of the module can be saved for use in the TorchScript IR Graph?": {
        "answer": "offline",
        "question": "What version of the module can be saved for use in the TorchScript IR Graph?",
        "context": "Migrating to PyTorch 1.2 Recursive Scripting API References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Freezing aScriptModulewill clone it and attempt to inline what as constants in the TorchScript IR ": {
        "answer": "attempt to inline the cloned module\u2019s submodules, parameters, and attributes",
        "question": "Freezing aScriptModulewill clone it and attempt to inline what as constants in the TorchScript IR ",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What version of the module can be saved for use in a separate process?": {
        "answer": "offline",
        "question": "What version of the module can be saved for use in a separate process?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does aScriptModule do?": {
        "answer": "Load aScriptModuleorScriptFunction",
        "question": "What does aScriptModule do?",
        "context": "References TorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency. We provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons. For a gentle introduction to TorchScript, see theIntroduction to TorchScripttutorial. For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Scripting a function ornn.Module compile as using the TorchScript compiler?": {
        "answer": "TorchScript code",
        "question": "What does Scripting a function ornn.Module compile as using the TorchScript compiler?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What function is called when it is first called during tracing?": {
        "answer": "Compilesfn",
        "question": "What function is called when it is first called during tracing?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the method that provides for conatiner type refinement in TorchScript?": {
        "answer": "a pass-through function that returnsvalue",
        "question": "What is the name of the method that provides for conatiner type refinement in TorchScript?",
        "context": "For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see theLoading a PyTorch Model in C++tutorial.   Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does asynchronous task executingfuncand a reference to the value of the result of this execution do?": {
        "answer": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution",
        "question": "What does asynchronous task executingfuncand a reference to the value of the result of this execution do?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the TorchScript method that indicates to the compiler that the left-hand expression is a class instance attribute with type oftype?": {
        "answer": "a pass-through function that returnsvalue",
        "question": "What is the TorchScript method that indicates to the compiler that the left-hand expression is a class instance attribute with type oftype?",
        "context": "  Scripting a function ornn.Modulewill inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return aScriptModuleorScriptFunction.   Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a pass-through function that indicates to the TorchScript compiler that the left-hand side expression is a class instance attribute with type": {
        "answer": "returnsthe_value",
        "question": "What is a pass-through function that indicates to the TorchScript compiler that the left-hand side expression is a class instance attribute with type",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used when it is first called during tracing?": {
        "answer": "Compilesfn",
        "question": "What is used when it is first called during tracing?",
        "context": "Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Trace a module and return an executableScriptModule that will be optimized using just-in-time compilation?": {
        "answer": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution",
        "question": "What does Trace a module and return an executableScriptModule that will be optimized using just-in-time compilation?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the difference between C++torch::jit::Module and aScriptModule?": {
        "answer": "represents a single function and does not have any attributes or Parameters",
        "question": "What is the difference between C++torch::jit::Module and aScriptModule?",
        "context": "Trace a function and return an executable  orScriptFunctionthat will be optimized using just-in-time compilation.   Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does tracing create?": {
        "answer": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution",
        "question": "What does tracing create?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of version of a script module can you save for use in a separate process?": {
        "answer": "offline",
        "question": "What type of version of a script module can you save for use in a separate process?",
        "context": "Compilesfnwhen it is first called during tracing.   Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When are traced functions particularly useful?": {
        "answer": "when you need to use control-flow around a simple feed-forward model",
        "question": "When are traced functions particularly useful?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a scripted function that can call an encoder module generated using tracing?": {
        "answer": "a traced function in script",
        "question": "What is an example of a scripted function that can call an encoder module generated using tracing?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What type of version of a module can you save for use in a separate process?": {
        "answer": "offline",
        "question": "What type of version of a module can you save for use in a separate process?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The beam search of a sequence to sequence model will typically be written in script but can call what?": {
        "answer": "an encoder module generated using tracing",
        "question": "The beam search of a sequence to sequence model will typically be written in script but can call what?",
        "context": "Trace a module and return an executableScriptModulethat will be optimized using just-in-time compilation.   Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does C++torch::jit::Module have in common with aScriptModule?": {
        "answer": "represents a single function and does not have any attributes or Parameters",
        "question": "What does C++torch::jit::Module have in common with aScriptModule?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing and scripting can be composed to what?": {
        "answer": "suit the particular requirements of a part of a model",
        "question": "Tracing and scripting can be composed to what?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Scripted functions can call what?": {
        "answer": "traced functions",
        "question": "Scripted functions can call what?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to generate an encoder module?": {
        "answer": "tracing",
        "question": "What is used to generate an encoder module?",
        "context": "Creates an asynchronous task executingfuncand a reference to the value of the result of this execution.   Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the difference between aScriptModule and C++torch::jit::Module?": {
        "answer": "represents a single function and does not have any attributes or Parameters",
        "question": "What is the difference between aScriptModule and C++torch::jit::Module?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can a traced function do?": {
        "answer": "can call an encoder module generated using tracing",
        "question": "What can a traced function do?",
        "context": "Forces completion of atorch.jit.Future[T]asynchronous task, returning the result of the task.   A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a pass-through function that indicates to the TorchScript compiler the type of the_value?": {
        "answer": "returnsthe_value",
        "question": "What is a pass-through function that indicates to the TorchScript compiler the type of the_value?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can a traced function call?": {
        "answer": "can call an encoder module generated using tracing",
        "question": "What can a traced function call?",
        "context": "  A wrapper around C++torch::jit::Module.   Functionally equivalent to aScriptModule, but represents a single function and does not have any attributes or Parameters.   Freezing aScriptModulewill clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph.   Save an offline version of this module for use in a separate process.   Load aScriptModuleorScriptFunctionpreviously saved withtorch.jit.save   This decorator indicates to the compiler that a function or method should be ignored and left as a Python function.   This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception.   This function provides for conatiner type refinement in TorchScript.   This method is a pass-through function that returnsvalue, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type oftype.   This method is a pass-through function that returnsthe_value, used to hint TorchScript compiler the type ofthe_value. In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can an encoder module be generated using?": {
        "answer": "tracing",
        "question": "What can an encoder module be generated using?",
        "context": "In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model. Scripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing. Example (calling a traced function in script): Traced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly. Example (calling a script function in a traced function): This composition also works fornn.Modules as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module. Example (using a traced module): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Debugging withpdbworks except for what?": {
        "answer": "when we invoke the@torch.jit.scriptfunction",
        "question": "Debugging withpdbworks except for what?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "How can we disable JIT?": {
        "answer": "globally disable JIT",
        "question": "How can we disable JIT?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript provide a code pretty-printer for allScriptModuleinstances?": {
        "answer": "Python syntax",
        "question": "What does TorchScript provide a code pretty-printer for allScriptModuleinstances?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What will you need to access.codeon if theScriptModulehas more than one method?": {
        "answer": "the module",
        "question": "What will you need to access.codeon if theScriptModulehas more than one method?",
        "context": "Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so: and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the output produced by the example above?": {
        "answer": "TorchScript\u2019s compilation of the code for theforwardmethod",
        "question": "What is the output produced by the example above?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript has a representation at a lower level than the code pretty- printer, in the form of what?": {
        "answer": "IR graphs",
        "question": "TorchScript has a representation at a lower level than the code pretty- printer, in the form of what?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is a static single assignment?": {
        "answer": "SSA",
        "question": "What is a static single assignment?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the name of the C++ backend of PyTorch?": {
        "answer": "ATen",
        "question": "What is the name of the C++ backend of PyTorch?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "The graph follows the same rules described in what section?": {
        "answer": "Inspecting Codesection",
        "question": "The graph follows the same rules described in what section?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "We will be able to step into the@torch.jit.scriptfunction as what?": {
        "answer": "normal Python function",
        "question": "We will be able to step into the@torch.jit.scriptfunction as what?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the code pretty-printer give an interpretation of the script method\u2019s code as valid?": {
        "answer": "Python syntax",
        "question": "What does the code pretty-printer give an interpretation of the script method\u2019s code as valid?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If theScriptModulehas more than one method, you will need to what?": {
        "answer": "access.codeon the method itself and not the module",
        "question": "If theScriptModulehas more than one method, you will need to what?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript's static single assignment?": {
        "answer": "SSA",
        "question": "What is TorchScript's static single assignment?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What document describes the rules for forwardmethod lookup?": {
        "answer": "theInspecting Codesection",
        "question": "What document describes the rules for forwardmethod lookup?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the schema for?": {
        "answer": "built-in functions likeaten",
        "question": "What is the schema for?",
        "context": "and we will be able to step into the@torch.jit.scriptfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see@torch.jit.ignore. TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What language does TorchScript provide a code pretty-printer for allScriptModuleinstances?": {
        "answer": "Python syntax",
        "question": "What language does TorchScript provide a code pretty-printer for allScriptModuleinstances?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What produces this output?": {
        "answer": "The example above",
        "question": "What produces this output?",
        "context": "TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example: AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is the output of the example above?": {
        "answer": "TorchScript\u2019s compilation of the code for theforwardmethod",
        "question": "What is the output of the example above?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you use this output for?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "What can you use this output for?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where are these associatedblocks found?": {
        "answer": "In the graph print-out",
        "question": "Where are these associatedblocks found?",
        "context": "AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output: This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can you use TorchScript\u2019s compilation of the code for theforwardmethod?": {
        "answer": "to ensure TorchScript (tracing or scripting) has captured your model code correctly",
        "question": "What can you use TorchScript\u2019s compilation of the code for theforwardmethod?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Why are operators formatted in the graph print-out?": {
        "answer": "to reflect their equivalent source code forms to facilitate easy debugging",
        "question": "Why are operators formatted in the graph print-out?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is dependent on the underlying code?": {
        "answer": "Tracing of control flow",
        "question": "What is dependent on the underlying code?",
        "context": "This is TorchScript\u2019s compilation of the code for theforwardmethod.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly. TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript follows the same rules described in theInspecting Codesection with regard to what?": {
        "answer": "forwardmethod lookup",
        "question": "TorchScript follows the same rules described in theInspecting Codesection with regard to what?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g. what?": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g. what?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does TorchScript use to assign the output to a (unique) value namedrv.1?": {
        "answer": "%rv.1:Tensormeans",
        "question": "What does TorchScript use to assign the output to a (unique) value namedrv.1?",
        "context": "TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What are some cases where the trace of a given Python function/module will not be representative of the underlying code?": {
        "answer": "edge cases",
        "question": "What are some cases where the trace of a given Python function/module will not be representative of the underlying code?",
        "context": "TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations": {
        "answer": "edge cases",
        "question": "Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Tracing of in-place operations of tensor views (e.g., what on the left-hand side of an assignment)": {
        "answer": "indexing",
        "question": "Tracing of in-place operations of tensor views (e.g., what on the left-hand side of an assignment)",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this message indicate to us that the computation differed between when we first traced it and when we traced it with traced?": {
        "answer": "diagnostic information",
        "question": "What does this message indicate to us that the computation differed between when we first traced it and when we traced it with traced?",
        "context": "Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Where is the location in the original source file that generated this instruction?": {
        "answer": "on line 9, and at character 10",
        "question": "Where is the location in the original source file that generated this instruction?",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does this message indicate to us that the computation differed between when we first traced it and when we traced it with thecheck_in": {
        "answer": "diagnostic information",
        "question": "What does this message indicate to us that the computation differed between when we first traced it and when we traced it with thecheck_in",
        "context": "%rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What section describes the rules for forwardmethod lookup?": {
        "answer": "theInspecting Codesection",
        "question": "What section describes the rules for forwardmethod lookup?",
        "context": "TorchScript also has a representation at a lower level than the code pretty-\nprinter, in the form of IR graphs. TorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example: graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup. The example script above produces the graph: Take the instruction%rv.1:Tensor=aten::zeros(%4,%6,%6,%10,%12)#test.py:9:10for\nexample. %rv.1:Tensormeans we assign the output to a (unique) value namedrv.1, that value is ofTensortype and that we do not know its concrete shape. aten::zerosis the operator (equivalent totorch.zeros) and the input list(%4,%6,%6,%10,%12)specifies which values in scope should be passed as inputs. The schema for built-in functions likeaten::zeroscan be found atBuiltin Functions. #test.py:9:10is the location in the original source file that generated this instruction. In this case, it is a file namedtest.py, on line 9, and at character 10. Notice that operators can also have associatedblocks, namely theprim::Loopandprim::Ifoperators. In the graph print-out, these\noperators are formatted to reflect their equivalent source code forms\nto facilitate easy debugging. Graphs can be inspected as shown to confirm that the computation described\nby aScriptModuleis correct, in both automated and manual fashion, as\ndescribed below. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the tracer produce?": {
        "answer": "The tracer produces warnings for several problematic patterns in traced computation",
        "question": "What does the tracer produce?",
        "context": "There are some edge cases that exist where the trace of a given Python\nfunction/module will not be representative of the underlying code. These\ncases can include: Tracing of control flow that is dependent on inputs (e.g. tensor shapes) Tracing of in-place operations of tensor views (e.g. indexing on the left-hand side of an assignment) Note that these cases may in fact be traceable in the future. One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example: Gives us the following diagnostic information: This message indicates to us that the computation differed between when\nwe first traced it and when we traced it with thecheck_inputs. Indeed,\nthe loop within the body ofloop_in_traced_fndepends on the shape\nof the inputx, and thus when we try anotherxwith a different\nshape, the trace differs. In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead: Which produces: The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor: Produces several warnings and a graph which simply returns the input: We can fix this by modifying the code to not use the in-place update, but\nrather build up the result tensor out-of-place withtorch.cat: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Which version of TorchScript does this section detail the changes to TorchScript in?": {
        "answer": "PyTorch 1.2",
        "question": "Which version of TorchScript does this section detail the changes to TorchScript in?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If you are new to TorchScript you can do what?": {
        "answer": "skip this section",
        "question": "If you are new to TorchScript you can do what?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does Torch.jit.script now do?": {
        "answer": "attempt to recursively compile functions, methods, and classes",
        "question": "What does Torch.jit.script now do?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule?": {
        "answer": "2.torch.jit.script(nn_module_instance)",
        "question": "What is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Methods called fromforwardare what in the order they are used inforward?": {
        "answer": "lazily compiled",
        "question": "Methods called fromforwardare what in the order they are used inforward?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To compile a method other thanforwardthat is not called fromforward, what is done?": {
        "answer": "add@torch.jit.export",
        "question": "To compile a method other thanforwardthat is not called fromforward, what is done?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To stop the compiler from what, add@torch.jit.ignoreor@torch.jit.unused. @ignor": {
        "answer": "compiling a method",
        "question": "To stop the compiler from what, add@torch.jit.ignoreor@torch.jit.unused. @ignor",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @ignoreleaves the method as a call to python?": {
        "answer": "@ignoreleaves the method as a call to python",
        "question": "What does @ignoreleaves the method as a call to python?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "@ignoredcannot be exported;@unusedcan?": {
        "answer": "@ignoredcannot be exported;@unusedcan",
        "question": "@ignoredcannot be exported;@unusedcan?",
        "context": "This section details the changes to TorchScript in PyTorch 1.2. If you are new to TorchScript you can\nskip this section. There are two main changes to the TorchScript API with PyTorch 1.2. 1.torch.jit.scriptwill now attempt to recursively compile functions,\nmethods, and classes that it encounters. Once you calltorch.jit.script,\ncompilation is \u201copt-out\u201d, rather than \u201copt-in\u201d. 2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Annotate their types usingPEP 526-styleclass annotations.": {
        "answer": "empty container types",
        "question": "Annotate their types usingPEP 526-styleclass annotations.",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is now the preferred way to createScriptModules?": {
        "answer": "2.torch.jit.script(nn_module_instance)",
        "question": "What is now the preferred way to createScriptModules?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Methods called fromforwardare what?": {
        "answer": "lazily compiled",
        "question": "Methods called fromforwardare what?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Add@torch.jit.ignoreor@torch.jit.unused. @ignoreleaves the method as a": {
        "answer": "compiling a method",
        "question": "Add@torch.jit.ignoreor@torch.jit.unused. @ignoreleaves the method as a",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "For empty container types, what should empty container types do?": {
        "answer": "annotate their types usingPEP 526-styleclass annotations",
        "question": "For empty container types, what should empty container types do?",
        "context": "2.torch.jit.script(nn_module_instance)is now the preferred way to createScriptModules, instead of inheriting fromtorch.jit.ScriptModule.\nThese changes combine to provide a simpler, easier-to-use API for converting\nyournn.Modules intoScriptModules, ready to be optimized and executed in a\nnon-Python environment. The new usage looks like this: The module\u2019sforwardis compiled by default. Methods called fromforwardare lazily compiled in the order they are used inforward. To compile a method other thanforwardthat is not called fromforward, add@torch.jit.export. To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Before PyTorch 1.2 what decorator was used to make a function or method callable from code that is exported?": {
        "answer": "@ignore",
        "question": "Before PyTorch 1.2 what decorator was used to make a function or method callable from code that is exported?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What did PyTorch 1.2 use to get the @ignore decorator back?": {
        "answer": "use@torch.jit.unused()",
        "question": "What did PyTorch 1.2 use to get the @ignore decorator back?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To stop the compiler from compiling a method, add what?": {
        "answer": "@torch.jit.ignoreor@torch.jit.unused",
        "question": "To stop the compiler from compiling a method, add what?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What eleaves the method as a call to python?": {
        "answer": "@ignor",
        "question": "What eleaves the method as a call to python?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What can empty container types do?": {
        "answer": "annotate their types",
        "question": "What can empty container types do?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "See@torch.jit.ignoreand@torch.jit.unusedfor what?": {
        "answer": "details",
        "question": "See@torch.jit.ignoreand@torch.jit.unusedfor what?",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What compiler compiles the module?": {
        "answer": "TorchScript",
        "question": "What compiler compiles the module?",
        "context": "To stop the compiler from compiling a method, add@torch.jit.ignoreor@torch.jit.unused.@ignoreleaves the method as a call to python, and@unusedreplaces it with an exception.@ignoredcannot be exported;@unusedcan. Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is compiled in the order they are used inforward?": {
        "answer": "@torch.jit.exportmethods",
        "question": "What is compiled in the order they are used inforward?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used as an entry point into aScriptModuleand should be compiled?": {
        "answer": "annn.Module",
        "question": "What is used as an entry point into aScriptModuleand should be compiled?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a function that does not need a decorator?": {
        "answer": "@torch.jit.exporton a method",
        "question": "What is an example of a function that does not need a decorator?",
        "context": "Most attribute types can be inferred, sotorch.jit.Attributeis not necessary. For empty container types, annotate their types usingPEP 526-styleclass annotations. Constants can be marked with aFinalclass annotation instead of adding the name of the member to__constants__. Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To get this functionality back, what did PyTorch 1.2 use to get it back?": {
        "answer": "use@torch.jit.unused()",
        "question": "To get this functionality back, what did PyTorch 1.2 use to get it back?",
        "context": "Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used as an entry point into aScriptModule and should be compiled?": {
        "answer": "annn.Module",
        "question": "What is used as an entry point into aScriptModule and should be compiled?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a Python 3 type hints?": {
        "answer": "@torch.jit.exporton a method",
        "question": "What is an example of a Python 3 type hints?",
        "context": "Python 3 type hints can be used in place oftorch.jit.annotate The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "TorchScript class support is what?": {
        "answer": "experimental",
        "question": "TorchScript class support is what?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Warning TorchScript class support is experimental. Currently it is best suited for what?": {
        "answer": "simple record-like types",
        "question": "Warning TorchScript class support is experimental. Currently it is best suited for what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Everything in a user definedTorchScript Classis exported what way?": {
        "answer": "by default",
        "question": "Everything in a user definedTorchScript Classis exported what way?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "When does the @torch.jit.ignoreannotation\u2019s behavior change?": {
        "answer": "PyTorch 1.2",
        "question": "When does the @torch.jit.ignoreannotation\u2019s behavior change?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "To get this functionality back, use what?": {
        "answer": "@torch.jit.unused()",
        "question": "To get this functionality back, use what?",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Functions don\u2019t change much, they can be decorated with what?": {
        "answer": "@torch.jit.ignoreortorch.jit.unusedif needed",
        "question": "Functions don\u2019t change much, they can be decorated with what?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is TorchScript class support best suited for?": {
        "answer": "simple record-like types",
        "question": "What is TorchScript class support best suited for?",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does the TorchScript compiler need to know the types ofmodule attributes?": {
        "answer": "Most types",
        "question": "What does the TorchScript compiler need to know the types ofmodule attributes?",
        "context": "The@torch.jit.script_methoddecorator Classes that inherit fromtorch.jit.ScriptModule Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What decorator was used to make a function or method callable from code that is exported?": {
        "answer": "@ignore",
        "question": "What decorator was used to make a function or method callable from code that is exported?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What does @torch.jit.ignore and@torch.jit.unused provide?": {
        "answer": "details",
        "question": "What does @torch.jit.ignore and@torch.jit.unused provide?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What cannot have their types inferred from the value of the member?": {
        "answer": "Empty lists and dicts",
        "question": "What cannot have their types inferred from the value of the member?",
        "context": "Thetorch.jit.Attributewrapper class The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What cannot have their types inferred and must have their types annotated withPEP 526-styleclass?": {
        "answer": "Empty lists and dicts",
        "question": "What cannot have their types inferred and must have their types annotated withPEP 526-styleclass?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in what?": {
        "answer": "PyTorch 1.2",
        "question": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is used to get the @ignore functionality back?": {
        "answer": "@torch.jit.unused()",
        "question": "What is used to get the @ignore functionality back?",
        "context": "The__constants__array Thetorch.jit.annotatefunction Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "See@torch.jit.ignoreand@torch.jit.unused for what?": {
        "answer": "details",
        "question": "See@torch.jit.ignoreand@torch.jit.unused for what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Warning TorchScript class support is what?": {
        "answer": "experimental",
        "question": "Warning TorchScript class support is what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "If a type cannot be inferred and is what?": {
        "answer": "not explicitly annotated",
        "question": "If a type cannot be inferred and is what?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): Functions don\u2019t change much, they can be decorated with@torch.jit.ignoreortorch.jit.unusedif needed. Warning TorchScript class support is experimental. Currently it is best suited\nfor simple record-like types (think aNamedTuplewith methods\nattached). Everything in a user definedTorchScript Classis\nexported by default, functions can be decorated with@torch.jit.ignoreif needed. The TorchScript compiler needs to know the types ofmodule attributes. Most types\ncan be inferred from the value of the member. Empty lists and dicts cannot have their\ntypes inferred and must have their types annotated withPEP 526-styleclass annotations.\nIf a type cannot be inferred and is not explicitly annotated, it will not be added as an attribute\nto the resultingScriptModule Old API: New API: ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "What is an example of a method that does not need the @ignore decorator?": {
        "answer": "@torch.jit.exporton a method",
        "question": "What is an example of a method that does not need the @ignore decorator?",
        "context": "Warning The@torch.jit.ignoreannotation\u2019s behavior changes in\nPyTorch 1.2. Before PyTorch 1.2 the @ignore decorator was used to make a function\nor method callable from code that is exported. To get this functionality back,\nuse@torch.jit.unused().@torch.jit.ignoreis now equivalent\nto@torch.jit.ignore(drop=False). See@torch.jit.ignoreand@torch.jit.unusedfor details. When passed to thetorch.jit.scriptfunction, atorch.nn.Module\u2019s data is\ncopied to aScriptModuleand the TorchScript compiler compiles the module.\nThe module\u2019sforwardis compiled by default. Methods called fromforwardare\nlazily compiled in the order they are used inforward, as well as any@torch.jit.exportmethods. This decorator indicates that a method on annn.Moduleis used as an entry point into aScriptModuleand should be compiled. forwardimplicitly is assumed to be an entry point, so it does not need this decorator.\nFunctions and methods called fromforwardare compiled as they are seen\nby the compiler, so they do not need this decorator either. Example (using@torch.jit.exporton a method): ",
        "source": "https://pytorch.org/docs/stable/jit.html"
    },
    "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on what?": {
        "answer": "Einstein summation convention",
        "question": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on what?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What specifies the subscripts for each dimension of the inputoperandsin the same order as the dimensions?": {
        "answer": "Theequationstring",
        "question": "What specifies the subscripts for each dimension of the inputoperandsin the same order as the dimensions?",
        "context": "Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. Optionally, the output subscripts can be explicitly defined by adding an arrow (\u2018->\u2019) at the end of the equation\nfollowed by the subscripts for the output. For instance, the following equation computes the transpose of a\nmatrix multiplication: \u2018ij,jk->ki\u2019. The output subscripts must appear at least once for some input operand and\nat most once for the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the exception to the Einstein summation convention?": {
        "answer": "if a subscript is repeated for the same input operand",
        "question": "What is the exception to the Einstein summation convention?",
        "context": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation\nbased on the Einstein summation convention. Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them in a short-hand format based on what?": {
        "answer": "Einstein",
        "question": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them in a short-hand format based on what?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the summation subscript in Einsum astorch.einsum?": {
        "answer": "j",
        "question": "What is the summation subscript in Einsum astorch.einsum?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What is the exception to Einsum's broadcastable format?": {
        "answer": "if a subscript is repeated for the same input operand",
        "question": "What is the exception to Einsum's broadcastable format?",
        "context": "Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them\nin a short-hand format based on the Einstein summation convention, given byequation. The details of\nthis format are described below, but the general idea is to label every dimension of the inputoperandswith some subscript and define which subscripts are part of the output. The output is then computed by summing\nthe product of the elements of theoperandsalong the dimensions whose subscripts are not part of the\noutput. For example, matrix multiplication can be computed using einsum astorch.einsum(\u201cij,jk->ik\u201d, A, B).\nHere, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: Theequationstring specifies the subscripts (lower case letters[\u2018a\u2019, \u2018z\u2019]) for each dimension of\nthe inputoperandsin the same order as the dimensions, separating subcripts for each operand by a\ncomma (\u2018,\u2019), e.g.\u2018ij,jk\u2019specify subscripts for two 2D operands. The dimensions labeled with the same subscript\nmust be broadcastable, that is, their size must either match or be1. The exception is if a subscript is\nrepeated for the same input operand, in which case the dimensions labeled with this subscript for this operand\nmust match in size and the operand will be replaced by its diagonal along these dimensions. The subscripts that\nappear exactly once in theequationwill be part of the output, sorted in increasing alphabetical order.\nThe output is computed by multiplying the inputoperandselement-wise, with their dimensions aligned based\non the subscripts, and then summing out the dimensions whose subscripts are not part of the output. ",
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum"
    },
    "What does the PyTorchaudiopackage consist of?": {
        "answer": "Package Reference PyTorch Libraries",
        "question": "What does the PyTorchaudiopackage consist of?",
        "context": "This library is part of thePyTorchproject. PyTorch is an open source\nmachine learning framework. Features described in this documentation are classified by release status: Stable:These features will be maintained long-term and there should generally\nbe no major performance limitations or gaps in documentation.\nWe also expect to maintain backwards compatibility (although\nbreaking changes can happen and notice will be given one release ahead\nof time). Beta:Features are tagged as Beta because the API may change based on\nuser feedback, because the performance needs to improve, or because\ncoverage across operators is not yet complete. For Beta features, we are\ncommitting to seeing the feature through to the Stable classification.\nWe are not, however, committing to backwards compatibility. Prototype:These features are typically not available as part of\nbinary distributions like PyPI or Conda, except sometimes behind run-time\nflags, and are at an early stage for feedback and testing. Thetorchaudiopackage consists of I/O, popular datasets and common audio transformations. Package Reference PyTorch Libraries ",
        "source": "https://pytorch.org/audio/stable/index.html"
    },
    "Return the what value for the given nonlinearity function?": {
        "answer": "recommended gain value",
        "question": "Return the what value for the given nonlinearity function?",
        "context": "Return the recommended gain value for the given nonlinearity function.\nThe values are as follows: nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the recommended gain value for the given nonlinearity function?": {
        "answer": "nonlinearity gain",
        "question": "What is the recommended gain value for the given nonlinearity function?",
        "context": "Return the recommended gain value for the given nonlinearity function.\nThe values are as follows: nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is nonlinearity?": {
        "answer": "non-linear function",
        "question": "What is nonlinearity?",
        "context": "nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the Tensor mean?": {
        "answer": "the mean of the normal distribution std",
        "question": "What is the Tensor mean?",
        "context": "Return the recommended gain value for the given nonlinearity function.\nThe values are as follows: nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013": {
        "answer": "n-dimensionaltorch",
        "question": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013",
        "context": "Return the recommended gain value for the given nonlinearity function.\nThe values are as follows: nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is Linear / Identity 111 Conv1,2,3D 111 Sigmoid 111 Tanh 53frac": {
        "answer": "nonlinearity gain",
        "question": "What is Linear / Identity 111 Conv1,2,3D 111 Sigmoid 111 Tanh 53frac",
        "context": "nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the default gain forSELUsacrifices?": {
        "answer": "the normalisation effect",
        "question": "What is the default gain forSELUsacrifices?",
        "context": "nonlinearity gain Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is 111 Conv1,2,3D 111 Sigmoid 111 Tanh?": {
        "answer": "Linear / Identity",
        "question": "What is 111 Conv1,2,3D 111 Sigmoid 111 Tanh?",
        "context": "Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the name of the non-linear function?": {
        "answer": "nonlinearity",
        "question": "What is the name of the non-linear function?",
        "context": "Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the value to fill the tensor with Examples Fills the input Tensor with?": {
        "answer": "scalar value1",
        "question": "What is the value to fill the tensor with Examples Fills the input Tensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does Linear / Identity 111 Conv1,2,3,3D 111 Tanh 53frac5335": {
        "answer": "tensor",
        "question": "What does Linear / Identity 111 Conv1,2,3,3D 111 Tanh 53frac5335",
        "context": "Linear / Identity 111 Conv{1,2,3}D 111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is another name for 111 Sigmoid 111 Tanh?": {
        "answer": "111 Sigmoid 111 Tanh",
        "question": "What is another name for 111 Sigmoid 111 Tanh?",
        "context": "111 Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What effect does the default gain forSELUsacrifices have for more stable gradient flow in rectangular layers?": {
        "answer": "the normalisation effect",
        "question": "What effect does the default gain forSELUsacrifices have for more stable gradient flow in rectangular layers?",
        "context": "Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the": {
        "answer": "nonlinearity",
        "question": "What is the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does a Tensor Example Fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What does a Tensor Example Fill the input Tensor with?",
        "context": "111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is Sigmoid 111 Tanh?": {
        "answer": "Sigmoid 111 Tanh",
        "question": "What is Sigmoid 111 Tanh?",
        "context": "Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does a tensor fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What does a tensor fill the input Tensor with?",
        "context": "Sigmoid 111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What do Tensor Examples Fill?": {
        "answer": "2-dimensional input",
        "question": "What do Tensor Examples Fill?",
        "context": "111 Tanh 53\\frac{5}{3}35\u200b ReLU 2\\sqrt{2}2\u200b Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What should you do in order to implementSelf-Normalizing Neural Networks?": {
        "answer": "usenonlinearity='linear'instead ofnonlinearity='selu'",
        "question": "What should you do in order to implementSelf-Normalizing Neural Networks?",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does an n-dimensionaltorch.Tensor Examples Fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What value does an n-dimensionaltorch.Tensor Examples Fill the input Tensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does an n-dimensionaltorch.Tensor Examples Fill?": {
        "answer": "2-dimensional inputTensorwith the identity matrix",
        "question": "What does an n-dimensionaltorch.Tensor Examples Fill?",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What Preserves the identity of the inputs inLinearlayers?": {
        "answer": "Preserves the identity of the inputs inLinearlayers,",
        "question": "What Preserves the identity of the inputs inLinearlayers?",
        "context": "Leaky Relu 21+negative_slope2\\sqrt{\\frac{2}{1 + \\text{negative\\_slope}^2}}1+negative_slope22\u200b\u200b SELU 34\\frac{3}{4}43\u200b Warning In order to implementSelf-Normalizing Neural Networks,\nyou should usenonlinearity='linear'instead ofnonlinearity='selu'.\nThis gives the initial weights a variance of1/N,\nwhich is necessary to induce a stable fixed point in the forward pass.\nIn contrast, the default gain forSELUsacrifices the normalisation\neffect for more stable gradient flow in rectangular layers. nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does an n-dimensionaltorch.Tensor Example Fills the input Tensor with?": {
        "answer": "scalar value1",
        "question": "What value does an n-dimensionaltorch.Tensor Example Fills the input Tensor with?",
        "context": "nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the 2-dimensional inputTensor filled with?": {
        "answer": "identity matrix",
        "question": "What is the 2-dimensional inputTensor filled with?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Preserves the identity of the inputs inLinearlayers, where where as many inputs are preserved as possible?": {
        "answer": "as many inputs are preserved as possible",
        "question": "Preserves the identity of the inputs inLinearlayers, where where as many inputs are preserved as possible?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does the 3, 4, 5-dimensional inputTensorwith?": {
        "answer": "Dirac delta function",
        "question": "What does the 3, 4, 5-dimensional inputTensorwith?",
        "context": "nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Preserves the identity of the inputs in what?": {
        "answer": "Convolutionallayers",
        "question": "Preserves the identity of the inputs in what?",
        "context": "nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "In case of what, each group of channels preserves identity tensor\u2013a 3, 4, 5-dimensionaltorch.T": {
        "answer": "groups>1",
        "question": "In case of what, each group of channels preserves identity tensor\u2013a 3, 4, 5-dimensionaltorch.T",
        "context": "nonlinearity\u2013 the non-linear function (nn.functionalname) param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does param stand for?": {
        "answer": "optional parameter",
        "question": "What does param stand for?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What function does the tensor fill the 3, 4, 5-dimensional inputTensorwith?": {
        "answer": "Dirac delta function",
        "question": "What function does the tensor fill the 3, 4, 5-dimensional inputTensorwith?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Glorot, what is Glorot?": {
        "answer": "X",
        "question": "Glorot, what is Glorot?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Who is Glorot, X. & Ben?": {
        "answer": "& Ben",
        "question": "Who is Glorot, X. & Ben?",
        "context": "param\u2013 optional parameter for the non-linear function Examples Fills the input Tensor with values drawn from the uniform\ndistributionU(a,b)\\mathcal{U}(a, b)U(a,b). tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does tensor Examples Fill the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What value does tensor Examples Fill the input Tensor with?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does fills the 2-dimensional inputTensorwith?": {
        "answer": "identity matrix",
        "question": "What does fills the 2-dimensional inputTensorwith?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What function does the 3, 4, 5-dimensional inputTensor have?": {
        "answer": "Dirac delta function",
        "question": "What function does the 3, 4, 5-dimensional inputTensor have?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Who was the author of Understanding the difficulty of training deep feedforward neural networks?": {
        "answer": "Y.",
        "question": "Who was the author of Understanding the difficulty of training deep feedforward neural networks?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "How does Glorot describe the difficulty of training deep feedforward neural networks?": {
        "answer": "using a uniform distribution",
        "question": "How does Glorot describe the difficulty of training deep feedforward neural networks?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "a\u2013 what is the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal distribution?": {
        "answer": "the lower bound of the uniform distribution",
        "question": "a\u2013 what is the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal distribution?",
        "context": "a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What value does an n-dimensionaltorch.Tensor Examples Fills the input Tensor with?": {
        "answer": "scalar value0",
        "question": "What value does an n-dimensionaltorch.Tensor Examples Fills the input Tensor with?",
        "context": "a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Who is the author of Understanding the difficulty of training deep feedforward neural networks?": {
        "answer": "Bengio",
        "question": "Who is the author of Understanding the difficulty of training deep feedforward neural networks?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "How does Glorot describe training deep feedforward neural networks?": {
        "answer": "using a uniform distribution",
        "question": "How does Glorot describe training deep feedforward neural networks?",
        "context": "b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the term for a tensor?": {
        "answer": "tensor",
        "question": "What is the term for a tensor?",
        "context": "a\u2013 the lower bound of the uniform distribution b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What function does a 2-dimensionaltorch.Tensor Examples Fills the 3, 4, 5-dimensional inputTens": {
        "answer": "Dirac delta function",
        "question": "What function does a 2-dimensionaltorch.Tensor Examples Fills the 3, 4, 5-dimensional inputTens",
        "context": "b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is it called when a tensor has values sampled fromU(a,a)mathcalU(": {
        "answer": "Glorot initialization",
        "question": "What is it called when a tensor has values sampled fromU(a,a)mathcalU(",
        "context": "b\u2013 the upper bound of the uniform distribution Examples Fills the input Tensor with values drawn from the normal\ndistributionN(mean,std2)\\mathcal{N}(\\text{mean}, \\text{std}^2)N(mean,std2). tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "In case of groups>1, each group of channels preserves identity <sep>": {
        "answer": "In case of groups>1, each group of channels preserves identity",
        "question": "In case of groups>1, each group of channels preserves identity <sep>",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Who were Glorot, X. & Bengio, Y. (2010)?": {
        "answer": "& Bengio, Y.",
        "question": "Who were Glorot, X. & Bengio, Y. (2010)?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "In what year did Glorot, X. & Bengio, Y. begin training deep feedforward neural networks?": {
        "answer": "2010",
        "question": "In what year did Glorot, X. & Bengio, Y. begin training deep feedforward neural networks?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is another name for Glorot?": {
        "answer": "Glorot initialization",
        "question": "What is another name for Glorot?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is a Tensor gain?": {
        "answer": "an optional scaling factor",
        "question": "What is a Tensor gain?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "When was Glorot, X. & Bengio, Y. born?": {
        "answer": "2010",
        "question": "When was Glorot, X. & Bengio, Y. born?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the result of the resulting tensor?": {
        "answer": "The resulting tensor",
        "question": "What is the result of the resulting tensor?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor mean\u2013 the mean of the normal distribution std\u2013 the standard deviation of the normal distribution Examples Fills the input Tensor with the valueval\\text{val}val. tensor\u2013 an n-dimensionaltorch.Tensor val\u2013 the value to fill the tensor with Examples Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Fills the 3, 4, 5-dimensional inputTensorwith what function?": {
        "answer": "Dirac delta function",
        "question": "Fills the 3, 4, 5-dimensional inputTensorwith what function?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is another name for Glorot initialization?": {
        "answer": "Glorot initialization",
        "question": "What is another name for Glorot initialization?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is a tensor gain?": {
        "answer": "an optional scaling factor",
        "question": "What is a tensor gain?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "Glorot, X. & Bengio, Y. (2010), using what distribution?": {
        "answer": "normal distribution",
        "question": "Glorot, X. & Bengio, Y. (2010), using what distribution?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is an optional scaling factor in a tensor gain?": {
        "answer": "an optional scaling factor",
        "question": "What is an optional scaling factor in a tensor gain?",
        "context": "Fills the input Tensor with the scalar value1. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What does tensor fill the 2-dimensional inputTensorwith?": {
        "answer": "identity matrix",
        "question": "What does tensor fill the 2-dimensional inputTensorwith?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What function does tensor fill the 3, 4, 5-dimensional inputTensorwith?": {
        "answer": "Dirac delta function",
        "question": "What function does tensor fill the 3, 4, 5-dimensional inputTensorwith?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is the resulting tensor's values sampled fromN(0,std2)mathcalN(": {
        "answer": "Glorot initialization",
        "question": "What is the resulting tensor's values sampled fromN(0,std2)mathcalN(",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is an optional tensor gain?": {
        "answer": "scaling factor",
        "question": "What is an optional tensor gain?",
        "context": "tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the input Tensor with the scalar value0. tensor\u2013 an n-dimensionaltorch.Tensor Examples Fills the 2-dimensional inputTensorwith the identity\nmatrix. Preserves the identity of the inputs inLinearlayers, where as\nmany inputs are preserved as possible. tensor\u2013 a 2-dimensionaltorch.Tensor Examples Fills the {3, 4, 5}-dimensional inputTensorwith the Dirac\ndelta function. Preserves the identity of the inputs inConvolutionallayers, where as many input channels are preserved as possible. In case\nof groups>1, each group of channels preserves identity tensor\u2013 a {3, 4, 5}-dimensionaltorch.Tensor groups(optional) \u2013 number of groups in the conv layer (default: 1) Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a uniform\ndistribution. The resulting tensor will have values sampled fromU(\u2212a,a)\\mathcal{U}(-a, a)U(\u2212a,a)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inUnderstanding the difficulty of training deep feedforward\nneural networks- Glorot, X. & Bengio, Y. (2010), using a normal\ndistribution. The resulting tensor will have values sampled fromN(0,std2)\\mathcal{N}(0, \\text{std}^2)N(0,std2)where Also known as Glorot initialization. tensor\u2013 an n-dimensionaltorch.Tensor gain\u2013 an optional scaling factor Examples Fills the inputTensorwith values according to the method\ndescribed inDelving deep into rectifiers: Surpassing human-level\nperformance on ImageNet classification- He, K. et al. (2015), using a\nuniform distribution. The resulting tensor will have values sampled fromU(\u2212bound,bound)\\mathcal{U}(-\\text{bound}, \\text{bound})U(\u2212bound,bound)where Also known as He initialization. tensor\u2013 an n-dimensionaltorch.Tensor ",
        "source": "https://pytorch.org/docs/stable/nn.init.html"
    },
    "What is batch1(Tensor)?": {
        "answer": "first batch of matrices to be multiplied batch2(Tensor)",
        "question": "What is batch1(Tensor)?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What is an example of a batch matrix-matrix product?": {
        "answer": "Example",
        "question": "What is an example of a batch matrix-matrix product?",
        "context": "Performs a batch matrix-matrix product of matrices stored\ninbatch1andbatch2,\nwith a reduced add step (all matrix multiplications get accumulated\nalong the first dimension).inputis added to the final result. batch1andbatch2must be 3-D tensors each containing the\nsame number of matrices. Ifbatch1is a(b\u00d7n\u00d7m)(b \\times n \\times m)(b\u00d7n\u00d7m)tensor,batch2is a(b\u00d7m\u00d7p)(b \\times m \\times p)(b\u00d7m\u00d7p)tensor,inputmust bebroadcastablewith a(n\u00d7p)(n \\times p)(n\u00d7p)tensor\nandoutwill be a(n\u00d7p)(n \\times p)(n\u00d7p)tensor. Ifbetais 0, theninputwill be ignored, andnanandinfin\nit will not be propagated. For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers. This operator supportsTensorFloat32. batch1(Tensor) \u2013 the first batch of matrices to be multiplied batch2(Tensor) \u2013 the second batch of matrices to be multiplied beta(Number,optional) \u2013 multiplier forinput(\u03b2\\beta\u03b2) input(Tensor) \u2013 matrix to be added alpha(Number,optional) \u2013 multiplier forbatch1 @ batch2(\u03b1\\alpha\u03b1) out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm"
    },
    "What does this class wrap?": {
        "answer": "arbitraryoptim.Optimizer",
        "question": "What does this class wrap?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What happens after parameters are updated locally?": {
        "answer": "each rank will broadcast its parameters to all other peers",
        "question": "What happens after parameters are updated locally?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What kind of algorithm does ZeroRedundancyOptimizer use?": {
        "answer": "greedy",
        "question": "What kind of algorithm does ZeroRedundancyOptimizer use?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Each parameter belongs to what?": {
        "answer": "a single rank",
        "question": "Each parameter belongs to what?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the partition of each parameter at each rank?": {
        "answer": "arbitrary",
        "question": "What is the partition of each parameter at each rank?",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(tor": {
        "answer": "local optimizer",
        "question": "Params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(tor",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What group(ProcessGroup, optional) \u2013torch.distributedProcessGroup?": {
        "answer": "group(ProcessGroup, optional) \u2013torch.distributedProcessGroup",
        "question": "What group(ProcessGroup, optional) \u2013torch.distributedProcessGroup?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "When enabled, parameters will be packed into what?": {
        "answer": "larger buckets",
        "question": "When enabled, parameters will be packed into what?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "When disabled, each what will be communicated separately?": {
        "answer": "individual parameter",
        "question": "When disabled, each what will be communicated separately?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the default?": {
        "answer": "all trailing arguments will be forwarded to the given optimizer",
        "question": "What is the default?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "When can a param group be useful?": {
        "answer": "when fine tuning a pre-trained network",
        "question": "When can a param group be useful?",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many update the consolidated state_dict list?": {
        "answer": "one per rank",
        "question": "How many update the consolidated state_dict list?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Restore the global parameter groups. to(int) \u2013 the rank that receives the global states. (default: 0) <sep>": {
        "answer": "Restore the global parameter groups",
        "question": "Restore the global parameter groups. to(int) \u2013 the rank that receives the global states. (default: 0) <sep>",
        "context": "This class wraps an arbitraryoptim.Optimizerand shards its states across ranks in the group as described byZeRO. The optimizer instance in each rank is only responsible for\nupdating1/world_sizeparameters and hence only needs to keep1/world_sizeoptimizer states. After parameters are updated locally,\neach rank will broadcast its parameters to all other peers to keep all\nmodel replicas in the same state.ZeroRedundancyOptimizercan be used\nin conjunction withtorch.nn.parallel.DistributedDataparallelto\nreduce per-rank peak memory consumption. ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What uses a greedy algorithm to pack a number of parameters at each rank?": {
        "answer": "ZeroRedundancyOptimizer",
        "question": "What uses a greedy algorithm to pack a number of parameters at each rank?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the partition of the algorithm?": {
        "answer": "arbitrary",
        "question": "What is the partition of the algorithm?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the default behavior of ZeroRedundancyOptimizer?": {
        "answer": "all trailing arguments will be forwarded to the given optimizer",
        "question": "What is the default behavior of ZeroRedundancyOptimizer?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "When can adding a param group to theOptimizersparam_groups be useful?": {
        "answer": "when fine tuning a pre-trained network",
        "question": "When can adding a param group to theOptimizersparam_groups be useful?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "How many consolidated state_dict lists are updated per rank?": {
        "answer": "one per rank",
        "question": "How many consolidated state_dict lists are updated per rank?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "To(int) \u2013 the rank that receives the global states. (default: what?": {
        "answer": "0",
        "question": "To(int) \u2013 the rank that receives the global states. (default: what?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "state_dict(dict) \u2013 what state should be an object returned from a call tostate_dict() Gets this rank\u2019sstate": {
        "answer": "optimizer state",
        "question": "state_dict(dict) \u2013 what state should be an object returned from a call tostate_dict() Gets this rank\u2019sstate",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What should state_dict(dict) be?": {
        "answer": "an object returned from a call tostate_dict() Gets this rank\u2019sstate_dict",
        "question": "What should state_dict(dict) be?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is a list ofparam_groups?": {
        "answer": "a list ofparam_groups",
        "question": "What is a list ofparam_groups?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What corresponds to the param_groups for a rank?": {
        "answer": "Element 0",
        "question": "What corresponds to the param_groups for a rank?",
        "context": "ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order. params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is params(Iterable) \u2013 anIterableoftorch.Tensors?": {
        "answer": "optimizer",
        "question": "What is params(Iterable) \u2013 anIterableoftorch.Tensors?",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "When disabled, what happens to each individual parameter?": {
        "answer": "each individual parameter will be communicated separately",
        "question": "When disabled, what happens to each individual parameter?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Update the consolidated state_dict list, how many per rank?": {
        "answer": "one per rank",
        "question": "Update the consolidated state_dict list, how many per rank?",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Restore the global parameter groups as well as the what?": {
        "answer": "shard",
        "question": "Restore the global parameter groups as well as the what?",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "state_dict(dict) \u2013 what?": {
        "answer": "optimizer state",
        "question": "state_dict(dict) \u2013 what?",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "State_dict(dict) \u2013 optimizer state. Should be what?": {
        "answer": "an object returned from a call tostate_dict() Gets this rank\u2019sstate_dict",
        "question": "State_dict(dict) \u2013 optimizer state. Should be what?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Which element corresponds to rank 0, etc. We need all the ranks for the broadcast insidestep(). Returns the local_state_dict for ": {
        "answer": "Element 0",
        "question": "Which element corresponds to rank 0, etc. We need all the ranks for the broadcast insidestep(). Returns the local_state_dict for ",
        "context": "params(Iterable) \u2013 anIterableoftorch.Tensors optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "Returns what for a given rank?": {
        "answer": "local_state_dict",
        "question": "Returns what for a given rank?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What is the class of the local optimizer?": {
        "answer": "optimizer_class",
        "question": "What is the class of the local optimizer?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What should be optimized along with group specific optimization options?": {
        "answer": "Tensors",
        "question": "What should be optimized along with group specific optimization options?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What corresponds to rank 0, etc. We need all the ranks for the broadcast insidestep(). Returns the local_state_dict for a": {
        "answer": "Element 0",
        "question": "What corresponds to rank 0, etc. We need all the ranks for the broadcast insidestep(). Returns the local_state_dict for a",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "globalstate_dict is what?": {
        "answer": "last known global optimizer state",
        "question": "globalstate_dict is what?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What performs performs?": {
        "answer": "Performs",
        "question": "What performs performs?",
        "context": "optimizer_class(torch.nn.Optimizer) \u2013 the class of the local\noptimizer. group(ProcessGroup, optional) \u2013torch.distributedProcessGroup(default:group.WORLDinitialized bytorch.distributed.init_process_group()). parameters_as_bucket_views(bool) \u2013 when enabled, parameters will\nbe packed into larger buckets to speed up communication andparam.datafields will point to bucket views at different\noffsets. When disabled, each individual parameter will be\ncommunicated separately, butparams.datawill stay intact. **default\u2013 all trailing arguments will be forwarded to the given optimizer. Example: Add a param group to theOptimizersparam_groups. This can be useful when fine tuning a pre-trained network, as frozen\nlayers can be made trainable and added to theOptimizeras\ntraining progresses. param_group(dict) \u2013 Specifies what Tensors should be optimized\nalong with group specific optimization options. Update the consolidated state_dict list, one per rank. to(int) \u2013 the rank that receives the global states. (default: 0) Restore the global parameter groups as well as the shard. state_dict(dict) \u2013 optimizer state. Should be an object returned\nfrom a call tostate_dict() Gets this rank\u2019sstate_dict.  The state of the optimizer as adict.\nIt contains two entries: differs between optimizer classes. param_groups - a dict containing all parameter groups Partitions parameters across distributed data parallel ranks. a list ofparam_groups(which is a list of dict) where each\nelement of the list contains the param_groups for a rank. Element 0\ncorresponds to rank 0, etc. We need all the ranks for the broadcast\ninsidestep(). Returns the local_state_dict for a given rank. rank(int) \u2013 rank to getlocal_state_dictfor state_dict(dict) \u2013 globalstate_dict the last known global optimizer state, which consist of a list of\nthe shards. Performs a single optimization step (parameter update). closure(callable) \u2013 A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers. optional loss, depends on the underlying optimizer ",
        "source": "https://pytorch.org/docs/stable/distributed.optim.html"
    },
    "What package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors?": {
        "answer": "torch",
        "question": "What package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What counterpart does the torch package have?": {
        "answer": "CUDA",
        "question": "What counterpart does the torch package have?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what if theinputis a single element tensor?": {
        "answer": "True if theinputis a single element tensor",
        "question": "Returns what if theinputis a single element tensor?",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch package return?": {
        "answer": "total number of elements in theinputtensor",
        "question": "What does the torch package return?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch package construct?": {
        "answer": "a tensor withdata",
        "question": "What does the torch package construct?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the COO(rdinate) format contain?": {
        "answer": "specified values at the givenindices",
        "question": "What does the COO(rdinate) format contain?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the torch package do?": {
        "answer": "Create",
        "question": "What does the torch package do?",
        "context": "The torch package contains data structures for multi-dimensional\ntensors and defines mathematical operations over these tensors.\nAdditionally, it provides many utilities for efficient serializing of\nTensors and arbitrary types, and other useful utilities. It has a CUDA counterpart, that enables you to run your tensor computations\non an NVIDIA GPU with compute capability >= 3.0   Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Get the what?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "Get the what?",
        "context": "Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Random sampling creation ops are listed under Random samplingand include:torch.rand()torch.rand()torch.": {
        "answer": "Random sampling creation ops",
        "question": "Random sampling creation ops are listed under Random samplingand include:torch.rand()torch.rand()torch.",
        "context": "Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Constructs what?": {
        "answer": "a tensor withdata",
        "question": "Constructs what?",
        "context": "Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize?": {
        "answer": "a tensor filled with the scalar value0",
        "question": "What returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize?",
        "context": "Returns True ifobjis a PyTorch tensor.   Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Creation ops are listed under Random sampling and include:torch.rand()torch.rand()torch.rand": {
        "answer": "Random sampling",
        "question": "Creation ops are listed under Random sampling and include:torch.rand()torch.rand()torch.rand",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does a tensor in COO(rdinate) format contain?": {
        "answer": "specified values at the givenindices",
        "question": "What does a tensor in COO(rdinate) format contain?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize. Returns ": {
        "answer": "Returns a tensor",
        "question": "Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize. Returns ",
        "context": "Returns True ifobjis a PyTorch storage object.   Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with the shape defined by the variable argumentsize. Returns a tensor filled with what?": {
        "answer": "scalar value1",
        "question": "Returns a tensor filled with the shape defined by the variable argumentsize. Returns a tensor filled with what?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what?": {
        "answer": "random permutation of integers from0ton-1",
        "question": "Returns a what?",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Sets the default floating point dtype tod get?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What does Sets the default floating point dtype tod get?",
        "context": "Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what type of tensor of sizeendstartstepleftlceil fractextend": {
        "answer": "1-D tensor",
        "question": "Returns a what type of tensor of sizeendstartstepleftlceil fractextend",
        "context": "Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the current default floating pointtorch.dtype?": {
        "answer": "current default floating pointtorch.dtype",
        "question": "What is the current default floating pointtorch.dtype?",
        "context": "Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with what value1?": {
        "answer": "scalar",
        "question": "Returns a tensor filled with what value1?",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what type of tensor?": {
        "answer": "1-D tensor",
        "question": "Returns a what type of tensor?",
        "context": "Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what type of tensor of sizeendstartstep+1leftlfloor fractext": {
        "answer": "1-D tensor",
        "question": "Returns a what type of tensor of sizeendstartstep+1leftlfloor fractext",
        "context": "Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Creation ops are listed under Random sampling and include:torch.rand()torch.rand()torch.randin": {
        "answer": "Random sampling",
        "question": "Creation ops are listed under Random sampling and include:torch.rand()torch.rand()torch.randin",
        "context": "Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what tensor of sizeendstartstep+1leftlfloor fractextend -": {
        "answer": "1-D tensor",
        "question": "Returns what tensor of sizeendstartstep+1leftlfloor fractextend -",
        "context": "Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is returned?": {
        "answer": "tensor filled with the scalar value1",
        "question": "What type of tensor is returned?",
        "context": "Returns True if the data type ofinputis a complex data type i.e., one oftorch.complex64, andtorch.complex128.   Returns True if the data type ofinputis a floating point data type i.e., one oftorch.float64,torch.float32,torch.float16, andtorch.bfloat16.   Returns True if theinputis a single element tensor which is not equal to zero after type conversions.   Sets the default floating point dtype tod.   Get the current default floating pointtorch.dtype.   Sets the defaulttorch.Tensortype to floating point tensor typet.   Returns the total number of elements in theinputtensor.   Set options for printing.   Disables denormal floating numbers on CPU. Note Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is created of sizestepswhose values are evenly spaced fromstarttoend inclusive?": {
        "answer": "one-dimensional tensor",
        "question": "What is created of sizestepswhose values are evenly spaced fromstarttoend inclusive?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the Random sampling creation ops?": {
        "answer": "Create",
        "question": "What is the name of the Random sampling creation ops?",
        "context": "Random sampling creation ops are listed underRandom samplingand\ninclude:torch.rand()torch.rand_like()torch.randn()torch.randn_like()torch.randint()torch.randint_like()torch.randperm()You may also usetorch.empty()with theIn-place random samplingmethods to createtorch.Tensors with values sampled from a broader\nrange of distributions.   Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is constructed in COO(rdinate) format with specified values at the givenindices?": {
        "answer": "asparse tensor",
        "question": "What is constructed in COO(rdinate) format with specified values at the givenindices?",
        "context": "Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what size tensor of sizeendstartstep+1leftlfloor fractextend": {
        "answer": "1-D",
        "question": "Returns a what size tensor of sizeendstartstep+1leftlfloor fractextend",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive?": {
        "answer": "one-dimensional",
        "question": "What type of tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive?",
        "context": "Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor of sizestepswhose values are evenly spaced frombasestarttextbasetextstartbasestart": {
        "answer": "one-dimensional",
        "question": "What type of tensor of sizestepswhose values are evenly spaced frombasestarttextbasetextstartbasestart",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what tensor with ones on the diagonal and zeros elsewhere?": {
        "answer": "2-D",
        "question": "Returns a what tensor with ones on the diagonal and zeros elsewhere?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns an uninitialized tensor with what size asinput?": {
        "answer": "same size asinput",
        "question": "Returns an uninitialized tensor with what size asinput?",
        "context": "  Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute valueabsand angleangle.   Computes the Heaviside step function for each element ininput. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with uninitialized data. Returns an uninitialized tensor with the": {
        "answer": "Return",
        "question": "Returns a tensor filled with uninitialized data. Returns an uninitialized tensor with the",
        "context": "Constructs a tensor withdata.   Constructs asparse tensor in COO(rdinate) formatwith specified values at the givenindices.   Convert the data into atorch.Tensor.   Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the tensor of sizeendstartstep+1leftlfloor fractextend -": {
        "answer": "1-D",
        "question": "What is the tensor of sizeendstartstep+1leftlfloor fractextend -",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor of sizestepswhose values are evenly spaced fromstarttoend inclusive?": {
        "answer": "one-dimensional tensor",
        "question": "What type of tensor of sizestepswhose values are evenly spaced fromstarttoend inclusive?",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what tensor with ones on the diagonal and zeros elsewhere?": {
        "answer": "2-D tensor",
        "question": "Returns what tensor with ones on the diagonal and zeros elsewhere?",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns an uninitialized tensor with what size?": {
        "answer": "same size asinput",
        "question": "Returns an uninitialized tensor with what size?",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.": {
        "answer": "Con",
        "question": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.",
        "context": "Create a view of an existingtorch.Tensorinputwith specifiedsize,strideandstorage_offset.   Creates aTensorfrom anumpy.ndarray.   Returns a tensor filled with the scalar value0, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value0, with the same size asinput.   Returns a tensor filled with the scalar value1, with the shape defined by the variable argumentsize.   Returns a tensor filled with the scalar value1, with the same size asinput.   Returns a 1-D tensor of size\u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309with values from the interval[start,end)taken with common differencestepbeginning fromstart.   Returns a 1-D tensor of size\u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1with values fromstarttoendwith stepstep.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   Constructs a complex tensor with its real part equal torealand its imaginary part equal toimag.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Concatenates what in the given dimension?": {
        "answer": "given sequence ofseqtensors",
        "question": "Concatenates what in the given dimension?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splitsinput, a tensor with three or more dimensions, into what?": {
        "answer": "multiple tensors depthwise",
        "question": "Splitsinput, a tensor with three or more dimensions, into what?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Gathers values along an axis specified what?": {
        "answer": "bydim",
        "question": "Gathers values along an axis specified what?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splitsinput, a tensor with one or more dimensions, into what?": {
        "answer": "multiple tensors",
        "question": "Splitsinput, a tensor with one or more dimensions, into what?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Stack tensors in sequence what way (column wise)?": {
        "answer": "horizontally",
        "question": "Stack tensors in sequence what way (column wise)?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the index that returns a new tensor which indexes theinputtensor along dimensiondimusing": {
        "answer": "aLongTensor",
        "question": "What is the name of the index that returns a new tensor which indexes theinputtensor along dimensiondimusing",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the boolean maskmask that returns a new 1-D tensor which indexes theinputtensor": {
        "answer": "aBoolTensor",
        "question": "What is the boolean maskmask that returns a new 1-D tensor which indexes theinputtensor",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the new tensor that returns a new tensor that is?": {
        "answer": "a narrowed version ofinputtensor",
        "question": "What is the new tensor that returns a new tensor that is?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Concatenates what?": {
        "answer": "a sequence of tensors along a new dimension",
        "question": "Concatenates what?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.transpose() stand for?": {
        "answer": "Alias fortorch.transpose()",
        "question": "What does Alias fortorch.transpose() stand for?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Expectsinputto be = what?": {
        "answer": "2-D tens",
        "question": "Expectsinputto be = what?",
        "context": "Concatenates the given sequence ofseqtensors in the given dimension.   Splits a tensor into a specific number of chunks.   Splitsinput, a tensor with three or more dimensions, into multiple tensors depthwise according toindices_or_sections.   Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Creates a new tensor by doing what?": {
        "answer": "horizontally stacking the tensors intensors",
        "question": "Creates a new tensor by doing what?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens along an axis specified bydim?": {
        "answer": "Gathers values",
        "question": "What happens along an axis specified bydim?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.movedim() return a new tensor that is?": {
        "answer": "a narrowed version ofinputtensor",
        "question": "What does Alias fortorch.movedim() return a new tensor that is?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a tensor with the same data and number of elements asinput, but with the specified shape?": {
        "answer": "Alias oftorch.vstack()",
        "question": "What function returns a tensor with the same data and number of elements asinput, but with the specified shape?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens when a sequence of tensors is stacked along a new dimension?": {
        "answer": "Concatenates a sequence of tensors along a new dimension",
        "question": "What happens when a sequence of tensors is stacked along a new dimension?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are the elements ofinputat the given?": {
        "answer": "indices",
        "question": "What are the elements ofinputat the given?",
        "context": "Creates a new tensor by horizontally stacking the tensors intensors.   Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Selects values frominputat what?": {
        "answer": "1-dimensional indices",
        "question": "Selects values frominputat what?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where do Stack tensors stack in sequence?": {
        "answer": "depthwise",
        "question": "Where do Stack tensors stack in sequence?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Gathers values along what axis?": {
        "answer": "axis specified bydim",
        "question": "Gathers values along what axis?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Splitsinput into what horizontally according toindices_or_sections?": {
        "answer": "multiple tensors",
        "question": "Splitsinput into what horizontally according toindices_or_sections?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the index which indexes theinputtensor along dimensiondimusing the entries inindex?": {
        "answer": "aLongTensor",
        "question": "What is the name of the index which indexes theinputtensor along dimensiondimusing the entries inindex?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what with the elements ofinputat the given indices?": {
        "answer": "a new tensor",
        "question": "Returns what with the elements ofinputat the given indices?",
        "context": "  Stack tensors in sequence depthwise (along third axis).   Gathers values along an axis specified bydim.   Splitsinput, a tensor with one or more dimensions, into multiple tensors horizontally according toindices_or_sections.   Stack tensors in sequence horizontally (column wise).   Returns a new tensor which indexes theinputtensor along dimensiondimusing the entries inindexwhich is aLongTensor.   Returns a new 1-D tensor which indexes theinputtensor according to the boolean maskmaskwhich is aBoolTensor.   Moves the dimension(s) ofinputat the position(s) insourceto the position(s) indestination.   Alias fortorch.movedim().   Returns a new tensor that is a narrowed version ofinputtensor.      Returns a tensor with the same data and number of elements asinput, but with the specified shape.   Alias oftorch.vstack().   Out-of-place version oftorch.Tensor.scatter_()   Out-of-place version oftorch.Tensor.scatter_add_()   Splits the tensor into chunks.   Returns a tensor with all the dimensions ofinputof size1removed.   Concatenates a sequence of tensors along a new dimension.   Alias fortorch.transpose().   Alias fortorch.transpose().   Expectsinputto be <= 2-D tensor and transposes dimensions 0 and 1.   Returns a new tensor with the elements ofinputat the given indices.   Selects values frominputat the 1-dimensional indices fromindicesalong the givendim.   Splits a tensor into multiple sub-tensors, all of which are views ofinput, along dimensiondimaccording to the indices or number of sections specified byindices_or_sections.   Constructs a tensor by repeating the elements ofinput.   Returns a tensor that is a transposed version ofinput.   Removes a tensor dimension.   Returns a new tensor with a dimension of size one inserted at the specified position.   Splitsinput, a tensor with two or more dimensions, into multiple tensors vertically according toindices_or_sections.   Stack tensors in sequence vertically (row wise).   Return a tensor of elements selected from eitherxory, depending oncondition. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sets the seed for generating random numbers to what?": {
        "answer": "non-deterministic random number",
        "question": "Sets the seed for generating random numbers to what?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sets the seed for generating random numbers to a non-deterministic random number.": {
        "answer": "Sets the seed for generating random numbers",
        "question": "Sets the seed for generating random numbers to a non-deterministic random number.",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the initial seed for generating random numbers as what?": {
        "answer": "Pythonlong",
        "question": "Returns the initial seed for generating random numbers as what?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Draws binary random numbers (0 or 1) from a what distribution?": {
        "answer": "Bernoulli",
        "question": "Draws binary random numbers (0 or 1) from a what distribution?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row": {
        "answer": "a tensor",
        "question": "Returns what where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row",
        "context": "Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Random numbers drawn from separate normal distributions where mean and standard deviation are given?": {
        "answer": "whose mean and standard deviation are given",
        "question": "Random numbers drawn from separate normal distributions where mean and standard deviation are given?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "From what distribution is each element sampled?": {
        "answer": "Poisson distribution",
        "question": "From what distribution is each element sampled?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor filled with random integers generated uniformly what?": {
        "answer": "betweenlow(inclusive) andhigh(exclusive)",
        "question": "Returns a tensor filled with random integers generated uniformly what?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive": {
        "answer": "a tensor",
        "question": "What is returned with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Random numbers from a normal distribution with mean0and variance1 is also called what?": {
        "answer": "standard normal distribution",
        "question": "Random numbers from a normal distribution with mean0and variance1 is also called what?",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is filled with random numbers from a normal distribution with mean 0 and variance 1?": {
        "answer": "a tensor with the same size asinput",
        "question": "What is filled with random numbers from a normal distribution with mean 0 and variance 1?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a random permutation of integers from0ton-1?": {
        "answer": "random permutation of integers from0ton-1",
        "question": "What returns a random permutation of integers from0ton-1?",
        "context": "Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the in-place version of torch.Tensor.bernoulli_()?": {
        "answer": "torch.Tensor.bernoulli_()",
        "question": "What is the in-place version of torch.Tensor.bernoulli_()?",
        "context": "Sets the seed for generating random numbers to a non-deterministic random number.   Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns the initial seed for generating random numbers as a Pythonlong?": {
        "answer": "Sets the seed for generating random numbers",
        "question": "What is the name of the function that returns the initial seed for generating random numbers as a Pythonlong?",
        "context": "Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the initial seed for generating random numbers as a what?": {
        "answer": "Pythonlong",
        "question": "Returns the initial seed for generating random numbers as a what?",
        "context": "Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sets the seed for generating random numbers. Returns the random number generator state as atorch.ByteTensor.": {
        "answer": "random number generator state",
        "question": "Sets the seed for generating random numbers. Returns the random number generator state as atorch.ByteTensor.",
        "context": "Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of random numbers drawn from separate normal distributions what?": {
        "answer": "whose mean and standard deviation are given",
        "question": "Returns a tensor of random numbers drawn from separate normal distributions what?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean what?": {
        "answer": "0 and variance 1",
        "question": "Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean what?",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are the numbers drawn from the Cauchy distribution?": {
        "answer": "torch.Tensor.cauchy_()",
        "question": "What are the numbers drawn from the Cauchy distribution?",
        "context": "Sets the seed for generating random numbers.   Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor of random numbers drawn from separate normal distributions where mean and standard deviation are given?": {
        "answer": "whose mean and standard deviation are given",
        "question": "Returns a tensor of random numbers drawn from separate normal distributions where mean and standard deviation are given?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?": {
        "answer": "a tensor",
        "question": "What does Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)?",
        "context": "Returns the initial seed for generating random numbers as a Pythonlong.   Returns the random number generator state as atorch.ByteTensor.   Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the number drawn from the Cauchy distribution torch?": {
        "answer": "torch.Tensor.cauchy_()",
        "question": "What is the name of the number drawn from the Cauchy distribution torch?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sets what state?": {
        "answer": "random number generator state",
        "question": "Sets what state?",
        "context": "Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive)": {
        "answer": "a tensor",
        "question": "Returns what tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive)",
        "context": "Sets the random number generator state.   Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Each element sampled from a what distribution with rate parameter given by the corresponding element ininput?": {
        "answer": "Poisson",
        "question": "Each element sampled from a what distribution with rate parameter given by the corresponding element ininput?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a tensor filled with?": {
        "answer": "uninitialized data",
        "question": "What is a tensor filled with?",
        "context": "Creates a one-dimensional tensor of sizestepswhose values are evenly spaced fromstarttoend, inclusive.   Creates a one-dimensional tensor of sizestepswhose values are evenly spaced frombasestart{{\\text{{base}}}}^{{\\text{{start}}}}basestarttobaseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with basebase.   Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.   Returns a tensor filled with uninitialized data.   Returns an uninitialized tensor with the same size asinput.   Returns a tensor filled with uninitialized data.   Creates a tensor of sizesizefilled withfill_value.   Returns a tensor with the same size asinputfilled withfill_value.   Converts a float tensor to a quantized tensor with given scale and zero point.   Converts a float tensor to a per-channel quantized tensor with given scales and zero points.   Returns an fp32 Tensor by dequantizing a quantized Tensor   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a tensor filled with random numbers from a normal distribution with mean 0 and variance1?": {
        "answer": "random permutation of integers from0ton-1",
        "question": "What returns a tensor filled with random numbers from a normal distribution with mean 0 and variance1?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of ten": {
        "answer": "a tensor",
        "question": "Where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of ten",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a tensor with what shape as Tensorinput?": {
        "answer": "same shape",
        "question": "Returns a tensor with what shape as Tensorinput?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the in-place version of Torch.bernoulli() torch?": {
        "answer": "torch.Tensor.bernoulli_()",
        "question": "What is the name of the in-place version of Torch.bernoulli() torch?",
        "context": "Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Where is each element sampled from?": {
        "answer": "Poisson distribution",
        "question": "Where is each element sampled from?",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned if a tensor is filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)": {
        "answer": "a tensor",
        "question": "What is returned if a tensor is filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive)",
        "context": "  Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution torch.Tensor.uniform_()- numbers sampled from the continuous uniform distribution quasirandom.SobolEngine Thetorch.quasirandom.SobolEngineis an engine for generating (scrambled) Sobol sequences. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the in-place version of the Torch.bernoulli() torch?": {
        "answer": "torch.Tensor.bernoulli_()",
        "question": "What is the name of the in-place version of the Torch.bernoulli() torch?",
        "context": "Draws binary random numbers (0 or 1) from a Bernoulli distribution.   Returns a tensor where each row containsnum_samplesindices sampled from the multinomial probability distribution located in the corresponding row of tensorinput.   Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.   Returns a tensor of the same size asinputwith each element sampled from a Poisson distribution with rate parameter given by the corresponding element ininputi.e.,   Returns a tensor filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1)   Returns a tensor with the same size asinputthat is filled with random numbers from a uniform distribution on the interval[0,1)[0, 1)[0,1).   Returns a tensor filled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor with the same shape as Tensorinputfilled with random integers generated uniformly betweenlow(inclusive) andhigh(exclusive).   Returns a tensor filled with random numbers from a normal distribution with mean0and variance1(also called the standard normal distribution).   Returns a tensor with the same size asinputthat is filled with random numbers from a normal distribution with mean 0 and variance 1.   Returns a random permutation of integers from0ton-1. There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation: torch.Tensor.bernoulli_()- in-place version oftorch.bernoulli() torch.Tensor.cauchy_()- numbers drawn from the Cauchy distribution torch.Tensor.exponential_()- numbers drawn from the exponential distribution torch.Tensor.geometric_()- elements drawn from the geometric distribution torch.Tensor.log_normal_()- samples from the log-normal distribution torch.Tensor.normal_()- in-place version oftorch.normal() torch.Tensor.random_()- numbers sampled from the discrete uniform distribution ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what value of each element ininput?": {
        "answer": "absolute value",
        "question": "Computes the what value of each element ininput?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.abs() Computes the what cosine of each element ininput?": {
        "answer": "inverse",
        "question": "Alias fortorch.abs() Computes the what cosine of each element ininput?",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the cosine of the elements ofinput?": {
        "answer": "inverse hyperbolic",
        "question": "What is the cosine of the elements ofinput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Adds what to each element of the inputinputand returns a new resulting tensor?": {
        "answer": "scalarother",
        "question": "Adds what to each element of the inputinputand returns a new resulting tensor?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs the element-wise division what?": {
        "answer": "oftensor1bytensor2",
        "question": "Performs the element-wise division what?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what?": {
        "answer": "element-wise multiplication",
        "question": "Performs what?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the giveninputtensor's what?": {
        "answer": "element-wise angle",
        "question": "Computes the giveninputtensor's what?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.asinh() return a new tensor with?": {
        "answer": "arctangent",
        "question": "What does Alias fortorch.asinh() return a new tensor with?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Who returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?": {
        "answer": "Alias fortorch.atanh()",
        "question": "Who returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Inputi/otheritextinput_i / textotheriinputi /other": {
        "answer": "quadrant",
        "question": "Inputi/otheritextinput_i / textotheriinputi /other",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what ofinputandother?": {
        "answer": "bitwise XOR",
        "question": "Computes the what ofinputandother?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the smallest integer greater than or equal to each element?": {
        "answer": "the ceil of the elements ofinput",
        "question": "What is the smallest integer greater than or equal to each element?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What clamps all elements ininputinto the range?": {
        "answer": "Clamps all elements ininputinto the range",
        "question": "What clamps all elements ininputinto the range?",
        "context": "Computes the absolute value of each element ininput.   Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.acosh() add?": {
        "answer": "scalarotherto each element of the inputinput",
        "question": "What does Alias fortorch.acosh() add?",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Clamps all elements ininputinto what range?": {
        "answer": "range[min,max]",
        "question": "Clamps all elements ininputinto what range?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch.abs() do?": {
        "answer": "Alias fortorch.",
        "question": "What does Alias fortorch.abs() do?",
        "context": "Alias fortorch.abs()   Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what cosine of each element ininput?": {
        "answer": "inverse",
        "question": "Computes the what cosine of each element ininput?",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which function returns a new tensor with the arctangent of the elements ofinput?": {
        "answer": "Alias fortorch.asinh()",
        "question": "Which function returns a new tensor with the arctangent of the elements ofinput?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the inverse cosine of each element ininput. Computes the smallest integer greater than or equal to each element.": {
        "answer": "Alias fortorch.clamp()",
        "question": "Computes the inverse cosine of each element ininput. Computes the smallest integer greater than or equal to each element.",
        "context": "Computes the inverse cosine of each element ininput.   Alias fortorch.acos().   Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the giveninputtensor. Returns a new tensor with the arcsine of the elements ofin": {
        "answer": "element-wise angle",
        "question": "Computes the giveninputtensor. Returns a new tensor with the arcsine of the elements ofin",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Who returns a new tensor with the inverse hyperbolic sine of the elements ofinput?": {
        "answer": "Alias fortorch.asin()",
        "question": "Who returns a new tensor with the inverse hyperbolic sine of the elements ofinput?",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Clamps all elements ininputinto what?": {
        "answer": "range[min,max]",
        "question": "Clamps all elements ininputinto what?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function computes the element-wise conjugate of the giveninputtensor?": {
        "answer": "Alias fortorch.clamp()",
        "question": "What function computes the element-wise conjugate of the giveninputtensor?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What type of tensor is created with the magnitude ofinput?": {
        "answer": "floating-point tensor",
        "question": "What type of tensor is created with the magnitude ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic cosine of the elements ofinput.   Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function adds the scalarotherto each element of the inputinputand returns a new resulting tensor?": {
        "answer": "Alias fortorch.acosh()",
        "question": "What function adds the scalarotherto each element of the inputinputand returns a new resulting tensor?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Create a new what with the magnitude ofinputand the sign ofother, elementwise?": {
        "answer": "floating-point tensor",
        "question": "Create a new what with the magnitude ofinputand the sign ofother, elementwise?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what of the element?": {
        "answer": "cosine",
        "question": "Returns a new tensor with what of the element?",
        "context": "Alias fortorch.acosh().   Adds the scalarotherto each element of the inputinputand returns a new resulting tensor.   Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs the element-wise multiplication what?": {
        "answer": "oftensor1bytensor2",
        "question": "Performs the element-wise multiplication what?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.asin(). Returns a new tensor with what of the elements ofinput?": {
        "answer": "inverse hyperbolic sine",
        "question": "Alias fortorch.asin(). Returns a new tensor with what of the elements ofinput?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.asinh(). Returns a new tensor with the what of the elements ofin": {
        "answer": "arctangent",
        "question": "Alias fortorch.asinh(). Returns a new tensor with the what of the elements ofin",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which function returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?": {
        "answer": "Alias fortorch.atanh()",
        "question": "Which function returns a new tensor with the inverse hyperbolic tangent of the elements ofinput?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Inputi/otheritextinputi / textotheriinputi /otheri with consideration of": {
        "answer": "quadrant",
        "question": "Inputi/otheritextinputi / textotheriinputi /otheri with consideration of",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Clamps which elements ininputinto the range[min,max].?": {
        "answer": "all elements ininputinto the range[min,max].",
        "question": "Clamps which elements ininputinto the range[min,max].?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.clamp(). Computes the what of the giveninputtensor?": {
        "answer": "element-wise conjugate",
        "question": "Alias fortorch.clamp(). Computes the what of the giveninputtensor?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Create a new what tensor with the magnitude ofinputand the sign ofother, elementwise?": {
        "answer": "floating-point tensor",
        "question": "Create a new what tensor with the magnitude ofinputand the sign ofother, elementwise?",
        "context": "Performs the element-wise division oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Multiply the result by the scalarvalue and add it toinput. Computes the element-wise angle (in radi": {
        "answer": "oftensor1bytensor2",
        "question": "Multiply the result by the scalarvalue and add it toinput. Computes the element-wise angle (in radi",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what of the giveninputtensor?": {
        "answer": "the element-wise angle",
        "question": "Computes what of the giveninputtensor?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Who returns a new tensor with the arctangent of the elements ofinput?": {
        "answer": "Alias fortorch.asinh()",
        "question": "Who returns a new tensor with the arctangent of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the element-wise what of the giveninputtensor?": {
        "answer": "conjugate",
        "question": "Computes the element-wise what of the giveninputtensor?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is returned with each of the elements ofinputconverted from angles in degrees to radians?": {
        "answer": "a new tensor",
        "question": "What is returned with each of the elements ofinputconverted from angles in degrees to radians?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does divide each element of the inputinput by the corresponding element ofother?": {
        "answer": "Divides each element of the inputinputby the corresponding element ofother",
        "question": "What does divide each element of the inputinput by the corresponding element ofother?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which Alia performs the element-wise multiplication oftensor1bytensor2 multiply the result by the scalarvalue?": {
        "answer": "Alia",
        "question": "Which Alia performs the element-wise multiplication oftensor1bytensor2 multiply the result by the scalarvalue?",
        "context": "Performs the element-wise multiplication oftensor1bytensor2, multiply the result by the scalarvalueand add it toinput.   Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Inputi/otheritextinputi / textothericomputes the bitwise NOT of the given": {
        "answer": "quadrant",
        "question": "Inputi/otheritextinputi / textothericomputes the bitwise NOT of the given",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what element of the elements ofinput?": {
        "answer": "cosine",
        "question": "Returns a new tensor with what element of the elements ofinput?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What are the elements ofinputconverted from?": {
        "answer": "angles in degrees to radians",
        "question": "What are the elements ofinputconverted from?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What happens to each element of the inputinput by the corresponding element ofother?": {
        "answer": "Divides each element of the inputinputby the corresponding element ofother",
        "question": "What happens to each element of the inputinput by the corresponding element ofother?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the logarithmic derivative of the gamma function oninput?": {
        "answer": "Alias fortorch.div()",
        "question": "Computes the logarithmic derivative of the gamma function oninput?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what of the gamma function oninput?": {
        "answer": "logarithmic derivative",
        "question": "Computes the what of the gamma function oninput?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the logarithmic derivative of the gamma function oninput. Computes the logarithmic derivative of the": {
        "answer": "Alias fortorch.special.erf()",
        "question": "Computes the logarithmic derivative of the gamma function oninput. Computes the logarithmic derivative of the",
        "context": "Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Alias fortorch call?": {
        "answer": "special.erf()",
        "question": "What does Alias fortorch call?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is another name for Alias fortorch.special.erf()?": {
        "answer": "Alias fortorch.special.erfc()",
        "question": "What is another name for Alias fortorch.special.erf()?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the exponential of the elements ofinput?": {
        "answer": "Alias fortorch.special.erfinv()",
        "question": "What is the name of the function that returns a new tensor with the exponential of the elements ofinput?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what of the elements of the elements of the input?": {
        "answer": "inverse hyperbolic sine of the elements ofinput",
        "question": "Returns a new tensor with what of the elements of the elements of the input?",
        "context": "Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What element of the elements ofinput does Alias fortorch.asinh() return a new tensor with": {
        "answer": "arctangent",
        "question": "What element of the elements ofinput does Alias fortorch.asinh() return a new tensor with",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput. Alias fort": {
        "answer": "atan()",
        "question": "Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput. Alias fort",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "The arctangent ofinputi/otheri is considered with consideration of what?": {
        "answer": "quadrant",
        "question": "The arctangent ofinputi/otheri is considered with consideration of what?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What function returns a new tensor with the exponential of the elements of the input tensorinput?": {
        "answer": "Alias fortorch.special.erfinv()",
        "question": "What function returns a new tensor with the exponential of the elements of the input tensorinput?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a new tensor with what of the elements of the input tensorinput?": {
        "answer": "exponential",
        "question": "Returns a new tensor with what of the elements of the input tensorinput?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the name of the function that returns a new tensor with the exponential of the elements of the input tensorinput": {
        "answer": "Alias fortorch.special.exp2()",
        "question": "What is the name of the function that returns a new tensor with the exponential of the elements of the input tensorinput",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is Alias fortorch.special.exp2()?": {
        "answer": "Alia",
        "question": "What is Alias fortorch.special.exp2()?",
        "context": "  Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   Returns a new tensor with the data ininputfake quantized usingscale,zero_point,quant_minandquant_max.   Alias fortorch.trunc()   Raisesinputto the power ofexponent, elementwise, in double precision.   Returns a new tensor with the floor of the elements ofinput, the largest integer less than or equal to each element.    ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the indices of what value of all elements in theinputtensor?": {
        "answer": "the maximum value",
        "question": "Returns the indices of what value of all elements in theinputtensor?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Tests if all elements ininputevaluate what?": {
        "answer": "toTrue",
        "question": "Tests if all elements ininputevaluate what?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim. Returns the mean": {
        "answer": "p-norm of (input-other) Returns the log of summed exponentials",
        "question": "Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim. Returns the mean",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the median of the values ininput, doing what?": {
        "answer": "ignoringNaNvalues",
        "question": "Returns the median of the values ininput, doing what?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what quantiles of each row of theinputtensor along the dimensiondim?": {
        "answer": "q-th",
        "question": "Computes what quantiles of each row of theinputtensor along the dimensiondim?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the result of Computes the q-th quantiles of each row of theinputtensor along the dimensiondim": {
        "answer": "variant oftorch.quantile()that \u201cignores\u201dNaNvalues",
        "question": "What is the result of Computes the q-th quantiles of each row of theinputtensor along the dimensiondim",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "IfunbiasedisTrue, what will be used?": {
        "answer": "Bessel\u2019s correction",
        "question": "IfunbiasedisTrue, what will be used?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Bessel's correction will be used to calculate what?": {
        "answer": "standard deviation",
        "question": "Bessel's correction will be used to calculate what?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the input tensor. Eliminates all but the first element from every consecutive group of equivalent elements. IfunbiasedisTrue,": {
        "answer": "unique elements",
        "question": "Returns the input tensor. Eliminates all but the first element from every consecutive group of equivalent elements. IfunbiasedisTrue,",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Which element is eliminated from every consecutive group of equivalent elements?": {
        "answer": "Eliminates all but the first element",
        "question": "Which element is eliminated from every consecutive group of equivalent elements?",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "IfunbiasedisTrue, Bessel\u2019s correction will be used.": {
        "answer": "IfunbiasedisTrue",
        "question": "IfunbiasedisTrue, Bessel\u2019s correction will be used.",
        "context": "  Returns the indices of the maximum value of all elements in theinputtensor.   Returns the indices of the minimum value(s) of the flattened tensor or along a dimension   Returns the maximum value of each slice of theinputtensor in the given dimension(s)dim.   Returns the minimum value of each slice of theinputtensor in the given dimension(s)dim.   Tests if all elements ininputevaluate toTrue.    the input tensor.   Returns the maximum value of all elements in theinputtensor.   Returns the minimum value of all elements in theinputtensor.   Returns the p-norm of (input-other)   Returns the log of summed exponentials of each row of theinputtensor in the given dimensiondim.   Returns the mean value of all elements in theinputtensor.   Returns the median of the values ininput.   Returns the median of the values ininput, ignoringNaNvalues.   Returns a namedtuple(values,indices)wherevaluesis the mode value of each row of theinputtensor in the given dimensiondim, i.e.   Returns the matrix norm or vector norm of a given tensor.   Returns the sum of all elements, treating Not a Numbers (NaNs) as zero.   Returns the product of all elements in theinputtensor.   Computes the q-th quantiles of each row of theinputtensor along the dimensiondim.   This is a variant oftorch.quantile()that \u201cignores\u201dNaNvalues, computing the quantilesqas ifNaNvalues ininputdid not exist.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the standard deviation.   Returns the sum of all elements in theinputtensor.   Returns the unique elements of the input tensor.   Eliminates all but the first element from every consecutive group of equivalent elements.   IfunbiasedisTrue, Bessel\u2019s correction will be used.   IfunbiasedisTrue, Bessel\u2019s correction will be used to calculate the variance.   Counts the number of non-zero values in the tensorinputalong the givendim. ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a what dimension view of each input tensor with zero dimensions?": {
        "answer": "3-dimensional",
        "question": "Returns a what dimension view of each input tensor with zero dimensions?",
        "context": "Returns a 1-dimensional view of each input tensor with zero dimensions.   Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is one way to create a block diagonal matrix from provided tensors?": {
        "answer": "Count the frequency of each value in an array of non-negative ints",
        "question": "What is one way to create a block diagonal matrix from provided tensors?",
        "context": "Returns a 1-dimensional view of each input tensor with zero dimensions.   Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is created from provided tensors?": {
        "answer": "Create a block diagonal matrix",
        "question": "What is created from provided tensors?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Broadcasts the given tensors according to what?": {
        "answer": "Broadcasting semantics",
        "question": "Broadcasts the given tensors according to what?",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries": {
        "answer": "indices",
        "question": "Returns what of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries",
        "context": "Returns a 1-dimensional view of each input tensor with zero dimensions.   Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of the given sequence of tensors. Computes batched the p-norm distance between each pair of the": {
        "answer": "Do cartesian product",
        "question": "What product of the given sequence of tensors. Computes batched the p-norm distance between each pair of the",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Compute combinations of lengthrrrof the given tensor. Returns a copy ofinput. Returns a copy of": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "Compute combinations of lengthrrrof the given tensor. Returns a copy ofinput. Returns a copy of",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim?": {
        "answer": "a namedtuple(values,indices)",
        "question": "Returns what wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what along the given dimension?": {
        "answer": "n-th forward difference",
        "question": "Computes what along the given dimension?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What Sums the product of the elements of the inputoperandsalong dimensions specified using a notation?": {
        "answer": "Sums the product of the elements of the inputoperandsalong dimensions specified using a notation",
        "question": "What Sums the product of the elements of the inputoperandsalong dimensions specified using a notation?",
        "context": "Returns a 1-dimensional view of each input tensor with zero dimensions.   Returns a 2-dimensional view of each input tensor with zero dimensions.   Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns a view of each input tensor with zero dimensions. Count the frequency of each value in an array of non-negative in": {
        "answer": "3-dimensional",
        "question": "Returns a view of each input tensor with zero dimensions. Count the frequency of each value in an array of non-negative in",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is another way to create a block diagonal matrix from provided tensors?": {
        "answer": "Count the frequency of each value in an array of non-negative ints",
        "question": "What is another way to create a block diagonal matrix from provided tensors?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is done by reshaping it into a one-dimensional tensor?": {
        "answer": "Flattensinput",
        "question": "What is done by reshaping it into a one-dimensional tensor?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the result of Flattensinput by reshaping it into a one-dimensional tensor?": {
        "answer": "Reverse",
        "question": "What is the result of Flattensinput by reshaping it into a one-dimensional tensor?",
        "context": "Returns a 3-dimensional view of each input tensor with zero dimensions.   Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "How do you count the frequency of each value in an array of non-negative ints?": {
        "answer": "Count the frequency of each value in an array of non-negative ints",
        "question": "How do you count the frequency of each value in an array of non-negative ints?",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Create what from provided tensors?": {
        "answer": "block diagonal matrix",
        "question": "Create what from provided tensors?",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Compute combinations of lengthrrrof the given tensor. Returns the cross product of vectors in dimensiondimofinput": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "Compute combinations of lengthrrrof the given tensor. Returns the cross product of vectors in dimensiondimofinput",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Sums the product of the elements of inputoperandsalong dimensions specified using a notation based on what?": {
        "answer": "Einstein",
        "question": "Sums the product of the elements of inputoperandsalong dimensions specified using a notation based on what?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Reverse the order of what along given axis?": {
        "answer": "n-D tensor",
        "question": "Reverse the order of what along given axis?",
        "context": "Count the frequency of each value in an array of non-negative ints.   Create a block diagonal matrix from provided tensors.   Broadcasts the given tensors according toBroadcasting semantics.   Broadcastsinputto the shapeshape.   Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "For what do Broadcast_tensors() work?": {
        "answer": "shapes",
        "question": "For what do Broadcast_tensors() work?",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Compute combinations of lengthrrof the given tensor. Returns the cross product of vectors in dimensiondimofinputand": {
        "answer": "Compute combinations of lengthrrrof the given tensor",
        "question": "Compute combinations of lengthrrof the given tensor. Returns the cross product of vectors in dimensiondimofinputand",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Flattensinput by reshaping it into what?": {
        "answer": "one-dimensional tensor",
        "question": "Flattensinput by reshaping it into what?",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Reverse the order of what along given axis in dims?": {
        "answer": "n-D tensor",
        "question": "Reverse the order of what along given axis in dims?",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In the left/right direction, returning a new tensor. In the up/down direction, returning a new tensor": {
        "answer": "Flip tensor",
        "question": "In the left/right direction, returning a new tensor. In the up/down direction, returning a new tensor",
        "context": "Similar tobroadcast_tensors()but for shapes.   Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What returns a new tensor?": {
        "answer": "Flip tensor in the up/down direction",
        "question": "What returns a new tensor?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In the left/right direction, returning a new tensor. Flip tensor in the up/down direction, returning a": {
        "answer": "Flip tensor",
        "question": "In the left/right direction, returning a new tensor. Flip tensor in the up/down direction, returning a",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what product, denoted by otimes, ofinputandother?": {
        "answer": "Kronecker",
        "question": "Computes what product, denoted by otimes, ofinputandother?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Rotate a n Rotate a n Rotate a n Rotate a n Rotate a n Rot": {
        "answer": "Rotate a n",
        "question": "Rotate a n Rotate a n Rotate a n Rotate a n Rotate a n Rot",
        "context": "Returns the indices of the buckets to which each value in theinputbelongs, where the boundaries of the buckets are set byboundaries.   Do cartesian product of the given sequence of tensors.   Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Compute what?": {
        "answer": "combinations of lengthrrrof the given tensor",
        "question": "Compute what?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Reverse the order of what along given axis in dims. Flip tensor in the left/right direction, returning a new": {
        "answer": "n-D tensor",
        "question": "Reverse the order of what along given axis in dims. Flip tensor in the left/right direction, returning a new",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "In the left/right direction, return a new tensor. Flip tensor in the up/down direction, returning a": {
        "answer": "Flip tensor",
        "question": "In the left/right direction, return a new tensor. Flip tensor in the up/down direction, returning a",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what product of inputandother?": {
        "answer": "Kronecker product",
        "question": "Computes what product of inputandother?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Rotate by 90 degrees in the plane specified by dims axis?": {
        "answer": "Rotate a n-D tensor",
        "question": "What does Rotate by 90 degrees in the plane specified by dims axis?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the histogram of what?": {
        "answer": "element-wise greatest common divisor",
        "question": "Computes the histogram of what?",
        "context": "Computes batched the p-norm distance between each pair of the two collections of row vectors.   Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Rotate a n-D tensor by 90 degrees in the plane specified by dims axis?": {
        "answer": "Rotate",
        "question": "What does Rotate a n-D tensor by 90 degrees in the plane specified by dims axis?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the element-wise greatest common divisor of inputandother. Computes the histogram of a tensor.": {
        "answer": "GCD",
        "question": "Computes the element-wise greatest common divisor of inputandother. Computes the histogram of a tensor.",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes what of a tensor?": {
        "answer": "histogram",
        "question": "Computes what of a tensor?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What can be either scalar or scalar?": {
        "answer": "TakeNNNtensors",
        "question": "What can be either scalar or scalar?",
        "context": "Returns a copy ofinput.   Compute combinations of lengthrrrof the given tensor.   Returns the cross product of vectors in dimensiondimofinputandother.   Returns a namedtuple(values,indices)wherevaluesis the cumulative maximum of elements ofinputin the dimensiondim.   Returns a namedtuple(values,indices)wherevaluesis the cumulative minimum of elements ofinputin the dimensiondim.   Returns the cumulative product of elements ofinputin the dimensiondim.   Returns the cumulative sum of elements ofinputin the dimensiondim.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Creates a tensor whose diagonals of certain 2D planes (specified bydim1anddim2) are filled byinput.    Ifinputis a vector (1-D tensor), then returns a 2-D square tensor   Returns a partial view ofinputwith the its diagonal elements with respect todim1anddim2appended as a dimension at the end of the shape.   Computes the n-th forward difference along the given dimension.   Sums the product of the elements of the inputoperandsalong dimensions specified using a notation based on the Einstein summation convention.   Flattensinputby reshaping it into a one-dimensional tensor.   Reverse the order of a n-D tensor along given axis in dims.   Flip tensor in the left/right direction, returning a new tensor.   Flip tensor in the up/down direction, returning a new tensor.   Computes the Kronecker product, denoted by\u2297\\otimes\u2297, ofinputandother.   Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.   Computes the element-wise greatest common divisor (GCD) ofinputandother.   Computes the histogram of a tensor.   TakeNNNtensors, each of which can be either scalar or 1-dimensional vector, and createNNNN-dimensional grids, where theiiithgrid is defined by expanding theiiithinput over dimensions defined by other inputs.   Computes the element-wise least common multiple (LCM) ofinputandother.   Returns the logarithm of the cumulative summation of the exponentiation of elements ofinputin the dimensiondim.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what of matrices stored inbatch1andbatch2 with a reduced add step (all matrix multiplications get ": {
        "answer": "a batch matrix-matrix product",
        "question": "Performs what of matrices stored inbatch1andbatch2 with a reduced add step (all matrix multiplications get ",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of the matrixmatand the vectorvec is performed?": {
        "answer": "matrix-vector product",
        "question": "What product of the matrixmatand the vectorvec is performed?",
        "context": "Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs the outer-product of vectorsvec1andvec2and adds it to what?": {
        "answer": "matrixinput",
        "question": "Performs the outer-product of vectorsvec1andvec2and adds it to what?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs a batch matrix-matrix product of what?": {
        "answer": "matrices inbatch1andbatch2",
        "question": "Performs a batch matrix-matrix product of what?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what matrix product of theNNN2-D tensors?": {
        "answer": "matrix product of theNNN2-D tensors",
        "question": "Returns what matrix product of theNNN2-D tensors?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the inverse of a symmetric positive-definite matrixAAAusing its what?": {
        "answer": "Cholesky factoruuu",
        "question": "Computes the inverse of a symmetric positive-definite matrixAAAusing its what?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Positive semidefinite matrix to be inverted given its what?": {
        "answer": "Cholesky factor matrixuuu",
        "question": "Positive semidefinite matrix to be inverted given its what?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the dot product of two 1D tensors. Computes the eigenvalues and eigenve": {
        "answer": "Computes the dot product of two 1D tensors",
        "question": "Computes the dot product of two 1D tensors. Computes the eigenvalues and eigenve",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the eigenvalues and eigenvectors of a real square matrix. This is a what?": {
        "answer": "low-level function",
        "question": "Computes the eigenvalues and eigenvectors of a real square matrix. This is a what?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the dot product for 1D tensors. Computes the dot product for 1D tensors": {
        "answer": "Alias oftorch.outer()",
        "question": "Computes the dot product for 1D tensors. Computes the dot product for 1D tensors",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Calculates what of a square matrix or batches of square matrices?": {
        "answer": "log determinant",
        "question": "Calculates what of a square matrix or batches of square matrices?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Computes the LU factorization of a matrix?": {
        "answer": "Computes the LU factorization of a matrix",
        "question": "What does Computes the LU factorization of a matrix?",
        "context": "Performs a batch matrix-matrix product of matrices stored inbatch1andbatch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension).   Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what of the matricesmat1andmat2?": {
        "answer": "matrix multiplication",
        "question": "Performs what of the matricesmat1andmat2?",
        "context": "Performs a matrix multiplication of the matricesmat1andmat2.   Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the batch matrix-matrix product of?": {
        "answer": "matrices inbatch1andbatch2",
        "question": "What is the batch matrix-matrix product of?",
        "context": "Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what of a matrix or batches of matricesA?": {
        "answer": "LU factorization",
        "question": "Computes the what of a matrix or batches of matricesA?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what of the matrixmatand the vectorvec?": {
        "answer": "matrix-vector product",
        "question": "Performs what of the matrixmatand the vectorvec?",
        "context": "Performs a matrix-vector product of the matrixmatand the vectorvec.   Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the what factorization of a matrix or batches of matricesA?": {
        "answer": "LU",
        "question": "Computes the what factorization of a matrix or batches of matricesA?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs the what of vectorsvec1andvec2and adds it to the matrixinput?": {
        "answer": "outer-product",
        "question": "Performs the what of vectorsvec1andvec2and adds it to the matrixinput?",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns the what solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization": {
        "answer": "LU",
        "question": "Returns the what solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Unpacks the data and pivots from a LU factorization of a tensor into what?": {
        "answer": "tensorsLand",
        "question": "Unpacks the data and pivots from a LU factorization of a tensor into what?",
        "context": "Performs the outer-product of vectorsvec1andvec2and adds it to the matrixinput.   Performs a batch matrix-matrix product of matrices inbatch1andbatch2.   Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what of matrices stored ininputandmat2?": {
        "answer": "a batch matrix-matrix product",
        "question": "Performs what of matrices stored ininputandmat2?",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the dot product for 1D tensors. Computes the eigenvalues and eigenvector": {
        "answer": "Alias oftorch.outer()",
        "question": "Computes the dot product for 1D tensors. Computes the eigenvalues and eigenvector",
        "context": "Performs a batch matrix-matrix product of matrices stored ininputandmat2.   Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the LU factorization of a tensor?": {
        "answer": "LU factorization of a tensor into tensorsLandU",
        "question": "What is the LU factorization of a tensor?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is a matrix product of two tensors?": {
        "answer": "Matrix product of two tensors",
        "question": "What is a matrix product of two tensors?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does the matrix product of two tensors return?": {
        "answer": "Matrix product of two tensors",
        "question": "What does the matrix product of two tensors return?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does matrix_power() return?": {
        "answer": "numerical rank",
        "question": "What does matrix_power() return?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the solution to what problems for a full rank matrix?": {
        "answer": "least squares and least norm problems",
        "question": "Computes the solution to what problems for a full rank matrix?",
        "context": "Returns the matrix product of theNNN2-D tensors.   Computes the Cholesky decomposition of a symmetric positive-definite matrixAAAor for batches of symmetric positive-definite matrices.   Computes the inverse of a symmetric positive-definite matrixAAAusing its Cholesky factoruuu: returns matrixinv.   Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Returns what solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of": {
        "answer": "LU",
        "question": "Returns what solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is computed?": {
        "answer": "the element-wise angle (in radians) of the giveninputtensor",
        "question": "What is computed?",
        "context": "Computes the element-wise angle (in radians) of the giveninputtensor.   Returns a new tensor with the arcsine  of the elements ofinput.   Alias fortorch.asin().   Returns a new tensor with the inverse hyperbolic sine of the elements ofinput.   Alias fortorch.asinh().   Returns a new tensor with the arctangent  of the elements ofinput.   Alias fortorch.atan().   Returns a new tensor with the inverse hyperbolic tangent of the elements ofinput.   Alias fortorch.atanh().   Element-wise arctangent ofinputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200bwith consideration of the quadrant.   Computes the bitwise NOT of the given input tensor.   Computes the bitwise AND ofinputandother.   Computes the bitwise OR ofinputandother.   Computes the bitwise XOR ofinputandother.   Returns a new tensor with the ceil of the elements ofinput, the smallest integer greater than or equal to each element.   Clamps all elements ininputinto the range[min,max].   Alias fortorch.clamp().   Computes the element-wise conjugate of the giveninputtensor.   Create a new floating-point tensor with the magnitude ofinputand the sign ofother, elementwise.   Returns a new tensor with the cosine  of the elements ofinput.   Returns a new tensor with the hyperbolic cosine  of the elements ofinput.   Returns a new tensor with each of the elements ofinputconverted from angles in degrees to radians.   Divides each element of the inputinputby the corresponding element ofother.   Alias fortorch.div().   Computes the logarithmic derivative of the gamma function oninput.   Alias fortorch.special.erf().   Alias fortorch.special.erfc().   Alias fortorch.special.erfinv().   Returns a new tensor with the exponential of the elements of the input tensorinput.   Alias fortorch.special.exp2().   Alias fortorch.special.expm1().   Returns a new tensor with the data ininputfake quantized per channel usingscale,zero_point,quant_minandquant_max, across the channel specified byaxis.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.linalg.matrix_power() Returns what of a 2-D tensor?": {
        "answer": "numerical rank",
        "question": "Alias fortorch.linalg.matrix_power() Returns what of a 2-D tensor?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the matrix exponential of a square matrix or of each square matrix in a batch <sep>": {
        "answer": "Computes the matrix exponential of a square matrix or of each square matrix in a batch",
        "question": "Computes the matrix exponential of a square matrix or of each square matrix in a batch <sep>",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs what of the matricesinputandmat2?": {
        "answer": "matrix multiplication",
        "question": "Performs what of the matricesinputandmat2?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of the matrixinputand the vectorvec is performed?": {
        "answer": "matrix-vector",
        "question": "What product of the matrixinputand the vectorvec is performed?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the householder_product of Alias fortorch.linalg?": {
        "answer": "householder_product",
        "question": "What is the householder_product of Alias fortorch.linalg?",
        "context": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrixuuu.   Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is computed by Computes the dot product of two tensors?": {
        "answer": "Matrix product of two tensors",
        "question": "What is computed by Computes the dot product of two tensors?",
        "context": "Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Alias fortorch.linalg.matrix_power() Returns the what of a 2-D tensor": {
        "answer": "numerical rank",
        "question": "Alias fortorch.linalg.matrix_power() Returns the what of a 2-D tensor",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Performs a what product of the matrixinputand the vectorvec?": {
        "answer": "matrix-vector",
        "question": "Performs a what product of the matrixinputand the vectorvec?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix?": {
        "answer": "Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix",
        "question": "Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the matrix-matrix multiplication of a product of what with a general matrix?": {
        "answer": "Householder matrices",
        "question": "Computes the matrix-matrix multiplication of a product of what with a general matrix?",
        "context": "Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What does Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix do?": {
        "answer": "Out",
        "question": "What does Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix do?",
        "context": "Computes the dot product of two 1D tensors.   Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix. Outer product": {
        "answer": "householder_product()",
        "question": "Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix. Outer product",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What product of inputandvec2?": {
        "answer": "Outer product",
        "question": "What product of inputandvec2?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "Who computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix?": {
        "answer": "Alias fortorch",
        "question": "Who computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix?",
        "context": "Computes the eigenvalues and eigenvectors of a real square matrix.   This is a low-level function for calling LAPACK\u2019s geqrf directly.   Alias oftorch.outer().   Computes the dot product for 1D tensors.   Alias fortorch.linalg.inv()   Alias fortorch.linalg.det()   Calculates log determinant of a square matrix or batches of square matrices.   Alias fortorch.linalg.slogdet()   Computes the solution to the least squares and least norm problems for a full rank matrixAAAof size(m\u00d7n)(m \\times n)(m\u00d7n)and a matrixBBBof size(m\u00d7k)(m \\times k)(m\u00d7k).   Computes the LU factorization of a matrix or batches of matricesA.   Returns the LU solve of the linear systemAx=bAx = bAx=busing the partially pivoted LU factorization of A fromtorch.lu().   Unpacks the data and pivots from a LU factorization of a tensor into tensorsLandUand a permutation tensorPsuch thatLU_data,LU_pivots=(P@L@U).lu().   Matrix product of two tensors.   Alias fortorch.linalg.matrix_power()   Returns the numerical rank of a 2-D tensor.   Computes the matrix exponential of a square matrix or of each square matrix in a batch.   Performs a matrix multiplication of the matricesinputandmat2.   Performs a matrix-vector product of the matrixinputand the vectorvec.   Alias fortorch.linalg.householder_product().   Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.   Outer product ofinputandvec2.   Alias fortorch.linalg.pinv()   Computes the QR decomposition of a matrix or a batch of matricesinput, and returns a namedtuple (Q, R) of tensors such thatinput=QR\\text{input} = Q Rinput=QRwithQQQbeing an orthogonal matrix or batch of orthogonal matrices andRRRbeing an upper triangular matrix or batch of upper triangular matrices.   This function returns the solution to the system of linear equations represented byAX=BAX = BAX=Band the LU factorization of A, in order as a namedtuplesolution, LU.   Computes the singular value decomposition of either a matrix or batch of matricesinput.   ",
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops"
    },
    "What is the current state of this module?": {
        "answer": "BETA",
        "question": "What is the current state of this module?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "See what for details. Computes the entropy oninput(as defined below), elementwise.": {
        "answer": "documentation of each function",
        "question": "See what for details. Computes the entropy oninput(as defined below), elementwise.",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the error function ofinput. The error function is defined as follows: what is the input tensor?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "Computes the error function ofinput. The error function is defined as follows: what is the input tensor?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input ten": {
        "answer": "output tensor",
        "question": "Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input ten",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of the function that Computes the error function ofinput?": {
        "answer": "Computes the complementary error function ofinput",
        "question": "What is the name of the function that Computes the error function ofinput?",
        "context": "Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the complementary error function ofinput. The complementary error function is defined as follows: what is the input tensor?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "Computes the complementary error function ofinput. The complementary error function is defined as follows: what is the input tensor?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the name of the function that Computes the inverse error function ofinput?": {
        "answer": "Computes the inverse error function ofinput",
        "question": "What is the name of the function that Computes the inverse error function ofinput?",
        "context": "Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a Computes the exponential of the elements minus 1 ofinput?": {
        "answer": "Computes the exponential of the elements minus 1 ofinput",
        "question": "What is an example of a Computes the exponential of the elements minus 1 ofinput?",
        "context": "This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the natural logarithm of the absolute value of the gamma function oninput?": {
        "answer": "input(Tensor)",
        "question": "Computes the natural logarithm of the absolute value of the gamma function oninput?",
        "context": "The torch.special module, modeled after SciPy\u2019sspecialmodule. This module is in BETA. New functions are still being added, and some\nfunctions may change in future PyTorch releases. See the documentation of each\nfunction for details. Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Input(Tensor) \u2013 the input tensor. Out(Tensor,optional) \u2013 the output": {
        "answer": "out(Tensor,optional)",
        "question": "Input(Tensor) \u2013 the input tensor. Out(Tensor,optional) \u2013 the output",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the error function defined as?": {
        "answer": "input(Tensor) \u2013 the input tensor",
        "question": "What is the error function defined as?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the elements minus 1 ofinput. Note This function provides greater precision than exp(x) - 1 for small values of ": {
        "answer": "exponential",
        "question": "Computes the elements minus 1 ofinput. Note This function provides greater precision than exp(x) - 1 for small values of ",
        "context": "Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tens": {
        "answer": "natural logarithm",
        "question": "Computes the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tens",
        "context": "Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is the first kind?": {
        "answer": "exponentially scaled zeroth order modified Bessel function",
        "question": "What is the first kind?",
        "context": "Computes the entropy oninput(as defined below), elementwise. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a function that computes the error function ofinput?": {
        "answer": "Computes the complementary error function ofinput",
        "question": "What is an example of a function that computes the error function ofinput?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of an error function that is defined in the range(1,1)(-1, 1)(1,1)?": {
        "answer": "Computes the inverse error function ofinput",
        "question": "What is an example of an error function that is defined in the range(1,1)(-1, 1)(1,1)?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is also known as the logistic sigmoid function?": {
        "answer": "expit",
        "question": "What is also known as the logistic sigmoid function?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a computation?": {
        "answer": "Computes the natural logarithm of the absolute value of the gamma function oninput",
        "question": "What is an example of a computation?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the first kind of what function for each element ofinput?": {
        "answer": "exponentially scaled zeroth order modified Bessel function",
        "question": "Computes the first kind of what function for each element ofinput?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example?": {
        "answer": "Computes the natural logarithm of the absolute value of the gamma function oninput",
        "question": "What is an example?",
        "context": "out(Tensor,optional) \u2013 the output tensor. Computes the error function ofinput. The error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "Computes the first kind for each element ofinput. input(Tensor) \u2013 the input tensor. out(": {
        "answer": "exponentially scaled zeroth order modified Bessel function",
        "question": "Computes the first kind for each element ofinput. input(Tensor) \u2013 the input tensor. out(",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    },
    "What is an example of a function that computes the inverse error function ofinput?": {
        "answer": "Computes the inverse error function ofinput",
        "question": "What is an example of a function that computes the inverse error function ofinput?",
        "context": "input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the complementary error function ofinput.\nThe complementary error function is defined as follows: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the inverse error function ofinput.\nThe inverse error function is defined in the range(\u22121,1)(-1, 1)(\u22121,1)as: input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the expit (also known as the logistic sigmoid function) of the elements ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponential of the elements minus 1\nofinput. Note This function provides greater precision than exp(x) - 1 for small values of x. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the base two exponential function ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the natural logarithm of the absolute value of the gamma function oninput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Example: Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below)\nfor each element ofinput. input(Tensor) \u2013 the input tensor. out(Tensor,optional) \u2013 the output tensor. Returns a new tensor with the logit of the elements ofinput.inputis clamped to [eps, 1 - eps] when eps is not None.\nWhen eps is None andinput< 0 orinput> 1, the function will yields NaN. input(Tensor) \u2013 the input tensor. eps(float,optional) \u2013 the epsilon for input clamp bound. Default:None out(Tensor,optional) \u2013 the output tensor. Example: Computesinput*log1p(other)with the following cases. Similar to SciPy\u2019sscipy.special.xlog1py. input(NumberorTensor) \u2013 Multiplier other(NumberorTensor) \u2013 Argument Note At least one ofinputorothermust be a tensor. out(Tensor,optional) \u2013 the output tensor. Example: ",
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf"
    }
}